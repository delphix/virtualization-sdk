{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome!","text":"<p>With this Delphix Virtualization SDK documentation we hope you will find all you need to know in order to develop your own plugins!</p>"},{"location":"#overview","title":"Overview","text":"<p>If you already know about plugins, and are looking for something specific, use the links to the left to find what you are looking for or search.</p> <p>If this is your first time here, and you are wondering what developing a Delphix plugin will do for you\u2014read on!</p>"},{"location":"#what-does-a-delphix-plugin-do","title":"What Does a Delphix Plugin do?","text":"<p>The Delphix Engine is an appliance that lets you quickly and cheaply make virtual copies of large datasets. The engine has built-in support for interfacing with certain types of datasets, such as Oracle, SQL Server and ASE.</p> <p>When you develop a plugin, you enable end users to use your dataset type as if they were using a built-in dataset type, whether it\u2019s MongoDB, Cassandra, or something else. Your plugin will extend the Delphix Engine\u2019s capabilities by teaching it how to run essential virtual data operations on your datasets:</p> <ul> <li>How to stop and start them</li> <li>Where to store their data</li> <li>How to make virtual copies</li> </ul> <p>These plugin operations are the building blocks of the Delphix Engine. From these building blocks, the engine can provide all of the normal Delphix functionality to the datasets you connect to such as:</p> <ul> <li>Provisioning</li> <li>Refreshing</li> <li>Rewinding</li> <li>Replication</li> <li>Syncing</li> </ul>"},{"location":"#where-to-start","title":"Where to Start","text":"<p>Read through the first few sections of this documentation, and we will walk you through how to get setup for development, then how to develop, build, and deploy your first plugin.</p> <p>Getting Started will show you how to setup the SDK. When you finish this section, you will have a full plugin development environment, and you will be ready to start building plugins.</p> <p>Building Your First Plugin will walk you step-by-step through the process of developing a very simple plugin. With it, you will learn the concepts and techniques that you will need to develop fully-fledged plugins. That does not mean this first plugin is useless\u2014you will be able to virtualize simple datasets with it.</p> <p>Once you complete these sections, use the rest of the documentation whenever you would like.</p>"},{"location":"#questions","title":"Questions?","text":"<p>If you have questions, bugs or feature requests reach out to us via the Virtualization SDK GitHub repository.</p>"},{"location":"Getting_Started/","title":"Getting Started","text":"<p>The Virtualization SDK is a Python package on PyPI. Install it in your local development environment so that you can build and upload a plugin.</p> <p>The SDK consists of three parts:</p> <ul> <li>The <code>dlpx.virtulization.platform</code> module</li> <li>The <code>dlpx.virtualization.libs</code> module</li> <li>A CLI</li> </ul> <p>The platform and libs modules expose objects and methods needed to develop a plugin. The CLI is used to build and upload a plugin.</p>"},{"location":"Getting_Started/#requirements","title":"Requirements","text":"<ul> <li>macOS 10.14+, Ubuntu 16.04+, or Windows 10</li> <li>Python 2.7 (vSDK 3.1.0 and earlier)</li> <li>Python 3.8 (vSDK 4.0.0 and later)</li> <li>Java 7+</li> <li>A Delphix Engine of an appropriate version</li> <li>An active internet connection to download packages from PyPI</li> </ul> <p>Use proxy server</p> <p>Pip recommends setting up a proxy server in case of restricted internet access. Please follow the guidelines from Pip on how to set up a proxy server.</p>"},{"location":"Getting_Started/#installation","title":"Installation","text":"<p>To install the latest version of the SDK run:</p> <pre><code>$ pip install dvp\n</code></pre> <p>Use a Virtual Environment</p> <p>We highly recommended that you develop plugins inside of a virtual environment. To learn more about virtual environments, refer to Virtualenv's documentation.</p> <p>If using vSDK 3.1.0 or earlier, the virtual environment needs to use Python 2.7.</p> <p>If using vSDK 4.0.0 or earlier, the virtual environment needs to use Python 3.8.</p> <p>This is configured when creating the virtualenv:</p> <p><code>$ virtualenv -p /path/to/python2.7/binary ENV</code> or <code>$ virtualenv -p /path/to/python3.8/binary ENV</code></p> <p>To install a specific version of the SDK run:</p> <pre><code>$ pip install dvp==&lt;version&gt;\n</code></pre> <p>To upgrade an existing installation of the SDK run:</p> <pre><code>$ pip install dvp --upgrade\n</code></pre> <p>API Build Version</p> <p>The version of the SDK defines the version of the Virtualization Platform API your plugin will be built against.</p>"},{"location":"Getting_Started/#basic-usage","title":"Basic Usage","text":"<p>Our CLI reference describes commands, provides examples, and a help section.</p> <p>To build your plugin:</p> <pre><code>$ dvp build -c &lt;plugin_config&gt; -a &lt;artifact_file&gt;\n</code></pre> <p>This will generate an upload artifact at <code>&lt;artifact_file&gt;</code>. That file can then be uploaded with:</p> <pre><code>$ dvp upload -e &lt;delphix_engine_address&gt; -u &lt;delphix_admin_user&gt; -a &lt;artifact_file&gt;\n</code></pre> <p>You will be prompted for the Delphix Engine user's password.</p> <p>You can also use a CLI Configuration File to set default values for CLI command options.</p>"},{"location":"Getting_Started/#questions","title":"Questions?","text":"<p>If you have questions, bugs or feature requests reach out to us via the Virtualization SDK GitHub repository.</p>"},{"location":"Best_Practices/CLI_Configuration_File/","title":"CLI Configuration File","text":"<p>The CLI configuration file can be used to set default values for CLI command options.</p>"},{"location":"Best_Practices/CLI_Configuration_File/#location","title":"Location","text":"<p>The configuration file is located in the user's home directory under <code>.dvp/config</code>.</p> <pre><code>&lt;USER_HOME&gt;\n    \u2514\u2500\u2500 .dvp\n        \u2514\u2500\u2500 config\n</code></pre> <p>Your user's home directory will depend on the operating system, but can be referred to using <code>~</code> in Unix-based operating systems or <code>%UserProfile%</code> in Windows.</p>"},{"location":"Best_Practices/CLI_Configuration_File/#supported-options","title":"Supported Options","text":"<p>Use <code>default</code> profile</p> <p>Only the values listed in the <code>default</code> profile are used unless they are overridden by values passed in from a command line option with the same name.</p> <p>The CLI configuration file supports the following options:</p>"},{"location":"Best_Practices/CLI_Configuration_File/#engine","title":"engine","text":"<p>Specifies the Delphix Engine which can be used as part of the dvp upload or dvp download-logs command.</p> <pre><code>engine = engine.example.com\n</code></pre>"},{"location":"Best_Practices/CLI_Configuration_File/#user","title":"user","text":"<p>Specifies the user to a Delphix Engine which is used as part of the dvp upload or dvp download-logs command.</p> <pre><code>user = admin\n</code></pre>"},{"location":"Best_Practices/CLI_Configuration_File/#password","title":"password","text":"<p>Specifies the password for the user to a Delphix Engine which is used as part of the dvp upload or dvp download-logs command.</p> <pre><code>password = userpassword\n</code></pre>"},{"location":"Best_Practices/CLI_Configuration_File/#example","title":"Example","text":"<p>The following example uses all of the supported options for the CLI configuration file: <pre><code>[default]\nengine = engine.example.com\nuser = admin\npassword = userpassword\n</code></pre></p>"},{"location":"Best_Practices/Code_Sharing/","title":"Code Sharing","text":"<p>All Python modules inside of <code>srcDir</code> can be imported just as they would be if the plugin was executing locally. When a plugin operation is executed <code>srcDir</code> is the current working directory so all imports need to be relative to <code>srcDir</code> regardless of the path of the module doing the import.</p> <p>Please refer to Python's documentation on modules to learn more about modules and imports.</p>"},{"location":"Best_Practices/Code_Sharing/#example","title":"Example","text":"<p>Assume we have the following file structure:</p> <pre><code>postgres\n\u251c\u2500\u2500 plugin_config.yml\n\u251c\u2500\u2500 schema.json\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 operations\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 discovery.py\n    \u251c\u2500\u2500 plugin_runner.py\n    \u251c\u2500\u2500 resources\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 execute_sql.sh\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 list_installs.sh\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 list_schemas.sql\n    \u2514\u2500\u2500 utils\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 execution_util.py\n</code></pre> <p>Any module in the plugin could import <code>execution_util.py</code> with <code>from utils import execution_util</code>.</p> <p>Gotcha</p> <p>When using a vSDK version that was built on Python 2.7, every directory needs to have an <code>__init__.py</code> file in it otherwise the modules and resources in the folder will not be found at runtime. For more information on <code>__init__.py</code> files refer to Python's documentation on packages.</p> <p>Note that the <code>srcDir</code> in the plugin config file (<code>src</code> in this example) does not need an <code>__init__.py</code> file.</p> <p>For information on which vSDK versions run on Python 2.7, visit the Version Compatibility Page.</p> <p>Assume <code>schema.json</code> contains:</p> <pre><code>{\n    \"repositoryDefinition\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": { \"type\": \"string\" }\n        },\n        \"nameField\": \"name\",\n        \"identityFields\": [\"name\"]\n    },\n    \"sourceConfigDefinition\": {\n        \"type\": \"object\",\n        \"required\": [\"name\"],\n        \"additionalProperties\": false,\n        \"properties\": {\n            \"name\": { \"type\": \"string\" }\n        },\n        \"nameField\": \"name\",\n        \"identityFields\": [\"name\"]\n    }\n}\n</code></pre> <p>To keep the code cleaner, this plugin does two things:</p> <ol> <li>Splits discovery logic into its own module: <code>discovery.py</code>.</li> <li>Uses two helper funtions <code>execute_sql</code> and <code>execute_shell</code> in <code>utils/execution_util.py</code> to abstract all remote execution.</li> </ol>"},{"location":"Best_Practices/Code_Sharing/#plugin_runnerpy","title":"plugin_runner.py","text":"<p>When the platform needs to execute a plugin operation, it always calls into the function decorated by the <code>entryPoint</code> object. The rest of the control flow is determined by the plugin. In order to split logic, the decorated function must delegate into the appropriate module. Below is an example of <code>plugin_runner.py</code> delegating into <code>discovery.py</code> to handle repository and source config discovery:</p> <pre><code>from operations import discovery\nfrom dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.discovery.repository()\ndef repository_discovery(source_connection):\nreturn discovery.find_installs(source_connection);\n@plugin.discovery.source_config()\ndef source_config_discovery(source_connection, repository):\nreturn discovery.find_schemas(source_connection, repository)\n</code></pre> <p>Note</p> <p><code>discovery.py</code> is in the <code>operations</code> package so it is imported with <code>from operations import discovery</code>.</p>"},{"location":"Best_Practices/Code_Sharing/#discoverypy","title":"discovery.py","text":"<p>In <code>discovery.py</code> the plugin delegates even further to split business logic away from remote execution. <code>utils/execution_util.py</code> deals with remote execution and error handling so <code>discovery.py</code> can focus on business logic. Note that <code>discovery.py</code> still needs to know the format of the return value from each script.</p> <pre><code>from dlpx.virtualization import libs\nfrom generated.definitions import RepositoryDefinition, SourceConfigDefinition\nfrom utils import execution_util\ndef find_installs(source_connection):\ninstalls = execution_util.execute_shell(source_connection, 'list_installs.sh')\n# Assume 'installs' is a comma separated list of the names of Postgres installations.\ninstall_names = installs.split(',')\nreturn [RepositoryDefinition(name=name) for name in install_names]\ndef find_schemas(source_connection, repository):\nschemas = execution_util.execute_sql(source_connection, repository.name, 'list_schemas.sql')\n# Assume 'schemas' is a comma separated list of the schema names.\nschema_names = schemas.split(',')\nreturn [SourceConfigDefinition(name=name) for name in schema_names]\n</code></pre> <p>Note</p> <p>Even though <code>discovery.py</code> is in the <code>operations</code> package, the import for <code>execution_util</code> is still relative to the <code>srcDir</code> specified in the plugin config file. <code>execution_util</code> is in the <code>utils</code> package so it is imported with <code>from utils import execution_util</code>.</p>"},{"location":"Best_Practices/Code_Sharing/#execution_utilpy","title":"execution_util.py","text":"<p><code>execution_util.py</code> has two methods <code>execute_sql</code> and <code>execute_shell</code>. <code>execute_sql</code> takes the name of a SQL script in <code>resources/</code> and executes it with <code>resources/execute_sql.sh</code>. <code>execute_shell</code> takes the name of a shell script in <code>resources/</code> and executes it.</p> <pre><code>from importlib import resources\nfrom dlpx.virtualization import libs\ndef execute_sql(source_connection, install_name, script_name):\npsql_script = resources.read_text(\"resources\", \"execute_sql.sh\")\nsql_script = resources.read_text(\"resources\", script_name)\nresult = libs.run_bash(\nsource_connection, psql_script, variables={\"SCRIPT\": sql_script}, check=True\n)\nreturn result.stdout\ndef execute_shell(source_connection, script_name):\nscript = resources.read_text(\"resources\", script_name)\nresult = libs.run_bash(source_connection, script, check=True)\nreturn result.stdout\n</code></pre> <p>Warning</p> <p>If developing a plugin in Python 2.7, you will need to use <code>pkgutil.get_data</code> rather than <code>importlib.resources.read_text</code>.</p> <p>See Managing Scripts For Remote Execution for more info.</p> <p>Note</p> <p>Both <code>execute_sql</code> and <code>execute_shell</code> use the <code>check</code> parameter which will cause an error to be raised if the exit code is non-zero. For more information refer to the <code>run_bash</code> documentation.</p>"},{"location":"Best_Practices/Managing_Scripts_For_Remote_Execution/","title":"Managing Scripts for Remote Execution","text":"<p>To execute a PowerShell or Bash script or Expect script on a remote host, you must provide the script as a string to <code>run_powershell</code> or <code>run_bash</code> or <code>run_expect</code>. While you can keep these strings as literals in your Python code, best practice is to keep them as resource files in your source directory and access them with <code>pkgutil</code> or <code>importlib</code>, depending on your plugin language.</p> <p>pkgutil is part of the standard Python library. The method that is applicable to resources is pkgutil.get_data.</p> <p>When developing a plugin in Python3, it is instead suggested to use the newer <code>importlib.resources</code>. This package is part of the standard Python 3 library. The method that is applicable to resources is resources.read_text, which accepts the same arguments as <code>pkgutil.get_data</code>.</p>"},{"location":"Best_Practices/Managing_Scripts_For_Remote_Execution/#basic-usage","title":"Basic Usage","text":"<p>Given the following plugin structure:</p> <pre><code>\u251c\u2500\u2500 plugin_config.yml\n\u251c\u2500\u2500 schema.json\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 plugin_runner.py\n    \u2514\u2500\u2500 resources\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 get_date.sh\n</code></pre> <p>Assume <code>SnapshotDefinition</code> is:</p> <pre><code>\"snapshotDefinition\": {\n    \"type\" : \"object\",\n    \"additionalProperties\" : false,\n    \"properties\" : {\n        \"name\": {\"type\": \"string\"},\n        \"date\": {\"type\": \"string\"}\n    }\n}\n</code></pre> <p>and <code>src/resources/get_date.sh</code> contains:</p> <pre><code>#!/usr/bin/env bash\ndate\n</code></pre> <p>If <code>get_date.sh</code> is needed in <code>post_snapshot</code>, it can be retrieved and executed:</p> <pre><code>import pkgutil\nfrom dlpx.virtualization import libs\nfrom dlpx.virtualization.platform import Plugin\nfrom dlpx.virtualization.platform.exceptions import UserError\nfrom generated.definitions import SnapshotDefinition\nplugin = Plugin()\n@plugin.linked.post_snapshot()\ndef post_snapshot(direct_source, repository, source_config):\n# Retrieve script contents\nscript_content = pkgutil.get_data('resources', 'get_date.sh')\n# Execute script on remote host\nresponse = libs.run_bash(direct_source.connection, script_content)\n# Fail operation if the timestamp couldn't be retrieved\nif response.exit_code != 0:\nraise UserError(\n'Failed to get date',\n'Make sure the user has the required permissions',\n'{}\\n{}'.format(response.stdout, response.stderr))\nreturn SnapshotDefinition(name='Snapshot', date=response.stdout)\n</code></pre> <p>Python's Working Directory</p> <p>This assumes that <code>src/</code> is Python's current working directory. This is the behavior of the Virtualization Platform.</p> <p>Resources need to be in a Python module</p> <p><code>pkgutil.get_data</code> cannot retrieve the contents of a resource that is not in a Python package. When developing with Python 2.7, this means that a resource that is in the first level of your source directory will not be retrievable with <code>pkgutil</code>. Resources must be in a subdirectory of your source directory, and that subdirectory must contain an <code>__init__.py</code> file.</p> <p>Python 3 does not have this requirement.</p>"},{"location":"Best_Practices/Managing_Scripts_For_Remote_Execution/#multi-level-packages","title":"Multi-level Packages","text":"<p>Given the following plugin structure:</p> <pre><code>\u251c\u2500\u2500 plugin_config.yml\n\u251c\u2500\u2500 schema.json\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 plugin_runner.py\n    \u2514\u2500\u2500 resources\n        \u251c\u2500\u2500 __init__.py\n        \u251c\u2500\u2500 database\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 execute_sql.sh\n        \u2514\u2500\u2500 platform\n            \u251c\u2500\u2500 __init__.py\n            \u2514\u2500\u2500 get_date.sh\n</code></pre> <p>The contents of <code>src/resources/platform/get_date.sh</code> can be retrieved with:</p> <pre><code>script_content = pkgutil.get_data('resources.platform', 'get_date.sh')\n</code></pre> <p>In a Python 3.8 plugin, the suggested approach is:</p> <pre><code>script_content = resources.read_text('resources.platform', 'get_date.sh')\n</code></pre>"},{"location":"Best_Practices/Message_Limits/","title":"Message Limits","text":"<p>There are limits on how much data can be sent back and forth between the plugin and engine at a time. There are five scenarios where this comes into play:</p> <ol> <li> <p>Inputs sent from the engine to the plugin, as arguments to a Plugin Operation. For example, the schema-defined <code>Repository</code> object that is provided as input to plugin operations.</p> </li> <li> <p>Outputs sent back from the plugin to the engine, as the return values from plugin operations.</p> </li> <li> <p>Exception messages and call stacks thrown by plugin code. For example, the <code>message</code> field within User Visible Errors.</p> </li> <li> <p>Inputs sent from the plugin to the engine, as arguments to a Platform library function. For example, the <code>message</code> field that is passed to <code>logger.debug</code>.</p> </li> <li> <p>Outputs sent back from the engine to the plugin, as the return values from Platform Library functions. For example, the <code>stdout</code> resulting from a call to <code>libs.run_bash</code>.</p> </li> </ol> <p>For case 1 and 2, the total size of data must be less than 4 mebibytes (4 MiB).</p> <p>For case 3, the total size of data must be less than 128 kibibytes (128 KiB).</p> <p>For case 4 and 5, the total size of data must be less than 192 mebibytes (192 MiB).</p> <p>The actual size of this information at runtime is dependent on how the Python interpreter chooses to represent the information, so it's not always possible to know ahead of time what the exact size will be.</p> <p>Here are some examples of where problems may occur:</p> <ol> <li> <p>Using <code>libs.run_bash</code> to print the entire contents of a large file to stdout.</p> </li> <li> <p>Using a single <code>logger</code> command with many pages of output.</p> </li> <li> <p>Throwing an exception with a large message or stack trace.</p> </li> <li> <p>Large amount of metadata in a plugin defined schema like <code>Repository</code> or <code>Virtual Source</code>.</p> </li> </ol>"},{"location":"Best_Practices/Message_Limits/#how-to-tell-if-the-message-size-was-exceeded","title":"How to tell if the message size was exceeded","text":"<p>The plugin operation or platform library callback will fail with a RPC error. The exception will look like:</p> <pre><code>Error\nDiscovery of \"my_plugin\" failed: Plugin operation \"Repository Discovery\" got a RPC error for plugin \"my_plugin\". UNAVAILABLE: Network closed for unknown reason\n</code></pre>"},{"location":"Best_Practices/Message_Limits/#what-to-do-if-the-maximum-metadata-or-message-size-is-exceeded","title":"What to do if the maximum metadata or message size is exceeded","text":"<p>Reach out to us via the Virtualization SDK GitHub repository for guidance.</p>"},{"location":"Best_Practices/Runtime_Environment/","title":"Plugin Runtime Environment","text":""},{"location":"Best_Practices/Runtime_Environment/#process-lifetime","title":"Process Lifetime","text":"<p>Plugin code runs inside of a Python interpreter process on the Delphix Engine.</p> <p>A fair question to ask is \"What is the lifetime of this interpreter process?\"  After all, if the interpreter process runs for a long time, then the plugin might be able to store things in memory for later access.</p> <p>Unfortunately, there are no guarantees about process lifetime. Your interpreter process could last two years, or it could last 400 microseconds. There is no way to know or predict this ahead of time.</p> <p>So, do not make any assumptions about interpreter process lifetime in your plugin code.</p>"},{"location":"Best_Practices/Runtime_Environment/#available-modules","title":"Available Modules","text":"<p>Our Python 2.7 runtime environment only contains the Python Standard Library. No additional Python modules/libraries are available.</p> <p>If you want to use some Python module that is not part of the standard library, you might be able to do so. You would need to include that library as part of your plugin. That would involve downloading the source code for that module, and copying it into your source directory. For more information on how to lay out code in your source directory, see Code Sharing.</p>"},{"location":"Best_Practices/Runtime_Environment/#warnings","title":"Warnings","text":"<p>There are two major things to watch out for if you decide to incorporate a 3rd-party library.</p> <p>1) Make sure you're legally allowed to do so! The licensing agreement on the module will decide if, and under what circumstances, you're allowed to make copies of, and redistribute the module. Some modules will allow this, some will disallow this, and some will allow this for a fee.</p> <p>2) Some Python libraries include native code (often written in C or C++). There is no support for using such libraries with plugin code.  The reason for this is that native code needs to be specially compiled and built for the machine that it the library will be running on. And, unfortunately, the machine your plugin runs on (the Delphix Engine) is likely very different from the machine you use to develop and build your plugin.</p>"},{"location":"Best_Practices/Runtime_Environment/#network-access","title":"Network Access","text":"<p>As of Delphix Engine version 6.0.11.0, plugin code is able to use the network directly. No network access is possible in earlier versions.</p> <p>For example, suppose your plugin wants to talk to some DBMS running on some remote host. If the DBMS supports it, your plugin code might be able to connect to the DBMS server and talk to the DBMS directly. This can avoid the need to do DBMS operations via running Bash/Powershell code on the remote host.</p>"},{"location":"Best_Practices/Runtime_Environment/#example","title":"Example","text":"<pre><code>import httplib\nimport json\ndbms_port = 5432\n# Directly contact our DBMS's REST server to get a list of databases\ndef list_databases(remote_ip):\ncx = httplib.HTTPConnection(remote_ip, dbms_port)\ncx.request(\"GET\", \"/databases\")\nresponse = cx.getresponse()\nreturn json.loads(response.read())\n</code></pre> <p>What your plugin can access depends entirely on the customer. Some customers will set up their Delphix Engines such that plugins have full access to the entire internet. Some will completely restrict the network so that the plugin can only access a small handful of remote hosts.</p> <p>If your plugin has any specific network requirements, it's recommended to try, in your code, to confirm that these requirements are met. For example, the plugin could make such a check in the <code>discovery.repository()</code> operation, and throw an error if the check fails. Like any other requirement, this should of course be documented.</p>"},{"location":"Best_Practices/Scratch_Paths/","title":"Scratch Paths","text":"<p>A scratch path is a directory reserved for plugin use on each remote host. This is intended for uses such as:</p> <ul> <li>Storage of small amounts of persistent data</li> <li>A place to mount VDB data</li> <li>Temporary logs for debugging (Be careful that you don't use too much space though!)</li> </ul> <p>The location of this scratch area is given by the <code>scratch_path</code> property on the RemoteHost object.</p> <p>Things to note about the scratch path:</p> <ul> <li>No guarantees are made about where the path is located on the system.</li> <li>No guarantees are made about how much space might be available in this directory. It is strongly advised that you use only a small amount of disk space here.</li> <li>The directory will be owned by the \"primary user\" associated with the remote host. This might be a completely different user from the one that is associated with a particular dsource or VDB.</li> <li>If you need to store dSource- or VDB-specific data, it is highly recommended that you create a separate subdirectory for each dSource/VDB inside this scratch area. It's also recommended to name this subdirectory using the GUID of the dSource/VDB, so that you avoid accidental name collisions.</li> <li>The Delphix Engine will not do any cleanup for you, so be sure to delete anything you're no longer using. For example, any VDB-specific information must be deleted in your unconfigure operation (and dSource data gets deleted in your stopStaging operation.)</li> <li>Do not store any sensitive information here!</li> </ul>"},{"location":"Best_Practices/Sensitive_Data/","title":"Dealing With Sensitive Data","text":"<p>Often, a plugin will need to handle sensitive user-provided data. The most common example of this is a database password.</p> <p>Plugins must be careful to handle sensitive data appropriately. Three tips for handling sensitive data are:</p> <ol> <li>Tell the Delphix Engine which parts of your data are sensitive.</li> <li>When passing sensitive data to remote plugin library functions (such as <code>run_bash</code>), use environment variables.</li> <li>Avoid logging, or otherwise writing out the sensitive data.</li> </ol> <p>Each of these tips are explained below.</p>"},{"location":"Best_Practices/Sensitive_Data/#marking-your-data-as-sensitive","title":"Marking Your Data As Sensitive","text":"<p>Because the Delphix Engine manages the storing and retrieving of plugin-defined data, it needs to know which pieces of data are sensitive. The plugin does this in its schemas, by using the special <code>password</code> keyword.</p> <p>The following example of a schema defines an object with three properties, one of which is sensitive and tagged with the <code>password</code> keyword:</p> <pre><code>{\n\"type\": \"object\",\n\"properties\": {\n\"db_connectionPort\": {\"type\": \"string\"},\n\"db_username\": {\"type\": \"string\"},\n\"db_password\": {\"type\": \"string\", \"format\": \"password\"}\n}\n}\n</code></pre> <p>This tells the Delphix Engine to take special precautions with this password property, as follows:</p> <ol> <li>The Delphix Engine will encrypt the password before storing it, and decrypt it only as necessary to pass back to the plugin.</li> <li>The Delphix Engine will not write this password anywhere (for example, it will not appear in any system logs).</li> <li>The Delphix Engine's UI and CLI will not display the password.</li> <li>Clients of the Delphix Engine's public API will not be able to access the password.</li> </ol> <p>Note</p> <p>Removing a previously added password property from a field and running a Data Migration will expose the password in plaintext. If this is intentional, write a migration to ensure that the new property conforms to the new schema.</p>"},{"location":"Best_Practices/Sensitive_Data/#protecting-sensitive-data-with-password-vaults","title":"Protecting Sensitive Data with Password Vaults","text":"<p>Plugins can also leverage the password vaults configured in the Delphix engine to avoid storing sensitive data in the engine itself. In addition, vaults can rotate secrets seamlessly behind the scenes without requiring Delphix users to update those secrets in the engine. To give users the option to choose between directly entering a secret, such as a password or private key, or retrieving it from a vault, Delphix provides pre-defined credential types.</p> <p>When using these special types, the example above becomes:</p> <pre><code>{\n\"type\": \"object\",\n\"properties\": {\n\"db_connectionPort\": {\"type\": \"string\"},\n\"db_credentials_supplier\": {\n\"$ref\": \"https://delphix.com/platform/api#/definitions/passwordCredentialsSupplier\"\n}\n}\n}\n</code></pre> <p>For details on how the user can provide the information required for a property such as <code>db_credentials_supplier</code>, see the section on pre-defined types.</p> <p>At runtime, the plugin code must convert the credentials information provided by the user into an actual set of credentials that the plugin can use. To do this, the plugin must call the library function <code>retrieve_credentials</code>. For example:</p> <pre><code>from dlpx.virtualization import libs\nfrom dlpx.virtualization.common import PasswordCredentials\n...\n@plugin.virtual.stop()\ndef my_virtual_stop(virtual_source, repository, source_config):\ncredentials = libs.retrieve_credentials(virtual_source.parameters.db_credentials_supplier)\nassert isinstance(credentials, PasswordCredentials)\nconnect_to_dbms(credentials.username, credentials.password)\n</code></pre>"},{"location":"Best_Practices/Sensitive_Data/#using-environment-variables-for-remote-data-passing","title":"Using Environment Variables For Remote Data Passing","text":"<p>Sometimes, a plugin will need to pass sensitive data to a remote environment. For example, perhaps a database command needs to be run on a staging environment, and that database command will need to use a password.</p>"},{"location":"Best_Practices/Sensitive_Data/#example","title":"Example","text":"<p>Let us take a look at a very simple example where we need to shutdown a database called \"inventory\" on a target environment by using the <code>db_cmd shutdown inventory</code> command. This command will ask for a password on <code>stdin</code>, and for our example our password is \"hunter2\".</p> <p>If we were running this command by hand, it might look like this: <pre><code>$ db_cmd shutdown inventory\nConnecting to database instance...\nPlease enter database password:\n</code></pre></p> <p>At this point, we would type in \"hunter2\", and the command would proceed to shut down the database.</p> <p>Since a plugin cannot type in the password by hand, it will do something like this instead:</p> <pre><code>$ echo \"hunter2\" | db_cmd shutdown inventory\n</code></pre>"},{"location":"Best_Practices/Sensitive_Data/#dont-do-this","title":"Don't Do This","text":"<p>First, let us take a look at how not to do this! Here is a bit of plugin python code that will run the above command.</p> <pre><code>from dlpx.virtualization import libs\nfrom dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.stop()\ndef my_virtual_stop(virtual_source, repository, source_config):\n# THIS IS INSECURE! DO NOT DO THIS!\nfull_command = \"echo {} | db_cmd shutdown {}\".format(password, db_name)\nlibs.run_bash(virtual_source.connection, full_command)\n</code></pre> <p>This constructs a Python string containing exactly the desired command from above. However, this is not recommended.</p> <p>The problem here is that there is a cleartext password in the Python string. But, this Python string is not treated as sensitive by the Virtualization Platform. For example, suppose the Virtualization Platform cannot make a connection to the target environment. In which case, it will raise an error containing the Python string, so that people will know what command failed. But, in our example, that would result in the password being part of the cleartext error message.</p>"},{"location":"Best_Practices/Sensitive_Data/#using-environment-variables","title":"Using Environment Variables","text":"<p>The Delphix Engine provides a better way to pass sensitive data to remote bash (or powershell) calls: environment variables. Let us look at a different way to run the same command as above.</p> <pre><code>from dlpx.virtualization import libs\nfrom dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.stop()\n# Use environment variables to pass sensitive data to remote commands\nenvironment_vars = {\n\"DATABASE_PASSWORD\" : password\n}\nfull_command = \"echo $DATABASE_PASSWORD | db_cmd shutdown {}\".format(db_name)\nlibs.run_bash(virtual_source.connection, full_command, variables=environment_vars)\n</code></pre> <p>Note</p> <p>We are no longer putting the cleartext password into the Python command string. Instead, we are instructing the Virtualization Platform to put the password into an environment variable on the target environment. The Python command string merely mentions the name of the environment variable, and does not contain the password itself.</p> <p>Once the command runs on the target environment, Bash will substitute in the password, and the database shutdown will run as expected.</p> <p>Unlike with the command string, the Virtualization Platform does treat environment variables as sensitive information, and will not include them in error messages or internal logs, etc.</p>"},{"location":"Best_Practices/Sensitive_Data/#dont-write-out-sensitive-data","title":"Don't Write Out Sensitive Data","text":"<p>Plugin writers are strongly advised to never write out unencrypted sensitive data. This is common-sense general advice that applies to all areas of programming, not just for plugins. However, there are a couple of special concerns for plugins.</p> <p>The Virtualization Platform provides logging capabilities to plugins. The generated logs are unencrypted and not treated as sensitive. Therefore, it is important for plugins to never log sensitive data.</p> <p>In addition, remember that your plugin is not treated as sensitive by the Virtualization Platform. Plugin code is distributed unencrypted, and is viewable in cleartext by Delphix Engine users. Sensitive data such as passwords should never be hard-coded in your plugin code.</p>"},{"location":"Best_Practices/Strings/","title":"Working With Strings","text":"<p>Unfortunately, Python 2.7 makes it very easy to accidentally write string-related code that will sometimes work, but sometimes fail (especially for people who are not using English). Read on for some tips for how to avoid this.</p>"},{"location":"Best_Practices/Strings/#the-two-string-types","title":"The Two String Types","text":"<p>Python 2.7 has two different types that are both called \"strings\". One represents a sequence of bytes, and the other represents a sequence of characters.</p> <pre><code># The default string (aka 'str object') represents bytes\nmy_bytes = \"This string is a sequence of bytes\"\n# A 'Unicode object' represents characters (note the u just before the quote)\nmy_characters = u\"This string is a sequence of characters\"\n</code></pre>"},{"location":"Best_Practices/Strings/#unicode-strings-are-preferred","title":"Unicode Strings Are Preferred","text":"<p>There are a couple of reasons to prefer the \"unicode object\" over the \"str object\".</p> <p>First, in most cases, we care about characters, and we're not particularly interested in which bytes are used to represent those characters.  That is, we might care that we have a \"letter H\" followed by a \"letter I\", but it's usually irrelevant to us what byte values happen to be used.</p> <p>Second, there are lots of different schemes available which give rules for how to represent characters as bytes. These schemes are called \"encodings\"; some examples include \"ASCII\", \"UTF-8\", \"Shift-JIS\", and \"UCS-2\".  Each encoding uses different rules about which characters are represented by which bytes.</p> <p>A \"str object\" doesn't know anything about encodings... it is just a sequence of bytes. So, when a programmer is working with one of these byte strings, they have to know which encoding rules are in play.</p> <p>In order to avoid problems, we recommend using Unicode strings everywhere in your plugin code.</p>"},{"location":"Best_Practices/Strings/#delphix-io","title":"Delphix I/O","text":"<p>Your plugin will sometimes need to send strings back and forth to Delphix code. There are two supported formats for doing this.  Any time you receive a string from Delphix, it will be in one of the two following forms. This includes arguments to your plugin operations, and return values from \"Delphix Libs\" functions. Likewise, any time you send a string to Delphix, it must be in one of these two forms.</p> <p>Acceptable forms:</p> <ol> <li>A Unicode string (recommended)</li> <li>A \"str object\" (byte string) that uses the UTF-8 encoding</li> </ol>"},{"location":"Best_Practices/Strings/#converting-between-types","title":"Converting Between Types","text":"<p>Sometimes (hopefully rarely!), you might find yourself needing to convert back and forth between byte strings and character strings. For example, you might need to read or write a file on a remote system that is required to use some specific encoding. Here's how to do that:</p> <pre><code># Converting from a character string (\"unicode\") to a byte string (\"str\")\nmy_utf8_byte_string = my_character_string.encode(\"utf-8\")\nmy_utf16_byte_string = my_character_string.encode(\"utf-16\")\n# Converting from a byte string to a character string\nmy_character_string1 = my_utf8_byte_string.decode(\"utf-8\")\nmy_character_string2 = my_utf16_byte_string.decode(\"utf-16\")\nmy_character_string3 = my_ascii_byte_string.decode(\"ascii\")\n</code></pre> <p>Things to note:</p> <ul> <li><code>encode</code> goes from characters to bytes. <code>decode</code> goes from bytes to characters.</li> <li>If you try to <code>encode</code> a character string using the <code>ascii</code> encoding, but your character string contains non-ascii characters, you'll get an error. More generally: some encodings will error out with some characters.</li> <li>If you don't specify an encoding, Python will supply a default. But, there's a good chance the default will be wrong for your use case. So, always specify the encoding!</li> <li>Don't try to <code>encode</code> a byte string. If you do this, Python will \"helpfully\" insert an implicit <code>decode</code> first, which tends to cause very confusing error messages. Likewise, don't try to <code>decode</code> a character string.</li> <li><code>utf-8</code> is likely the best encoding to use for most situations. It accepts all characters, does not have issues with byte ordering, and is understood by most systems. This is not true of most other encodings.</li> </ul>"},{"location":"Best_Practices/Strings/#using-non-ascii-characters-in-python-files","title":"Using Non-ASCII characters in Python files","text":"<p>Python 2.7 source code files are assumed to use the \"ASCII\" encoding, unless told otherwise. Unfortunately, ASCII is an obsolete encoding that only knows how to deal with a small number of characters, and only really supports American English.</p> <p>In order to include non-ASCII characters in your source code, you need to use a different encoding than ASCII, and you need to tell the Python interpreter which encoding you're using.  In Python 2.7, this is done with a \"magic\" comment at the very top of each file.</p> <p>Here is an example of the first line of a Python file that uses the UTF-8 encoding: <pre><code># -*- coding: utf-8 -*-\n</code></pre></p> <p>If you do not specify an encoding, and the source code contains any non-ASCII characters, you will get errors  when building the plugin using dvp build or during the execution of a plugin operation.</p>"},{"location":"Best_Practices/Strings/#example","title":"Example","text":"<pre><code># -*- coding: utf-8 -*-\nfrom dlpx.virtualization.platform import Plugin\nfrom dlpx.virtualization import libs\nfrom generated.definitions import RepositoryDefinition\nplugin = Plugin()\n@plugin.discovery.repository()\ndef repository_discovery(source_connection):\n# Create a repository with name that uses non-ASCII characters\nreturn [RepositoryDefinition(name=u\"Th\u00e9\u00e2tre\")]\n</code></pre>"},{"location":"Best_Practices/User_Visible_Errors/","title":"User Visible Errors","text":"<p>Plugin authors can choose to fail a plugin operation by raising an exception of type <code>UserError</code> with a custom message, action and output for the end user.</p>"},{"location":"Best_Practices/User_Visible_Errors/#fields","title":"Fields","text":"Field Type Description message String Description of the failure to show the end user. action String Optional. List of actions that the end user could take to fix the problem. If not provided, it defaults to <code>Contact the plugin author to correct the error.</code> output String Optional. Output or stack trace from the failure to give the end user more information so that they can self diagnose. If not provided, it defaults to the stack trace of the failure. <p>Warning</p> <p>There is a limit to how much data can be stored within the fields of a <code>UserError</code>. See Message Limits for details.</p>"},{"location":"Best_Practices/User_Visible_Errors/#example","title":"Example","text":"<pre><code>from importlib import resources\nfrom dlpx.virtualization.platform import Plugin\nfrom generated.definitions import SourceConfigDefinition\nfrom dlpx.virtualization.platform.exceptions import UserError\nplugin = Plugin()\n@plugin.virtual.start()\ndef start(virtual_source, repository, source_config):\nscript_content = resources.read_text('resources', 'start_database.sh')\nresponse = libs.run_bash(virtual_source.connection, script_content)\n# Fail operation if the database could not be started\nif response.exit_code != 0:\nraise UserError(\n'Failed to start the database',\n'Make sure the user has appropriate permissions',\n'{}\\n{}'.format(response.stdout, response.stderr))\n</code></pre> <p>Warning</p> <p>If developing a plugin in Python 2.7, you will need to use <code>pkgutil.get_data</code> rather than <code>importlib.resources.read_text</code>.</p> <p>See Managing Scripts For Remote Execution for more info.</p> <p>The UI would show the end user if the plugin operation above fails:</p> <p></p>"},{"location":"Best_Practices/Working_with_Powershell/","title":"Working with Powershell","text":""},{"location":"Best_Practices/Working_with_Powershell/#error-handling-in-powershell","title":"Error handling in Powershell","text":"<p>Info</p> <p>Commands run via run_powershell are executed as a script. The exit code returned by run_powershell as part of the RunPowershellResult is determined by the exit code from the script.</p> <p>PowerShell gives you a few ways to handle errors in your scripts:</p> <ol> <li> <p>Set $ErrorActionPreference. This only applies to PowerShell Cmdlets. For scripts or other executables such as sqlcmd, PowerShell will return with exit code 0 even if there is an error, regardless of the value of $ErrorActionPrefe       rence. The allowable values for $ErrorActionPreference are:</p> <p>Continue (default) \u2013 Continue even if there is an error.                             SilentlyContinue \u2013 Acts like Continue with the exception that errors are not displayed            Inquire \u2013 Prompts the user in case of error             Stop -  Stops execution after the first error</p> </li> <li> <p>Use exception handling by using traps and try/catch blocks or if statements to detect errors and return with non-zero exit codes</p> </li> <li> <p>Use custom error handling that can be invoked after launching each command in the script to correctly detect errors. </p> </li> </ol>"},{"location":"Best_Practices/Working_with_Powershell/#examples","title":"Examples","text":"<p>The following example will show you how setting $ErrorActionPreference will return exit codes</p> <p>In the below code, <code>ls nothing123</code> is expected to fail.</p> <pre><code>ls nothing123\nWrite-Host \"Test\"\n</code></pre> <p>Here is the output when the above commands runs  on a remote host and the script will return the value of <code>$?</code> to be True eventhough the script failed.</p> <p>```PS C:\\Users\\dtully\\test&gt; ./test1.ps1 ls : Cannot find path 'C:\\Users\\dtully\\test\\nothing123' because it does not exist. At C:\\Users\\dtully\\test\\test1.ps1:1 char:1 + ls nothing123 + ~~~~~~~~~~~~~     + CategoryInfo          : ObjectNotFound: (C:\\Users\\dtully\\test\\nothing123:String) [Get-ChildItem], ItemNotFoundEx    ception     + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.GetChildItemCommand</p> <p>PS C:\\Users\\dtully\\test&gt; Write-Host $? True <pre><code>Now lets set $ErrorActionPreference=Stop.\n\n```Windows\n$ErrorActionPreference = \"Stop\"\nls nothing123\nWrite-Host \"Test\"\n</code></pre> Now when we run the command again we see the return value of <code>$?</code> to be False.</p> <pre><code>PS C:\\Users\\dtully\\test&gt; ./test1.ps1\nls : Cannot find path 'C:\\Users\\dtully\\test\\nothing123' because it does not exist.\nAt C:\\Users\\dtully\\test\\test1.ps1:2 char:1\n+ ls nothing123\n+ ~~~~~~~~~~~~~\n    + CategoryInfo          : ObjectNotFound: (C:\\Users\\dtully\\test\\nothing123:String) [Get-ChildItem], ItemNotFoundException\n    + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.GetChildItemCommand\n\nPS C:\\Users\\dtully\\test&gt; Write-Host $?\nFalse\n</code></pre> <p>The following example shows how you can use the function verifySuccess to detect whether the previous command failed, and if it did print, print an error message and return with an exit code of 1.</p> <pre><code>function die {\n    Write-Error \"Error: $($args[0])\"\n    exit 1\n}\n\nfunction verifySuccess {\n    if (!$?) {\n        die \"$($args[0])\"\n    }\n}\n\nWrite-Output \"I'd rather be in Hawaii\"\nverifySuccess \"WRITE_OUTPUT_FAILED\"\n\n&amp; C:\\Program Files\\Delphix\\scripts\\myscript.ps1\nverifySuccess \"MY_SCRIPT_FAILED\"\n</code></pre>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/","title":"Data Ingestion","text":""},{"location":"Building_Your_First_Plugin/Data_Ingestion/#how-does-delphix-ingest-data","title":"How Does Delphix Ingest Data?","text":"<p>As previously discussed, the Delphix Engine uses the discovery process to learn about datasets that live on a source environment. In this section we will learn how the Delphix Engine uses a two-step process to ingest a dataset.</p>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/#linking","title":"Linking","text":"<p>The first step is called linking. This is simply the creation of a new dataset on the Delphix Engine, which is associated with the dataset on the source environment. This new linked dataset is called a dSource.</p>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/#syncing","title":"Syncing","text":"<p>Immediately after linking, the new dSource is synced for the first time. Syncing is a process by which data from the source environment is copied onto the Delphix Engine. Subsequent syncs may then be periodically performed in order to keep the dSource up-to-date.</p> <p>The details of how this is done varies significantly from plugin to plugin. For example, some plugins will simply copy files from the filesystem. Other plugins might contact a DBMS and instruct it to send backup or replication streams. There are many possibilities here, but they all break down into two main strategies that the plugin author can choose from: direct and staging.</p> <p>With the direct strategy, the plugin is not in charge of the data copying. Instead the Delphix Engine directly pulls raw data from the source environment. The plugin merely provides the location of the data. This is a very simple strategy, and is also quite limiting.</p> <p>For our first plugin, we will be using the more flexible staging strategy. With this strategy, the Delphix Engine uses NFS for Unix environments (or iSCSI on Windows environments) to mount storage onto a staging environment. Our plugin will then be in full control of how to get data from the source environment onto this storage mount.</p> <p>With the staging strategy, there are two types of syncs: sync and resync. A <code>sync</code> is used to ingest incremental changes while a <code>resync</code> is used to re-ingest all the data for the dSource. For databases, this could mean re-ingesting from a full database backup to reset the dSource. A <code>sync</code> and a <code>resync</code> will execute the same plugin operations. To differentiate a <code>sync</code> from a <code>resync</code>, simply add a boolean property (i.e. <code>resync</code>) in the plugin's snapshot parameters definition. Once <code>sync</code> or <code>resync</code> is selected, the property will be passed into linked.pre_snapshot and linked.post_snapshot as a snapshot parameter.</p> <p>A regular <code>sync</code> is the default and is executed as part of policy driven syncs. A <code>resync</code> is only executed during initial ingestion or if the Delphix user manually starts one. The customer can manually trigger a <code>resync</code> via the UI by selecting the dSource, going to more options and selecting Resynchronize dSource. </p> <p>Gotcha</p> <p>Although it is not common, it is entirely possible that the staging environment is the same as the source environment. Be careful not to assume otherwise in your plugins.</p>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/#our-syncing-strategy","title":"Our Syncing Strategy","text":"<p>For our purposes here in this intro plugin, we will use a simple strategy. We won't do anything with the resync snapshot parameter and simply copy files from the filesystem on the source environment onto the NFS mount on the staging environment. We will do this by running the Unix tool <code>rsync</code> from our staging environment, and rely on passwordless SSH to connect to the source environment.</p> <p>Info</p> <p>This plugin is assuming that <code>rsync</code> is installed on the staging host, and that the staging host user is able to SSH into the source host without having to type in a password. A more full-featured plugin would test these assumptions, usually as part of discovery.</p> <p>In the special case mentioned above, where the staging environment is the same as the source environment, we could likely do something more efficient. However, for simplicity's sake, we won't do that here.</p>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/#defining-your-linked-source-data-format","title":"Defining Your Linked Source Data Format","text":"<p>In order to be able to successfully do the copying required, plugins might need to get some information from the end-user of your plugin. In our case, we need to tell <code>rsync</code> how to access the files. This means we need to know the source environment's IP address (or domain name), the username we need to connect as, and finally the location where the files live.</p> <p>Again, we will be using a JSON schema to define the data format. The user will be presented with a UI that lets them provide all the information our schema specifies.</p> <p>Open up <code>schema.json</code> in your editor/IDE. Locate the <code>LinkedSourceDefinition</code> and replace it with the following schema: <pre><code>\"linkedSourceDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"required\": [\"sourceAddress\", \"username\", \"mountLocation\"],\n\"properties\": {\n\"sourceAddress\": {\n\"type\": \"string\",\n\"prettyName\": \"Host from which to copy\",\n\"description\": \"IP or FQDN of host from which to copy\"\n},\n\"username\": {\n\"type\": \"string\",\n\"prettyName\": \"Username on Source Host\",\n\"description\": \"Username for making SSH connection to source host\"\n},\n\"mountLocation\": {\n\"type\": \"string\",\n\"format\": \"unixpath\",\n\"prettyName\": \"Mount Location on Staging Host\",\n\"description\": \"Where to mount storage onto the staging host while syncing\"\n}\n}\n},\n</code></pre></p> <p>Info</p> <p>As will be explained later, this schema will be used to generate Python code. All names in the autogenerated Python code will use <code>lower_case_with_underscores</code> as attribute names as per Python variable naming conventions. That is, if we were to use <code>mountLocation</code> as the schema property name, it would be called <code>mount_location</code> in the generated Python code.</p> <p>With this schema, the user will be required to provide the source username, the source's IP address, and the staging mount location as part of the linking process.</p>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/#implementing-syncing-in-your-plugin","title":"Implementing Syncing in Your Plugin","text":"<p>There are three things we must do to implement syncing. First, we need to tell the Delphix Engine where to mount storage onto the staging environment. Next we need to actually do the work of copying data onto that mounted storage. Finally, we need to generate any snapshot-related data.</p>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/#mount-specification","title":"Mount Specification","text":"<p>Before syncing can begin, the Delphix Engine needs to mount some storage onto the staging host. Since different plugins can have different requirements about where exactly this mount lives, it is up to the plugin to specify this location. As mentioned above, our simple plugin will get this location from the user.</p> <p>Open up the <code>plugin_runner.py</code> file and find the <code>linked_mount_specification</code> function (which was generated by <code>dvp init</code>). Replace it with the following code: <pre><code>@plugin.linked.mount_specification()\ndef linked_mount_specification(staged_source, repository):\n    mount_location = staged_source.parameters.mount_location\n    mount = Mount(staged_source.staged_connection.environment, mount_location)\n    return MountSpecification([mount])\n</code></pre></p> <p>Let's take this line-by-line to see what's going on here.</p> <p><pre><code>@plugin.linked.mount_specification()\n</code></pre> This decorator announces that the following function is the code that handles the <code>mount_specification</code> operation. This is what allows the Delphix Engine to know which function to call when it's time to learn where to mount. Every operation definition will begin with a similar decorator.</p> <p><pre><code>def linked_mount_specification(staged_source, repository):\n</code></pre> This begins a Python function definition. We chose to call it <code>linked_mount_specification</code>, but we could have chosen any name at all. This function accepts two arguments, one giving information about the linked source, and one giving information about the associated repository.</p> <pre><code>    mount_location = staged_source.parameters.mount_location\n</code></pre> <p>The <code>staged_source</code> input argument contains an attribute called <code>parameters</code>. This in turn contains all of the properties defined by the <code>linkedSourceDefinition</code> schema. So, in our case, that means it will contain attributes called <code>source_address</code>, <code>username</code>, and <code>mount_location</code>. Note how any attribute defined in <code>camelCase</code> in the schema is converted to <code>variable_with_underscores</code>. This line simply retrieves the user-provided mount location and saves it in a local variable.</p> <pre><code>    mount = Mount(staged_source.staged_connection.environment, mount_location)\n</code></pre> <p>This line constructs a new object from the Mount class. This class holds details about how Delphix Engine storage is mounted onto remote environments. Here, we create a mount object that says to mount onto the staging environment, at the location specified by the user.</p> <pre><code>    return MountSpecification([mount])\n</code></pre> <p>On the line just before this one, we created an object that describes a single mount. Now, we must return a full mount specification. In general, a mount specification is a collection of mounts. But, in our case, we just have one single mount. Therefore, we use an array with only one item it in -- namely, the one single mount object we created just above.</p>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/#data-copying","title":"Data Copying","text":"<p>As explained here, the Delphix Engine will always run the plugin's <code>preSnapshot</code> operation just before taking a snapshot of the dsource. That means our <code>preSnapshot</code> operation has to get the NFS share into the desired state. For us, that means that's the time to do our data copy.</p> <p>Unlike the previous operations we've seen so far, the pre-snapshot operation will not be autogenerated by <code>dvp init</code>. So, we will need to add one ourselves.  Open up the <code>plugin_runner.py</code> file.</p> <p>First, we'll add a new import line near the top of the file, so that we can use Delphix's platform libraries and raise user visible errors (explained below). <pre><code>from dlpx.virtualization import libs\nfrom dlpx.virtualization.platform.exceptions import UserError\n</code></pre></p> <p>Next, we'll add a new function:</p> <pre><code>@plugin.linked.pre_snapshot()\ndef copy_data_from_source(staged_source, repository, source_config, optional_snapshot_parameters):\nstage_mount_path = staged_source.mount.mount_path\ndata_location = \"{}@{}:{}\".format(staged_source.parameters.username,\nstaged_source.parameters.source_address,\nsource_config.path)\nrsync_command = \"rsync -r {} {}\".format(data_location, stage_mount_path)\nresult = libs.run_bash(staged_source.staged_connection, rsync_command)\nif result.exit_code != 0:\nraise UserError(\n\"Could not copy files.\",\n\"Ensure that passwordless SSH works for {}.\".format(staged_source.parameters.source_address),\nresult.stderr)\n</code></pre> <p>Let's walk through this function and see what's going on</p> <pre><code>    stage_mount_path = staged_source.mount.mount_path\n</code></pre> <p>The <code>staged_source</code> argument contains information about the current mount location. Here we save that to a local variable for convenience.</p> <pre><code>    data_location = \"{}@{}:{}\".format(staged_source.parameters.username,\nstaged_source.parameters.source_address,\nsource_config.path)\n</code></pre> <p>This code creates a Python string that represents the location of the data that we want to ingest. This is in the form <code>&lt;user&gt;@&lt;host&gt;:&lt;path&gt;</code>. For example <code>jdoe@sourcehost.mycompany.com:/bin</code>. As before with <code>mountLocation</code>, we have defined our schemas such that these three pieces of information were provided by the user. Here we're just putting them into a format that <code>rsync</code> will understand.</p> <pre><code>    rsync_command = \"rsync -r {} {}\".format(data_location, stage_mount_path)\n</code></pre> <p>This line is the actual Bash command that we'll be running on the staging host. This will look something like <code>rsync -r user@host:/source/path /staging/mount/path</code>.</p> <pre><code>    result = libs.run_bash(staged_source.staged_connection, rsync_command)\n</code></pre> <p>This is an example of a platform library function, where we ask the Virtualization Platform to do some work on our behalf. In this case, we're asking the platform to run our Bash command on the staging environment. For full details on the <code>run_bash</code> platform library function and others, see this reference.</p> <p><pre><code>    if result.exit_code != 0:\nraise UserError(\n\"Could not copy files.\",\n\"Ensure that passwordless SSH works for {}.\".format(staged_source.parameters.source_address),\nresult.stderr)\n</code></pre> Finally, we check to see if our Bash command actually worked okay. If not, we raise an error message, and describe one possible problem for the user to investigate. For more details on raising user visible errors, see this reference.</p>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/#saving-snapshot-data","title":"Saving Snapshot Data","text":"<p>Whenever the Delphix Engine takes a snapshot of a dSource or VDB, the plugin has the chance to save any information it likes alongside that snapshot. Later, if the snapshot is ever used to provision a new VDB, the plugin can use the previously-saved information to help get the new VDB ready for use.</p> <p>The format of this data is controlled by the plugin's <code>snapshotDefinition</code> schema. In our case, we don't have any data we need to save. So, there's not much to do here. We will not modify the blank schema that was created by <code>dvp init</code>.</p> <p>We do still need to provide python function for the engine to call, but we don't have to do much. In fact, the default implementation that was generated by <code>dvp init</code> will work just fine for our purposes:</p> <pre><code>@plugin.linked.post_snapshot()\ndef linked_post_snapshot(staged_source,\nrepository,\nsource_config,\noptional_snapshot_parameters):\nreturn SnapshotDefinition()\n</code></pre> <p>The only thing this code is doing is creating a new object using our (empty) snapshot definition, and returning that new empty object.</p>"},{"location":"Building_Your_First_Plugin/Data_Ingestion/#how-to-link-and-sync-in-the-delphix-engine","title":"How to Link and Sync in the Delphix Engine","text":"<p>Let's try it out and make sure this works!</p> <p>Prerequisites</p> <ul> <li> <p>You should already have a repository and source config set up from the previous page.</p> </li> <li> <p>You can optionally set up a new staging environment. Or, you can simply re-use your source     environment for staging.</p> </li> </ul> <p>Procedure</p> <p>Note</p> <p>Recall that, for simplicity's sake, this plugin requires that passwordless SSH is set up between your staging and source environments. You may want to verify this before continuing.</p> <ol> <li> <p>As before, use <code>dvp build</code> and <code>dvp upload</code> to get your latest plugin changes installed onto the Delphix Engine.</p> </li> <li> <p>Go to Manage &gt; Environments, select your source environment, and then go to the Databases tab. Find Repository for our First Plugin, and your source config underneath it.</p> </li> <li> <p>From your source config click Add dSource. This will begin the linking process. The first screen you see should ask for the properties that you recently added to your <code>linkedSourceDefinition</code>. </p> </li> <li> <p>Walk through the remainder of the screens and hit Submit. This will kick off the initial link and first sync.</p> </li> <li> <p>You can confirm that your new dSource was added successfully by going to Manage &gt; Datasets.</p> </li> </ol> <p>After you have finished entering this information, the initial sync process will begin. This is what will call your pre-snapshot operation, thus copying data.</p> <p>Gotcha</p> <p>Manually creating a dSource sets your plugin\u2019s linked source schema in stone, and you will have to recreate the dSource in order to modify your schema. We will cover how to deal with this correctly later, in the upgrade section. For now, if you need to change your plugin's linked source schema, you will have to first delete any dSources you have manually added.</p>"},{"location":"Building_Your_First_Plugin/Discovery/","title":"Discovery","text":""},{"location":"Building_Your_First_Plugin/Discovery/#what-is-discovery","title":"What is Discovery?","text":"<p>In order to ingest data from a source environment, the Delphix Engine first needs to learn information about the data: Where does it live? How can it be accessed? What is it called?</p> <p>Discovery is the process by which the Delphix Engine learns about remote data. Discovery can be either:</p> <ul> <li>automatic \u2014 where the plugin finds the remote data on its own</li> <li>manual \u2014 where the user tells us about the remote data</li> </ul> <p>For our first plugin, we will be using a mix of these two techniques.</p>"},{"location":"Building_Your_First_Plugin/Discovery/#source-configs-and-repositories","title":"Source Configs and Repositories","text":""},{"location":"Building_Your_First_Plugin/Discovery/#what-are-source-configs-and-repositories","title":"What are Source Configs and Repositories?","text":"<p>A source config is a collection of information that Delphix uses to represent a dataset. Different plugins will have different ideas about what a \"dataset\" is (an entire database? a set of config files? an application?). For our first plugin, it is simply a directory tree on the filesystem of the remote environment.</p> <p>A repository represents what you might call \"data dependencies\" -- anything installed on the remote host that the dataset depends on. For example, if you are working with a Postgres database, then your repository will represent an installation of a particular version of the Postgres DBMS. In this plugin, we do not have any special dependencies, except for the simple existence of the unix system on which the directory lives.</p> <p>We will be using automatic discovery for our repositories, and manual discovery for our source configs. This is the default configuration that is created by <code>dvp init</code>, so there is nothing further we need to do here.</p>"},{"location":"Building_Your_First_Plugin/Discovery/#defining-your-data-formats","title":"Defining Your Data Formats","text":"<p>Because each plugin will have different ideas about what a repository or source config represents, different plugins will have different sets of information that they need to collect and store.</p> <p>Delphix needs to know the format of this information. How many pieces of information are collected? What are they called? Are they strings? Numbers?</p> <p>For our first plugin, we do not need a lot of information. We use no special information about our repositories (except some way for the user to identify them). For source configs, all we need to know is the path to the directory from which we will be ingesting data.</p> <p>The plugin needs to describe all of this to the Delphix Engine, and it does so using schemas.  Recall that when we ran <code>dvp init</code>, a file full of bare-bones schemas was created. As we build up our first toolkit, we will be augmenting these schemas to serve our needs.</p>"},{"location":"Building_Your_First_Plugin/Discovery/#repository-schema","title":"Repository Schema","text":"<p>Open up the <code>schema.json</code> file in your editor/IDE and locate <code>repositoryDefinition</code>, it should look like this:</p> <pre><code>{\n\"repositoryDefinition\": {\n\"type\": \"object\",\n\"properties\": {\n\"name\": { \"type\": \"string\" }\n},\n\"nameField\": \"name\",\n\"identityFields\": [\"name\"]\n}\n}\n</code></pre> <p>Since we do not have any special dependencies, we can just leave it as-is.</p> <p>For detailed information about exactly how repository schemas work, see the reference page.</p> <p>In brief, what we are doing here is saying that each of our repositories will have a single property called <code>name</code>, which will be used both as a unique identifier and as the user-visible name of the repository.</p>"},{"location":"Building_Your_First_Plugin/Discovery/#source-config-schema","title":"Source Config Schema","text":"<p>For source configs, the bare-bones schema is not going to be good enough. Recall that for us, a source config represents a directory tree on a remote environment.</p> <p>Locate the <code>sourceConfigDefinition</code> inside the <code>schema.json</code> file and modify the definition so it looks like this:</p> <pre><code>\"sourceConfigDefinition\": {\n\"type\": \"object\",\n\"required\": [\"name\", \"path\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"name\": {\n\"type\": \"string\",\n\"prettyName\": \"Dataset Name\",\n\"description\": \"User-visible name for this dataset\"\n},\n\"path\": {\n\"type\": \"string\",\n\"format\": \"unixpath\",\n\"prettyName\": \"Path\",\n\"description\": \"Full path to data location on the remote environment\"\n}\n},\n\"nameField\": \"name\",\n\"identityFields\": [\"path\"]\n},\n</code></pre> <p>Now, we have two properties, a property <code>name</code> serving as the user-visible name of the source config and <code>path</code> which tells us where the data lives on the remote host. Note  we are using <code>path</code> as the unique identifier.</p> <p>Because we are using manual discovery, the end user is going to be responsible for filling in values for <code>name</code> and <code>path</code>. So, we have added some things to our schema that we did not need for repositories.</p> <p>The <code>prettyName</code> and <code>description</code> entries will be used by the UI to tell the user what these fields mean.</p> <p>Because we set <code>additionalProperties</code> to <code>false</code>, this will prevent users from supplying properties other than <code>name</code> and <code>path</code>.</p> <p>Finally, we have specified that the <code>path</code> property must be a well-formatted Unix path. This allows the UI to enforce that the format is correct before the user is allowed to proceed. (Note this only enforces the format, and does not actually check to see if the path really exists on some remote environment!)</p> <p>Refer to the reference page for Schemas for more details about these entries, and for other things that you can do in these schemas.</p>"},{"location":"Building_Your_First_Plugin/Discovery/#implementing-discovery-in-your-plugin","title":"Implementing Discovery in Your Plugin","text":""},{"location":"Building_Your_First_Plugin/Discovery/#about-python-code","title":"About Python Code","text":"<p>As described in the overview section, plugins customize the behavior of the Delphix Engine by providing Python code. Each customizable piece of behavior is called a \"plugin operation\". The plugin provides separate Python functions for each of the operations that it wants to customize.</p> <p>Right now, we are concerned with discovery. There are two customizable operations related to automatic discovery, one for repositories and one for source configs. In both cases, the job of the Python method is to automatically collect whatever information the schemas (see above) require, and to return that information to the Delphix Engine. The Delphix Engine will run these customized operations whenever a new environment is added, or when an existing environment is rediscovered.</p>"},{"location":"Building_Your_First_Plugin/Discovery/#a-look-at-the-generated-code","title":"A Look at the Generated Code","text":"<p>Recall that the <code>dvp init</code> command we ran created a file called <code>src/plugin_runner.py</code>. Open this file in your editor/IDE. You will see that this file already contains a bunch of Python code. Let's take a look at the first three blocks of code in this file.</p> <p><pre><code>from dlpx.virtualization.platform import Mount, MountSpecification, Plugin\nfrom generated.definitions import (\nRepositoryDefinition,\nSourceConfigDefinition,\nSnapshotDefinition,\n)\n</code></pre> These <code>import</code> lines make certain functionality available to our Python code. Some of this functionality will be used just below, as we implement discovery. Others will be used later on, as we implement ingestion and provisioning. Later, you'll add more <code>import</code>s to unlock more functionality.</p> <pre><code>plugin = Plugin()\n</code></pre> <p>This line creates a Python object which allows us to define our plugin types. We have the ability to do this because of the <code>import Plugin</code> statement above.</p> <p>This object is stored in a variable we have elected to call <code>plugin</code>. We are free to call this variable anything we want, so long as we also change the <code>entryPoint</code> line in the <code>plugin_config.yml</code> file. For this example, we will just leave it as <code>plugin</code>.</p> <pre><code>#\n# Below is an example of the repository discovery operation.\n#\n# NOTE: The decorators are defined on the 'plugin' object created above.\n#\n# Mark the function below as the operation that does repository discovery.\n@plugin.discovery.repository()\ndef repository_discovery(source_connection):\n#\n# This is an object generated from the repositoryDefinition schema.\n# In order to use it locally you must run the 'build -g' command provided\n# by the SDK tools from the plugin's root directory.\n#\nreturn [RepositoryDefinition(name='1e87dc30-3cdb-4f0a-9634-07ce017d20d1')]\n</code></pre> <p>This is our first plugin operation. In this case, it's defining what will happen when the Delphix Engine wants to discover repositories on an environment.  Let's take a look at this code line-by-line</p> <pre><code>@plugin.discovery.repository()\ndef repository_discovery(source_connection):\n</code></pre> <p>This begins the definition of a function called <code>repository_discovery</code>.</p> <p>We are using a Python decorator which signals to the Delphix Engine that this is the function which should be called when it is time to do repository discovery. The actual name of the function doesn't matter here. Note that we are using our <code>plugin</code> variable here as part of the decorator.</p> <p>The Delphix Engine will pass us information about the source environment in an argument called <code>source_connection</code>.</p> <p>Warning</p> <p>The name of this input argument matters. That is, you'll always need to have an argument called <code>source_connection</code> here. Each plugin operation has its own set of required argument names. For details on which arguments apply to which operations, see the reference section.</p> <pre><code>    return [RepositoryDefinition(name='1e87dc30-3cdb-4f0a-9634-07ce017d20d1')]\n</code></pre> <p>This creates and returns a Python object that corresponds to the format defined by our repository schema. Because our repository has exactly one string property called <code>name</code>, therefore this Python object has one property called <code>name</code>.</p> <p>Notice that the code generator has filled in the value of <code>name</code> with a random string. This results in a plugin operation that works, but which will not be very helpful for the user. We'll change this later.</p> <p>The rest of the file contains more plugin operations, and we'll be modifying them later.</p>"},{"location":"Building_Your_First_Plugin/Discovery/#repository-discovery","title":"Repository Discovery","text":"<p>Now, we need to modify the provided repository discovery operation. This operation will examine a remote environment, find any repositories, and return information about them to the Delphix Engine.</p> <p>As a reminder, our only external dependency on the remote environment is simply the existence of a filesystem. Since every Unix host has a filesystem, that means we will have exactly one repository per remote environment. Therefore, our repository discovery operation can be very simple.</p> <p>In fact, as we saw above, the default-generated <code>repository_discovery</code> function does almost exactly what we want -- it returns one single repository for any Unix host that it is asked to work with. The only problem with it is that it uses unhelpful name.  That's really easy to change!</p> <p>Replace or modify <code>repository_discovery</code> so it looks like this:</p> <pre><code>@plugin.discovery.repository()\ndef repository_discovery(source_connection):\nrepository = RepositoryDefinition('Repository for our First Plugin')\nreturn [repository]\n</code></pre> <p>Tip</p> <p>Be careful to always use consistent indentation in Python code!</p>"},{"location":"Building_Your_First_Plugin/Discovery/#source-config-discovery","title":"Source Config Discovery","text":"<p>For source configs, we will rely solely on manual discovery. Therefore, the user will tell us which directories they want to ingest from. We still have to define a source config discovery operation -- it just won't need to do much.</p> <p>The job of this operation is to return only source configs associated with the given <code>repository</code>. This function will be called once per repository. In our case, that means it will only be called once.</p> <p>Because we want to supply no automatically-discovered source configs, this function should simply returns an empty list.</p> <p>In fact, <code>dvp init</code> has already generated a function for us that does exactly this.</p> <pre><code>@plugin.discovery.source_config()\ndef source_config_discovery(source_connection, repository):\nreturn []\n</code></pre> <p>If we wanted to do automatic discovery of source configs, we'd modify this function. But, for our purposes now, the existing code is fine and we don't need to change anything.</p>"},{"location":"Building_Your_First_Plugin/Discovery/#how-to-run-discovery-in-the-delphix-engine","title":"How to Run Discovery in the Delphix Engine","text":"<p>Let us make sure discovery works!</p> <ol> <li> <p>Run the <code>dvp build</code> commands, as before. This will build the plugin, with all of the new changes, and create an artifact.</p> </li> <li> <p>Run <code>dvp upload -e &lt;engine&gt; -u &lt;user&gt;</code>, as before. This will get all the new changes onto the Delphix Engine.</p> </li> <li> <p>Once the new plugin is uploaded, add a remote unix environment to your engine. To do this, go to Manage &gt; Environments, chose Add Environment from the menu, answer the questions, and Submit. (If you already have an environment set up, you can just refresh it instead).</p> </li> </ol> <p>To keep an eye on this discovery process, you may need to open the Actions tab on the UI. If any errors happen, they will be reported here.</p> <ol> <li>After the automatic discovery process completes, go to the Databases tab. You will see an entry for Repository For Our First Plugin. This is the repository you created in your Python code.</li> </ol> <p></p> <p>Notice that it says No databases found on installation. This is because we chose not to do automatic source config discovery.</p> <p>However, because we have allowed manual source config discovery, you can add your own entries by clicking the plus sign (Add Database). Complete the information in the Add Database dialog and click Add.</p> <p></p> <p>This should all look familiar. It is precisely what we defined in our source config schema. As expected, there are two entries, one for our <code>name</code> property, and one for <code>path</code>.</p> <p>For example, in the above screenshot, we are specifying that we want to sync the <code>/bin</code> directory from the remote host, and we want to call it <code>Binaries</code>. You can pick any directory and name that you want.</p> <p>Once you have added one or more source configs, you will be able to sync. This is covered on the next page.</p> <p>Warning</p> <p>Once you have automatically or manually created source configs, you will not be allowed to modify your plugin's source config schema. We will cover how to deal with this later in the upgrade section. For now, if you need to change your plugin's source config schema:</p> <ul> <li>You will have to delete any source configs you have manually added.</li> <li>Delete the plugin and its corresponding objects (dSources, Virtual Sources, etc) if the source configs were manually discovered.</li> </ul>"},{"location":"Building_Your_First_Plugin/Initial_Setup/","title":"Initial Setup","text":"<p>Before we begin to start writing plugin code, we will need to do some setup work. We will be using the <code>dvp</code> tool, which is described in the Getting Started section.</p> <p>The quoted examples in this section assume you're working on a Unix-like system.</p>"},{"location":"Building_Your_First_Plugin/Initial_Setup/#quick-check","title":"Quick Check","text":"<p>First a reminder that it's highly recommended that you develop your plugin in a virtual environment.</p> <p>Next, make sure you have a Delphix Engine ready to use, as described in the Prerequisites section on the previous page.</p> <p>Finally, let's quickly make sure that <code>dvp</code> is working! Type <code>dvp -h</code> and you should see something like the following: <pre><code>(venv)$ dvp -h\nUsage: dvp [OPTIONS] COMMAND [ARGS]...\n\n  The tools of the Delphix Virtualization SDK that help develop, build, and\n  upload a plugin.\n\nOptions:\n  --version      Show the version and exit.\n  -v, --verbose  Enable verbose mode. Can be repeated up to three times for\n                 increased verbosity.\n  -q, --quiet    Enable quiet mode. Can be repeated up to three times for\n                 increased suppression.\n  -h, --help     Show this message and exit.\n\nCommands:\n  build          Build the plugin code and generate upload artifact file...\n  download-logs  Download plugin logs from a target Delphix Engine to a...\n  init           Create a plugin in the root directory.\n  upload         Upload the generated upload artifact (the plugin JSON\n                 file)...\n</code></pre></p> <p>If this looks good, you are ready to begin!</p> <p>If, instead, you see something like the following, go back to Getting Started and make sure you setup everything correctly before continuing. <pre><code>(venv)$ dvp\n-bash: dvp: command not found\n</code></pre></p>"},{"location":"Building_Your_First_Plugin/Initial_Setup/#creating-a-bare-plugin","title":"Creating a Bare Plugin","text":"<p>To start, we will create a new directory where our new plugin code will live. <pre><code>(venv)$ mkdir first_plugin\n(venv)$ cd first_plugin\n</code></pre></p> <p>Now that we are in our new plugin directory, we can use the <code>dvp</code> tool to create a plugin for us. This plugin will be a mere skeleton -- it will not do anything useful until we modify it in the subsequent pages.</p> <pre><code>(venv) first_plugin$ dvp init -n first_plugin -s STAGED -t UNIX\n</code></pre> <p>The <code>-n</code> argument here means \"plugin name.\" We are using the name <code>first_plugin</code>.</p> <p>The <code>-s</code> argument tells which syncing strategy we want to use.</p> <p>The <code>-t</code> argument tells which host platform our plugin supports.</p> <p>You can type <code>dvp init -h</code> for more information about the options available.</p> <p>After running this command, you should see that files have been created for you:</p> <pre><code>(venv) first_plugin$ ls\nplugin_config.yml   schema.json     src\n</code></pre> <p>These files are described below:</p> File Description <code>plugin_config.yml</code> The plugin config file, which provides a list of plugin properties <code>schema.json</code> Contains schemas which provide custom datatype definitions <code>src/plugin_runner.py</code> A Python file which will eventually contain code that handles plugin operations <p>Open these files in your editor/IDE and take a look at them. At this point they will not have a lot of content, but we will add to them as we go through the next few pages.</p>"},{"location":"Building_Your_First_Plugin/Initial_Setup/#building-the-new-plugin","title":"Building The New Plugin","text":"<p>The new files we created above have to get built to produce a single artifact. This is done with the <code>dvp</code> tool.</p> <pre><code>(venv) first_plugin$ dvp build\n</code></pre> <p>After the build, you should see that the build process has created a new file called <code>artifact.json</code>. <pre><code>(venv) first_plugin$ ls\nartifact.json       plugin_config.yml   schema.json     src\n</code></pre></p>"},{"location":"Building_Your_First_Plugin/Initial_Setup/#uploading-the-new-plugin","title":"Uploading The New Plugin","text":"<p>Now using the <code>dvp</code> tool we can upload the artifact onto our Delphix Engine.</p> <pre><code>(venv) first_plugin$ dvp upload -e engine.company.com -u admin\n</code></pre> <p>The <code>-e</code> argument specifies the engine on which to install the plugin, and the <code>-u</code> argument gives the Delphix Engine user.</p> <p>You will be prompted for a password.</p> <p>Once the upload is finished, you can verify the installation from the Manage &gt; Toolkits screen in the Delphix Engine UI.</p> <p></p>"},{"location":"Building_Your_First_Plugin/Overview/","title":"Overview","text":"<p>In the following few pages, we will walk through an example of making a simple, working plugin.</p> <p>Our plugin will virtualize simple directory trees on Unix systems. The actual contents of these directories could be anything: configuration files, documents, image libraries, etc. Our plugin will not care about the contents and will treat it as a directory tree full of files.</p>"},{"location":"Building_Your_First_Plugin/Overview/#data-flow-in-the-delphix-engine","title":"Data Flow in the Delphix Engine","text":"<p>Here we will briefly overview how data moves through the Delphix Engine.</p>"},{"location":"Building_Your_First_Plugin/Overview/#ingestion","title":"Ingestion","text":"<p>It all begins with Delphix ingesting data\u2014copying some data from what we call a source environment  onto the Delphix Engine.</p> <p>Plugins can use either of two basic strategies to do this copying:</p> <ul> <li>direct linking, where the Delphix Engine pulls data directly from the source environment.</li> <li>staged linking, where the plugin is responsible for pulling data from the source environment.</li> </ul> <p>Our plugin will use the staged linking strategy.</p> <p>With staged linking, Delphix exposes and mounts storage to a staging environment.  This would be an NFS share for Unix environments and iSCSI disks for Windows environments. You can use either the source environment or a different environment for staging. We will write our plugin to handle both approaches.</p> <p>Once Delphix mounts the storage share onto the staging environment, the plugin needs to arrange for the relevant data to be copied from the source environment onto the storage share, which is backed by Delphix Engine storage.</p> <p>When this initial copy is complete, Delphix will take a snapshot of the backing storage.</p> <p>This same basic operation will be repeated when Delphix mounts an NFS share: The plugin copies data onto it, then Delphix snapshots the result.</p>"},{"location":"Building_Your_First_Plugin/Overview/#provisioning","title":"Provisioning","text":"<p>Provisioning is when you take a Delphix Engine snapshot and create a virtual dataset from it.</p> <p>First the snapshot is cloned onto the Delphix Engine, then this newly-cloned data is mounted as a virtual dataset onto a target environment. While this new virtual dataset gets updated by its end users, the original snapshot is persistent. You can use it in a few ways:</p> <ul> <li>Provision other virtual datasets from it</li> <li>Rewind the virtual dataset back to the state it represents</li> <li>Create a physical database from it in what we call V2P: Virtual to Physical</li> </ul>"},{"location":"Building_Your_First_Plugin/Overview/#parts-of-a-plugin","title":"Parts of a Plugin","text":"<p>A plugin consists of three main parts. We will cover them briefly here, and then fill in more details later in the tutorial.</p>"},{"location":"Building_Your_First_Plugin/Overview/#plugin-config","title":"Plugin Config","text":"<p>Plugin config is where the plugin describes itself to the Delphix Engine. What is the plugin called? What version of the plugin is being used? What type(s) of environments does the plugin work with? What features does the plugin offer?...</p>"},{"location":"Building_Your_First_Plugin/Overview/#plugin-operations","title":"Plugin Operations","text":"<p>The plugin will need to provide operations. These are Python functions, each of which implements one small piece of functionality. This is how the plugin customizes Delphix behavior to work with the kind of dataset you\u2019re building the plugin for. One operation will handle setting up a newly-configured virtual dataset. Another will handle copying data from a source environment, and so on.</p> <p>Later we\u2019ll provide examples for our first plugin. See Plugin Operations for full details on the operations that are available, which are required, and what each one is required to do.</p>"},{"location":"Building_Your_First_Plugin/Overview/#schemas","title":"Schemas","text":"<p>As part of normal operations, plugins need to generate and access certain pieces of information in order to do their job. For example, plugins that work with Postgres might need to know which port number to connect to, or which credentials to use.</p> <p>Defining your plugin\u2019s schemas will enable it to give the Delphix Engine the details it needs to run the operations we\u2019ve built into it. Different datasets can have very different needs. The schemas you provide for your plugin will tell Delphix how to operate with your dataset.</p>"},{"location":"Building_Your_First_Plugin/Overview/#prerequisites","title":"Prerequisites","text":"<p>To complete the tutorial that follows, make sure you check off the things on this list:</p> <ul> <li>Download the SDK and get it working</li> <li>A running Delphix Engine version 6.0.2.0 or above.</li> <li>Add at least one Unix host\u2014but preferably three\u2014to the Delphix Engine as remote environments.</li> <li>Have a tool at hand for editing text files\u2014mostly Python and JSON. A simple text editor would work fine, or you can use a full-fledged IDE.</li> </ul>"},{"location":"Building_Your_First_Plugin/Provisioning/","title":"Provisioning","text":""},{"location":"Building_Your_First_Plugin/Provisioning/#what-is-provisioning","title":"What is Provisioning?","text":"<p>Once Delphix has a snapshot of a dataset (for example of a dSource), it is possible to quickly clone that snapshot to create a new virtual dataset. This new virtual dataset will be made available for use on a target environment. This process is called provisioning.</p>"},{"location":"Building_Your_First_Plugin/Provisioning/#our-provisioning-strategy","title":"Our Provisioning Strategy","text":"<p>For many plugins, there is a lot of work that needs to be done before a newly-provisioned virtual dataset can be made useful. For example, it might need to be registered with a running DBMS. Or, maybe some data inside the dataset needs to be changed so it behaves properly on the target environment.</p> <p>In our case, however, there is very little to do. All we really require is that the files in the virtual dataset are accessible at some path on the target environment. Since the Delphix Engine takes care of mounting the data, we only need to worry about controlling where that data is mounted.</p>"},{"location":"Building_Your_First_Plugin/Provisioning/#defining-our-provision-related-data-formats","title":"Defining our Provision-Related Data Formats","text":"<p>We have already seen four custom data formats: for repositories, source configs, snapshots and linked sources. The final one is used for virtual sources.</p> <p>Recall that, for our plugin, a VDB is just a directory full of files. There is no special procedure needed to enable it, no DBMS to coordinate with, etc. All we need to do is make the files available on the target environment.</p> <p>So, the only question for the user is \"Where should these files live?\"</p> <p>Open up <code>schema.json</code>, locate the <code>virtualSourceDefintion</code> section, and change it to look like this:</p> <pre><code>\"virtualSourceDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\" : false,\n\"required\": [\"mountLocation\"],\n\"properties\" : {\n\"mountLocation\": {\n\"type\": \"string\",\n\"format\": \"unixpath\",\n\"prettyName\": \"Mount Location on Target Host\",\n\"description\": \"Where to mount VDB onto the target host\"\n}\n}\n},\n</code></pre> <p>This should look familiar from the source config schema that we did earlier. We only have one property, and it represents the mount location on the target environment.</p>"},{"location":"Building_Your_First_Plugin/Provisioning/#implementing-provisioning","title":"Implementing Provisioning","text":"<p>There are numerous ways for a plugin to customize the provisioning process. For our example plugin, we just need to do a few things:</p> <ol> <li>Tell Delphix where to mount the virtual dataset.</li> <li>Create a <code>sourceConfig</code> to represent each newly-provisioned virtual dataset.</li> <li>Modify an existing <code>sourceConfig</code>, if necessary, when the virtual dataset is refreshed or rewound.</li> <li>Construct snapshot-related data any time a snapshot is taken of the virtual dataset.</li> </ol>"},{"location":"Building_Your_First_Plugin/Provisioning/#controlling-mounting","title":"Controlling Mounting","text":"<p>As we saw previously with linked sources, we need to tell Delphix where to mount the dataset. Open up <code>plugin_runner.py</code> and find the <code>plugin.virtual.mount_specification</code> decorator. Change that function so that it looks like this:</p> <pre><code>@plugin.virtual.mount_specification()\ndef vdb_mount_spec(virtual_source, repository):\nmount_location = virtual_source.parameters.mount_location\nmount = Mount(virtual_source.connection.environment, mount_location)\nreturn MountSpecification([mount])\n</code></pre> <p>As we did with linked sources, we just look up what the user told us, and then package that up and return it to Delphix.</p>"},{"location":"Building_Your_First_Plugin/Provisioning/#creating-a-source-config-for-a-new-vdb","title":"Creating a Source Config for a new VDB","text":"<p>Just like we saw earlier with linked datasets, each virtual dataset will need its own source config so that the Delphix Engine can interact with it. Our plugin is in charge of creating that source config at provision time</p> <p>As a reminder, here is what our schema looks like for source configs:</p> <pre><code>\"sourceConfigDefinition\": {\n\"type\": \"object\",\n\"required\": [\"name\", \"path\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"name\": {\n\"type\": \"string\",\n\"prettyName\": \"Dataset Name\",\n\"description\": \"User-visible name for this dataset\"\n},\n\"path\": {\n\"type\": \"string\",\n\"format\": \"unixpath\",\n\"prettyName\": \"Path\",\n\"description\": \"Full path to data location on the remote environment\"\n}\n},\n\"nameField\": \"name\",\n\"identityFields\": [\"path\"]\n},\n</code></pre> <p>Thus, for each newly-cloned virtual dataset, we create a new source config object with a name and a path. This is done by the <code>configure</code> plugin operation.</p> <p>In addition to generating a new source config, the configure operation is also tasked with getting the newly-cloned dataset ready for use on the target environment. What this means exactly will vary from plugin to plugin. For our simple plugin, the dataset does not require any setup work, and so we only have to worry about the source config.</p> <p>Find the <code>plugin.virtual.configure</code> decorator and change the function to look like this:</p> <pre><code>@plugin.virtual.configure()\ndef configure_new_vdb(virtual_source, snapshot, repository):\nmount_location = virtual_source.parameters.mount_location\nname = \"VDB mounted at {}\".format(mount_location)\nreturn SourceConfigDefinition(path=mount_location, name=name)\n</code></pre>"},{"location":"Building_Your_First_Plugin/Provisioning/#modifying-a-source-config-after-rewind-or-refresh","title":"Modifying a Source Config after Rewind or Refresh","text":"<p>Just as a new VDB might need to be configured, a refreshed or rewound VDB might need to be \"reconfigured\" to handle the new post-refresh (or post-rewind) state of the VDB. So, just as there is a <code>configure</code> operation, there is also a <code>reconfigure</code> operation.</p> <p>The main difference between the two is that <code>configure</code> must create a source config, but <code>reconfigure</code> needs to modify a pre-existing source config.</p> <p>In our simple plugin, there is no special work to do at reconfigure time, and there is no reason to modify anything about the source config. We just need to write a <code>reconfigure</code> operation that returns the existing source config without making any changes. Find the <code>plugin.virtual.reconfigure</code> decorator and modify the function as follows.</p> <pre><code>@plugin.virtual.reconfigure()\ndef reconfigure_existing_vdb(virtual_source, repository, source_config, snapshot):\nreturn source_config\n</code></pre>"},{"location":"Building_Your_First_Plugin/Provisioning/#saving-snapshot-data","title":"Saving Snapshot Data","text":"<p>As with our linked sources, we don't actually have anything we need to save when VDB snapshots are taken. And, again, <code>dvp init</code> has created a post-snapshot operation that will work just fine for us without modification:</p> <pre><code>@plugin.virtual.post_snapshot()\ndef virtual_post_snapshot(virtual_source, repository, source_config):\nreturn SnapshotDefinition()\n</code></pre>"},{"location":"Building_Your_First_Plugin/Provisioning/#how-to-provision-in-the-delphix-engine","title":"How To Provision in the Delphix Engine","text":"<p>Finally, let us try it out to make sure provisioning works!</p> <ol> <li>Again, use <code>dvp build</code> and <code>dvp upload</code> to get your new changes onto your Delphix Engine.</li> <li>Click Manage &gt; Datasets.</li> <li>Select the dSource you created in the last page. You should see at least one snapshot, and maybe more than one if you have manually taken a snapshot, or if you have a snapshot policy in place. Select one of these snapshots and click the Provision vFiles icon.</li> <li>This will open the Provision VDB wizard. Complete the steps and select Submit.   During VDB provisioning one of the things you will have to do is to provide the data required by your virtual source schema. In our case, that means you will be asked to provide a value for <code>mountLocation</code>. You will also be asked to choose a target environment on which the new VDB will live. After the wizard finishes, you will see a job appear in the Actions tab on the right-hand side of the screen. When that job completes, your new VDB should be ready.</li> <li>To ensure everything has worked correctly, log into to your target environment. From there, you can examine the directory you specified as the <code>mountLocation</code>. What you should see is a copy of the directory that you linked to with your dSource.</li> </ol>"},{"location":"References/CLI/","title":"CLI","text":"<p>The CLI is installed with the SDK. To install the SDK, refer to the Getting Started section. You can also use a CLI Configuration File to set default values for CLI command options.</p>"},{"location":"References/CLI/#help","title":"Help","text":"<p>Every command has a <code>-h</code> flag including the CLI itself. This will print the help menu.</p>"},{"location":"References/CLI/#examples","title":"Examples","text":"<p>Get the CLI's help menu.</p> <pre><code>$ dvp -h\nUsage: dvp [OPTIONS] COMMAND [ARGS]...\n\n  The tools of the Delphix Virtualization SDK that help develop, build, and\n  upload a plugin.\n\nOptions:\n  --version      Show the version and exit.\n  -v, --verbose  Enable verbose mode. Can be repeated up to three times for\n                 increased verbosity.\n\n  -q, --quiet    Enable quiet mode. Can be repeated up to three times for\n                 increased suppression.\n\n  -h, --help     Show this message and exit.\n\nCommands:\n  build          Build the plugin code and generate upload artifact file...\n  download-logs  Download plugin logs from a target Delphix Engine to a...\n  init           Create a plugin in the root directory.\n  upload         Upload the generated upload artifact (the plugin JSON\n                 file)...\n</code></pre> <p>Get the <code>build</code> command's help menu. <pre><code>$ dvp build -h\nUsage: dvp build [OPTIONS]\n\n  Build the plugin code and generate upload artifact file using the\n  configuration provided in the plugin config file.\n\nOptions:\n  -c, --plugin-config FILE    Set the path to plugin config file.This file\n                              contains the configuration required to build the\n                              plugin.  [default: plugin_config.yml]\n  -a, --upload-artifact FILE  Set the upload artifact.The upload artifact file\n                              generated by build process will be writtento\n                              this file and later used by upload command.\n                              [default: artifact.json]\n  -g, --generate-only         Only generate the Python classes from the schema\n                              definitions. Do not do a full build or create an\n                              upload artifact.  [default: False]\n  -h, --help                  Show this message and exit.\n</code></pre></p>"},{"location":"References/CLI/#verbosity","title":"Verbosity","text":"<p>To change the verbosity level of the CLI you can specify up to three <code>-v</code> (to increase) or <code>-q</code> (to decrease) the amount that is printed to the console. This is an option on the CLI itself and can be used with any command.</p> Option Output -qqq None -qq Critical -q Error -v Info -vv Debug -vvv All"},{"location":"References/CLI/#examples_1","title":"Examples","text":"<p>Print everything to the console.</p> <pre><code>$ dvp -vvv build\n</code></pre> <p>Print nothing to the console.</p> <pre><code>$ dvp -qqq build\n</code></pre>"},{"location":"References/CLI/#commands","title":"Commands","text":""},{"location":"References/CLI/#init","title":"init","text":""},{"location":"References/CLI/#description","title":"Description","text":"<p>Create a plugin in the root directory. The plugin will be valid but have no functionality.</p>"},{"location":"References/CLI/#options","title":"Options","text":"Option\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description Required Default\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 -r,--root-dirDIRECTORY Set the plugin root directory. N <code>os.cwd()</code> -n,--plugin-nameTEXT Set the name of the plugin that will be used to identify it. N id -s,--ingestion-strategy[DIRECT|STAGED] Set the ingestion strategy of the plugin. A \"direct\" plugin ingests without a staging server while a \"staged\" plugin requires a staging server. N <code>DIRECT</code> -t,--host-type[UNIX|WINDOWS] Set the host platform supported by the plugin. N <code>UNIX</code>"},{"location":"References/CLI/#examples_2","title":"Examples","text":"<p>Create a <code>UNIX</code> plugin in the current working directory with the <code>DIRECT</code> ingestion strategy. Here the name of the plugin will be equal to the id that is generated.</p> <pre><code>$ dvp init\n</code></pre> <p>Create a <code>UNIX</code> plugin in the current working directory with the <code>DIRECT</code> ingestion strategy and use <code>postgres</code> as the display name.</p> <pre><code>$ dvp init -n postgres\n</code></pre> <p>Create a <code>UNIX</code> plugin called <code>mongodb</code> in a custom location with the <code>STAGED</code> ingestion strategy.</p> <pre><code>$ dvp init -n mongodb -s STAGED -r /our/plugin/directory\n</code></pre> <p>Create a <code>WINDOWS</code> plugin called <code>mssql</code> in the current working directory with the <code>DIRECT</code> ingestion strategy.</p> <pre><code>$ dvp init -n mssql -t WINDOWS\n</code></pre>"},{"location":"References/CLI/#build","title":"build","text":""},{"location":"References/CLI/#description_1","title":"Description","text":"<p>Build the plugin code and generate upload artifact file using the configuration provided in the plugin config file.</p>"},{"location":"References/CLI/#options_1","title":"Options","text":"Option \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description Required Default\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 -c,--plugin-configFILE Set the path to plugin config file.This file contains the configuration required to build the plugin. N <code>plugin_config.yml</code> -a,--upload-artifactFILE Set the upload artifact.The upload artifact file generated by build process will be written to this file and later used by upload command. N <code>artifact.json</code> -g,--generate-only Only generate the Python classes from the schema definitions. Do not do a full build or create an upload artifact. N <code>False</code>"},{"location":"References/CLI/#examples_3","title":"Examples","text":"<p>Do a full build of the plugin and write the upload artifact to <code>./artifact.json</code>.</p> <p>This assumes current working directory contains a plugin config file named <code>plugin_config.yml</code>.</p> <pre><code>$ dvp build\n</code></pre> <p>Do a partial build and just generate the Python classes from the schema definitions.</p> <p>This assumes current working directory contains ad plugin config file named <code>plugin_config.yml</code>.</p> <pre><code>$ dvp build -g\n</code></pre> <p>Do a full build of a plugin and write the artifact file to a custom location.</p> <pre><code>$ dvp build -c config.yml -a build/artifact.json\n</code></pre>"},{"location":"References/CLI/#upload","title":"upload","text":""},{"location":"References/CLI/#description_2","title":"Description","text":"<p>Upload the generated upload artifact (the plugin JSON file) that was built to a target Delphix Engine. Note that the upload artifact should be the file created after running the build command and will fail if it's not readable or valid.</p>"},{"location":"References/CLI/#options_2","title":"Options","text":"Option \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description Required Default \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 -e,--delphix-engineTEXT Upload plugin to the provided engine. This should be either the hostname or IP address. Y None -u,--userTEXT Authenticate to the Delphix Engine with the provided user. Y None -a,--upload-artifact FILE Path to the upload artifact that was generated through build. N <code>artifact.json</code> --wait Block and wait for the upload job to finish on the Delphix Engine. N None --passwordTEXT Authenticate using the provided password. If ommitted, the password will be requested through a secure prompt. N None"},{"location":"References/CLI/#examples_4","title":"Examples","text":"<p>Upload artifact <code>build/artifact.json</code> to <code>engine.example.com</code> using the user <code>admin</code>. Since the password option is ommitted, a secure password prompt is used instead.</p> <pre><code>$ dvp upload -a build/artifact -e engine.example.com -u admin\nPassword:\n</code></pre>"},{"location":"References/CLI/#download-logs","title":"download-logs","text":""},{"location":"References/CLI/#description_3","title":"Description","text":"<p>Download plugin logs from a Delphix Engine to a local directory.</p>"},{"location":"References/CLI/#options_3","title":"Options","text":"Option \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description Required Default\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 -e,--delphix-engineTEXT Download plugin logs from the provided Delphix engine. This should be either the hostname or IP address. Y None -c,--plugin-config FILE Set the path to plugin config file. This file contains the plugin name to download logs for. N <code>plugin_config.yml</code> -u,--userTEXT Authenticate to the Delphix Engine with the provided user. Y None -d,--directory DIRECTORY Specify the directory of where to download the plugin logs. N <code>os.cwd()</code> --passwordTEXT Authenticate using the provided password. If ommitted, the password will be requested through a secure prompt. N None"},{"location":"References/CLI/#examples_5","title":"Examples","text":"<p>Download plugin logs from <code>engine.example.com</code> using the user <code>admin</code>. Since the password option is ommitted, a secure password prompt is used instead.</p> <pre><code>$ dvp download-logs -e engine.example.com -u admin\nPassword:\n</code></pre>"},{"location":"References/Classes/","title":"Classes","text":""},{"location":"References/Classes/#directsource","title":"DirectSource","text":"<p>Represents a Linked Source object and its properties when using a Direct Linking strategy.</p> <pre><code>from dlpx.virtualization.platform import DirectSource\ndirect_source = DirectSource(guid, connection, parameters)\n</code></pre>"},{"location":"References/Classes/#fields","title":"Fields","text":"Field Type Description guid String Unique Identifier for the source. connection RemoteConnection Connection for the source environment. parameters LinkedSourceDefinition User input as per the LinkedSource Schema."},{"location":"References/Classes/#stagedsource","title":"StagedSource","text":"<p>Represents a Linked Source object and its properties when using a Staged Linking strategy.</p> <pre><code>from dlpx.virtualization.platform import StagedSource\nstaged_source = StagedSource(guid, source_connection, parameters, mount, staged_connection, mounts)\n</code></pre>"},{"location":"References/Classes/#fields_1","title":"Fields","text":"Field Type Description guid String Unique Identifier for the source. source_connection RemoteConnection Connection for the source environment. parameters LinkedSourceDefinition User input as per the LinkedSource Schema. mount Mount Mount point associated with the source. staged_connection RemoteConnection Connection for the staging environment. mounts list[Mount] Mount points associated with the source. <p>mount vs mounts</p> <p>Both <code>mount</code> and <code>mounts</code> will not be present in the StagedSource object. Fields are populated based on number of mountSpecification object provided from linked_mount_specification decorator.</p> <ul> <li>When only one mountSpecification object is provided, <code>mount</code> will be present.</li> <li>When more than one mountSpecification object is provided, <code>mounts</code> will be present.</li> </ul>"},{"location":"References/Classes/#virtualsource","title":"VirtualSource","text":"<p>Represents a Virtual Source object and its properties.</p> <pre><code>from dlpx.virtualization.platform import VirtualSource\nvirtual_source = VirtualSource(guid, connection, parameters, mounts)\n</code></pre>"},{"location":"References/Classes/#fields_2","title":"Fields","text":"Field Type Description guid String Unique Identifier for the source. connection RemoteConnection Connection for the source environment. parameters VirtualSourceDefinition User input as per the VirtualSource Schema. mounts list[Mount] Mount points associated with the source."},{"location":"References/Classes/#remoteconnection","title":"RemoteConnection","text":"<p>Represents a connection to a source.</p> <pre><code>from dlpx.virtualization.common import RemoteConnection\nconnection = RemoteConnection(environment, user)\n</code></pre>"},{"location":"References/Classes/#fields_3","title":"Fields","text":"Field Type Description environment RemoteEnvironment Environment for the connection. user RemoteUser User for the connection."},{"location":"References/Classes/#status","title":"Status","text":"<p>An enum used to represent the state of a linked or virtual source and whether it is functioning as expected.</p> <pre><code>from dlpx.virtualization.platform import Status\nstatus = Status.ACTIVE\n</code></pre>"},{"location":"References/Classes/#values","title":"Values","text":"Value Description ACTIVE Source is healthy and functioning as expected. INACTIVE Source is not functioning as expected."},{"location":"References/Classes/#mount","title":"Mount","text":"<p>Represents a mount exported and mounted to a remote host.</p> <pre><code>from dlpx.virtualization.platform import Mount\nmount = Mount(environment, path)\n</code></pre>"},{"location":"References/Classes/#fields_4","title":"Fields","text":"Field Type Description remote_environment RemoteEnvironment or Reference Environment for the connection. mount_path String The path on the remote host that has the mounted data set. shared_path String Optional. The path of the subdirectory of the data set to mount to the remote host."},{"location":"References/Classes/#ownershipspecification","title":"OwnershipSpecification","text":"<p>Represents how to set the ownership for a data set. This only applies to Unix Hosts.</p> <pre><code>from dlpx.virtualization.platform import OwnershipSpecification\nownership_specification = OwnershipSpecification(uid, gid)\n</code></pre>"},{"location":"References/Classes/#fields_5","title":"Fields","text":"Field Type Description uid Integer The user id to set the ownership of the data set to. gid Integer The group id to set the ownership of the data set to."},{"location":"References/Classes/#mountspecification","title":"MountSpecification","text":"<p>Represents properties for the mount associated with an exported data set.</p> <pre><code>from dlpx.virtualization.platform import MountSpecification\nmount_specification = MountSpecification([mount], ownership_specification)\n</code></pre>"},{"location":"References/Classes/#fields_6","title":"Fields","text":"Field Type Description mounts list[Mount] The list of mounts to export the data sets to. ownership_specification OwnershipSpecification Optional. Control the ownership attributes for the data set. It defaults to the environment user of the remote environment if it is not specified."},{"location":"References/Classes/#remoteenvironment","title":"RemoteEnvironment","text":"<p>Represents a remote environment.</p> <pre><code>from dlpx.virtualization.common import RemoteEnvironment\nenvironment = RemoteEnvironment(name, reference, host)\n</code></pre>"},{"location":"References/Classes/#fields_7","title":"Fields","text":"Field Type Description name String Name of the environment. reference String Unique identifier for the environment. host RemoteHost Host that belongs to the environment."},{"location":"References/Classes/#remotehost","title":"RemoteHost","text":"<p>Represents a remote host, can be Unix or Windows.</p> <pre><code>from dlpx.virtualization.common import RemoteHost\nhost = RemoteHost(name, reference, binary_path, scratch_path)\n</code></pre>"},{"location":"References/Classes/#fields_8","title":"Fields","text":"Field Type Description name String Host address. reference String Unique identifier for the host. binary_path String Path to Delphix provided binaries on the host, which are present in the toolkit pushed to the remote host like <code>dlpx_db_exec</code>, <code>dlpx_pfexec</code>, etc. This property is only available for Unix hosts. scratch_path String Path to scratch area on the host. See details here."},{"location":"References/Classes/#remoteuser","title":"RemoteUser","text":"<p>Represents a user on a remote host.</p> <pre><code>from dlpx.virtualization.common import RemoteUser\nuser = RemoteUser(name, reference)\n</code></pre>"},{"location":"References/Classes/#fields_9","title":"Fields","text":"Field Type Description name String User name. reference String Unique identifier for the user."},{"location":"References/Classes/#credentials","title":"Credentials","text":"<p>Abstract class representing credentials that include a user name. Instances of this class are returned by the <code>retrieve_credentials</code> library call.</p> <pre><code>from dlpx.virtualization import libs\nfrom dlpx.virtualization.common import Credentials\nfrom dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.stop()\ndef my_virtual_stop(virtual_source, repository, source_config):\ncredentials = libs.retrieve_credentials(virtual_source.parameters.credentials_supplier)\nassert isinstance(credentials, Credentials)\nenvironment_vars = {\n\"DATABASE_USERNAME\" : credentials.username\n}\n...\n</code></pre>"},{"location":"References/Classes/#fields_10","title":"Fields","text":"Field Type Description username String User name. Empty string if not present."},{"location":"References/Classes/#keypaircredentials","title":"KeyPairCredentials","text":"<p>Concrete subclass of Credentials that represents key-pair credentials. Instances of this class may returned by the <code>retrieve_credentials</code> library call.</p> <pre><code>from dlpx.virtualization import libs\nfrom dlpx.virtualization.common import KeyPairCredentials\nfrom dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.stop()\ndef my_virtual_stop(virtual_source, repository, source_config):\ncredentials = libs.retrieve_credentials(virtual_source.parameters.key_pair_supplier)\nassert isinstance(credentials, KeyPairCredentials)\nenvironment_vars = {\n\"DATABASE_USERNAME\" : credentials.username,\n\"DATABASE_PRIVATE_KEY\" : credentials.private_key,\n\"DATABASE_PUBLIC_KEY\" : credentials.public_key\n}\n...\n</code></pre>"},{"location":"References/Classes/#fields_11","title":"Fields","text":"Field Type Description username String User name. Empty string if not present. private_key String Private key. public_key String Public key corresponding to private key. Empty string if not present."},{"location":"References/Classes/#passwordcredentials","title":"PasswordCredentials","text":"<p>Concrete subclass of Credentials that represents password credentials. Instances of this class may returned by the <code>retrieve_credentials</code> library call.</p> <pre><code>from dlpx.virtualization import libs\nfrom dlpx.virtualization.common import PasswordCredentials\nfrom dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.stop()\ndef my_virtual_stop(virtual_source, repository, source_config):\ncredentials = libs.retrieve_credentials(virtual_source.parameters.password_supplier)\nassert isinstance(credentials, PasswordCredentials)\nenvironment_vars = {\n\"DATABASE_USERNAME\" : credentials.username,\n\"DATABASE_PASSWORD\" : credentials.password\n}\n...\n</code></pre>"},{"location":"References/Classes/#fields_12","title":"Fields","text":"Field Type Description username String User name. Empty string if not present. password String Password."},{"location":"References/Decorators/","title":"Decorators","text":"<p>The Virtualization SDK exposes decorators to be able to annotate functions that correspond to each Plugin Operation. In the example below, it first instantiates a <code>Plugin()</code> object, that can then be used to tag plugin operations.</p> <pre><code>from dlpx.virtualization.platform import Plugin\n# Initialize a plugin object\nplugin = Plugin()\n# Use the decorator to annotate the function that corresponds to the \"Virtual Source Start\" Plugin Operation\n@plugin.virtual_source.start()\ndef my_start(virtual_source, repository, source_config):\nprint(\"running start\")\n</code></pre> <p>Info</p> <p>Decorators exposed by the Virtualization SDK are inherently python function calls and needs parentheses <code>()</code> appended at the end.</p> <p>Assuming the name of the object is <code>plugin</code> as above, the table below lists the corresponding decorators for each plugin operation.</p> Plugin Operation Decorator Repository Discovey <code>@plugin.discovery.repository()</code> Source Config Discovey <code>@plugin.discovery.source_config()</code> Direct Linked Source Pre-Snapshot <code>@plugin.linked.pre_snapshot()</code> Direct Linked Source Post-Snapshot <code>@plugin.linked.post_snapshot()</code> Direct Linked Source Size <code>@plugin.linked.source_size()</code> Staged Linked Source Pre-Snapshot <code>@plugin.linked.pre_snapshot()</code> Staged Linked Source Post-Snapshot <code>@plugin.linked.post_snapshot()</code> Staged Linked Source Start-Staging <code>@plugin.linked.start_staging()</code> Staged Linked Source Stop-Staging <code>@plugin.linked.stop_staging()</code> Staged Linked Source Status <code>@plugin.linked.status()</code> Staged Linked Source Worker <code>@plugin.linked.worker()</code> Staged Linked Source Mount Specification <code>@plugin.linked.mount_specification()</code> Staged Linked Source Size <code>@plugin.linked.source_size()</code> Virtual Source Configure <code>@plugin.virtual.configure()</code> Virtual Source Initialize <code>@plugin.virtual.initialize()</code> Virtual Source Unconfigure <code>@plugin.virtual.unconfigure()</code> Virtual Source Reconfigure <code>@plugin.virtual.reconfigure()</code> Virtual Source Cleanup <code>@plugin.virtual.cleanup()</code> Virtual Source Start <code>@plugin.virtual.start()</code> Virtual Source Stop <code>@plugin.virtual.stop()</code> VirtualSource Pre-Snapshot <code>@plugin.virtual.pre_snapshot()</code> Virtual Source Post-Snapshot <code>@plugin.virtual.post_snapshot()</code> Virtual Source Mount Specification <code>@plugin.virtual.mount_specification()</code> Virtual Source Status <code>@plugin.virtual.status()</code> Virtual Source Size <code>@plugin.virtual.source_size()</code> Repository Data Migration <code>@plugin.upgrade.repository(migration_id)</code> Source Config Data Migration <code>@plugin.upgrade.source_config(migration_id)</code> Linked Source Data Migration <code>@plugin.upgrade.linked_source(migration_id)</code> Virtual Source Data Migration <code>@plugin.upgrade.virtual_source(migration_id)</code> Snapshot Data Migration <code>@plugin.upgrade.snapshot(migration_id)</code> <p>Warning</p> <p>A plugin should only implement the direct operations or the staged operations based on the plugin type.</p>"},{"location":"References/Glossary/","title":"Glossary","text":""},{"location":"References/Glossary/#artifact","title":"Artifact","text":"<p>A single file that is the result of a build. It is this artifact which is distributed to users, and which is installed onto engines.</p>"},{"location":"References/Glossary/#automatic-discovery","title":"Automatic Discovery","text":"<p>Discovery which is done by the Delphix Engine (with help from a plugin) itself, with no need for the end user to provide any information.</p>"},{"location":"References/Glossary/#building","title":"Building","text":"<p>The process of creating an artifact from the collection of files that make up the plugin's source code.</p>"},{"location":"References/Glossary/#data-migration","title":"Data Migration","text":"<p>A python function which is called as part of the upgrade process. It handles transforming data from an older format to a newer format. More details here.</p>"},{"location":"References/Glossary/#data-migration-id","title":"Data Migration ID","text":"<p>Each data migration is tagged with a unique ID. This allows the Delphix Engine to know which data migrations need to be run, in which order, when upgrading to a new plugin version. More details here.</p>"},{"location":"References/Glossary/#decorator","title":"Decorator","text":"<p>A Python construct which is used by plugins to \"tag\" certain functions, so that the Delphix Engine knows which function corresponds to which plugin operation.</p>"},{"location":"References/Glossary/#direct-linking","title":"Direct Linking","text":"<p>A strategy that involves data being ingested directly from the source environment onto the Delphix Engine, without the assistance of a staging environment.</p>"},{"location":"References/Glossary/#discovery","title":"Discovery","text":"<p>The process by which the Delphix Engine learns about how a particular environment can be used for ingesting or virtualizing datasets.</p>"},{"location":"References/Glossary/#dsource","title":"dSource","text":"<p>See Linked Dataset</p>"},{"location":"References/Glossary/#empty-vdb","title":"Empty VDB","text":"<p>A VDB that is created from scratch, without provisioning from another dataset. Users can create empty VDBs when they want to construct a brand-new dataset from within Delphix, instead of creating it externally and then ingesting it.</p> <p>This \"empty\" VDB, of course, will typically not stay empty for long. Data will be added as users work with the new dataset.</p> <p>A plugin can support this functionality by implementing the initialize operation.</p>"},{"location":"References/Glossary/#environment","title":"Environment","text":"<p>A remote system that the Delphix Engine can interact with. An environment can be used as a source, staging or target environment (or any combination of those).  For example, a Linux machine that the Delphix Engine can connect to is an environment.</p>"},{"location":"References/Glossary/#environment-user","title":"Environment User","text":"<p>A set of user credentials that the Delphix Engine can use to interact with an Environmnet. For example, a username and password to login to a Linux machine.</p>"},{"location":"References/Glossary/#linked-dataset","title":"Linked Dataset","text":"<p>A dataset on the Delphix Engine which holds an ingested copy of a pre-existing external dataset from a source environment. A linked dataset is often called a dSource.</p>"},{"location":"References/Glossary/#linked-source","title":"Linked Source","text":"<p>An object on the Delphix Engine that holds information related to a linked dataset.</p>"},{"location":"References/Glossary/#linking","title":"Linking","text":"<p>The process by which the Delphix Engine connects a new dSource to a pre-existing dataset on a source environment.</p>"},{"location":"References/Glossary/#logging","title":"Logging","text":"<p>Logging is when a plugin writes out some human-readable information to a log file. The log file can then be examined, typically in order to debug a problem with the plugin.</p>"},{"location":"References/Glossary/#plugin-config","title":"Plugin Config","text":"<p>A YAML file containing a list of plugin properties: What is the plugin's name? What version of the plugin is this? Etc. More details here.</p>"},{"location":"References/Glossary/#manual-discovery","title":"Manual Discovery","text":"<p>Discovery which the end user does by manually entering the necessary information into the Delphix Engine.</p>"},{"location":"References/Glossary/#mount-specification","title":"Mount Specification","text":"<p>A collection of information, provided by the plugin, which give all the details about how and where virtual datasets should be mounted onto target environments. This term is often shortened to \"Mount Spec\".</p>"},{"location":"References/Glossary/#password-properties","title":"Password Properties","text":"<p>In schemas, any string property can be tagged with <code>\"format\": \"password\"</code>. This will let the Delphix Engine know that the property contains sensitive information. Any such values will only be stored in encrypted format, and the UI will not display the values on screen.</p>"},{"location":"References/Glossary/#platform-libraries","title":"Platform Libraries","text":"<p>A set of Python functions that are provided by the Virtualization Platform. Plugins use these library functions to request that the Virtualization Platform do some task on behalf of the plugin. For example, running a Bash command on an environment, or making an log entry.</p>"},{"location":"References/Glossary/#plugin","title":"Plugin","text":"<p>A tool that customizes the Delphix Engine so it knows how to interact with a particular kind of dataset.</p>"},{"location":"References/Glossary/#plugin-operation","title":"Plugin Operation","text":"<p>A piece of functionality that provided by a plugin in order to customize Delphix Engine behavior to work with a particular kind of dataset. A plugin operation is implemented as a Python function. For example, a MySQL plugin might provide an operation called \"stop\" which knows how to stop a MySQL database.</p>"},{"location":"References/Glossary/#provisioning","title":"Provisioning","text":"<p>The process of making a virtual copy of a dataset and making it available for use on a target environment.</p>"},{"location":"References/Glossary/#replication","title":"Replication","text":"<p>Delphix allows end users to replicate data objects between Delphix Engines by creating a replication profile. Data objects that belong to a plugin can also be part of the replication profile. Refer to the Delphix Engine Documentation for more details.</p>"},{"location":"References/Glossary/#repository","title":"Repository","text":"<p>Information that represents a set of dependencies that a dataset requires in order to be functional. For example, a particular Postgres database might require an installed Postgres 9.6 DBMS, and so its associated repository would contain all the information required to interact with that DBMS.</p>"},{"location":"References/Glossary/#schema","title":"Schema","text":"<p>A formal description of a data type. Plugins use JSON format for their schemas.</p>"},{"location":"References/Glossary/#snapshot","title":"Snapshot","text":"<p>A point-in-time read-only copy of a dataset. A snapshot includes associated metadata represented by the SnapshotDefinition Schema.</p>"},{"location":"References/Glossary/#snapshot-parameters","title":"Snapshot Parameters","text":"<p>User provided parameters for the snapshot operation which can be defined in a Snapshot Parameters Definition.</p>"},{"location":"References/Glossary/#source-config","title":"Source Config","text":"<p>A collection of information that the Delphix Engine needs to interact with a dataset (whether linked or virtual on an environment.</p>"},{"location":"References/Glossary/#source-environment","title":"Source Environment","text":"<p>An environment containing data that is ingested by the Delphix Engine.</p>"},{"location":"References/Glossary/#staged-linking","title":"Staged Linking","text":"<p>A strategy where a staging environment is used to coordinate the ingestion of data into a dsource.</p>"},{"location":"References/Glossary/#staging-environment","title":"Staging Environment","text":"<p>An environment used by the Delphix Engine to coordinate ingestion from a source environment.</p>"},{"location":"References/Glossary/#syncing","title":"Syncing","text":"<p>The process by which the Delphix Engine ingests data from a dataset on a source environment into a dsource. Syncing always happens immediately after linking, and typically is done periodically thereafter.</p>"},{"location":"References/Glossary/#target-environment","title":"Target Environment","text":"<p>An environment on which Delphix-provided virtualized datasets can be used.</p>"},{"location":"References/Glossary/#lua-toolkit","title":"Lua Toolkit","text":"<p>Legacy model for writing \"plugins\" in Lua, with limited documentation and limited support for writing, building and uploading toolkits. This was the predecessor to the Virtualization SDK.</p>"},{"location":"References/Glossary/#upgrade-operation","title":"Upgrade Operation","text":"<p>A special plugin operation that takes data produced by an older version of a plugin, and transforms it into the format expected by the new version of the plugin.</p>"},{"location":"References/Glossary/#vdb","title":"VDB","text":"<p>See Virtual Dataset</p>"},{"location":"References/Glossary/#version","title":"Version","text":"<p>A string identifier that is unique for every public release of a plugin.</p>"},{"location":"References/Glossary/#virtual-dataset","title":"Virtual Dataset","text":"<p>A dataset that has been cloned from a snapshot, and whose data is stored on the Delphix Engine. A virtual dataset is made available for use by mounting it to a target environment. A virtual dataset is often called a \"VDB\".</p>"},{"location":"References/Glossary/#virtual-source","title":"Virtual Source","text":"<p>An object on the Delphix Engine that holds information related to a virtual dataset.</p>"},{"location":"References/Glossary/#yaml","title":"YAML","text":"<p>YAML is a simple language often used for configuration files. Plugins define their plugin config using YAML.</p>"},{"location":"References/Logging/","title":"Logging","text":""},{"location":"References/Logging/#what-is-logging","title":"What is logging?","text":"<p>The Virtualization Platform keeps plugin-specific log files. A plugin can, at any point in any of its plugin operations, write out some text to its log file(s). These log files can be examined later, typically to try to debug a problem with the plugin.</p>"},{"location":"References/Logging/#overview","title":"Overview","text":"<p>The Virtualization Platform integrates with Python's built-in logging framework. A special Handler is exposed by the platform at <code>dlpx.virtualization.libs.PlatformHandler</code>. This handler needs to be added to the Python logger your plugin creates. Logging statements made through Python's logging framework will then be routed to the platform.</p>"},{"location":"References/Logging/#basic-setup","title":"Basic Setup","text":"<p>Below is the absolute minimum needed to setup logging for the platform. Please refer to Python's logging documentation and the example below to better understand how it can be customized.</p> <pre><code>import logging\nfrom dlpx.virtualization.libs import PlatformHandler\n# Get the root logger.\nlogger = logging.getLogger()\nlogger.addHandler(PlatformHandler())\n# The root logger's default level is logging.WARNING.\n# Without the line below, logging statements of levels\n# lower than logging.WARNING will be suppressed.\nlogger.setLevel(logging.DEBUG)\n</code></pre> <p>Logging Setup</p> <p>Python's logging framework is global. Setup only needs to happen once, but where it happens is important. Any logging statements that occur before the <code>PlatformHandler</code> is added will not be logged by the platform.</p> <p>It is highly recommended that the logging setup is done in the plugin's entry point module before any operations are ran.</p> <p>Add the PlatformHandler to the root logger</p> <p>Loggers in Python have a hierarchy and all loggers are children of a special logger called the \"root logger\". Logging hierarchy is not always intuitive and depends on how modules are structured.</p> <p>To avoid this complexity, add the <code>PlatformHandler</code> to the root logger. The root logger can be retrieved with <code>logging.getLogger()</code>.</p> <p>Warning</p> <p>There is a limit to how much data can be stored within a log message. See Message Limits for details.</p>"},{"location":"References/Logging/#usage","title":"Usage","text":"<p>Once the <code>PlatformHandler</code> has been added to the logger, logging is done with Python's Logger object. Below is a simple example including the basic setup code used above:</p> <pre><code>import logging\nfrom dlpx.virtualization.libs import PlatformHandler\nlogger = logging.getLogger()\nlogger.addHandler(PlatformHandler())\n# The root logger's default level is logging.WARNING.\n# Without the line below, logging statements of levels\n# lower than logging.WARNING will be suppressed.\nlogger.setLevel(logging.DEBUG)\nlogger.debug('debug')\nlogger.info('info')\nlogger.error('error')\n</code></pre>"},{"location":"References/Logging/#example","title":"Example","text":"<p>Imagine you notice that your plugin is taking a very long time to do discovery. Everything works, it just takes much longer than expected. You'd like to figure out why.</p> <p>Info</p> <p>Refer to Managing Scripts for Remote Execution for how remote scripts can be stored and retrieved.</p> <p>Suppose your plugin has a source config discovery operation that looks like this (code is abbreviated to be easier to follow): <pre><code>from importlib import resources\nfrom dlpx.virtualization import libs\nfrom dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.discovery.repository()\ndef repository_discovery(source_connection): \nreturn [RepositoryDefinition('Logging Example')]\n@plugin.discovery.source_config()\ndef source_config_discovery(source_connection, repository):\nversion_result = libs.run_bash(source_connection, resources.read_text('resources', 'get_db_version.sh'))\nusers_result = libs.run_bash(source_connection, resources.read_text('resources', 'get_db_users.sh'))\ndb_results = libs.run_bash(source_connection, resources.read_text('resources', 'get_databases.sh'))\nstatus_result = libs.run_bash(source_connection, resources.read_text('resources', 'get_database_statuses.sh'))\n# Return an empty list for simplicity. In reality\n# something would be done with the results above.\nreturn []\n</code></pre></p> <p>Warning</p> <p>If developing a plugin in Python 2.7, you will need to use <code>pkgutil.get_data</code> rather than <code>importlib.resources.read_text</code>.</p> <p>See Managing Scripts For Remote Execution for more info.</p> <p>Now, imagine that you notice that it's taking a long time to do discovery, and you'd like to try to figure out why. One thing that might help is to add logging, like this: <pre><code>import logging\nfrom importlib import resources\nfrom dlpx.virtualization import libs\nfrom dlpx.virtualization.platform import Plugin\nfrom generated.definitions import RepositoryDefinition\n# This should probably be defined in its own module outside\n# of the plugin's entry point file. It is here for simplicity.\ndef _setup_logger():\n# This will log the time, level, filename, line number, and log message.\nlog_message_format = '[%(asctime)s] [%(levelname)s] [%(filename)s:%(lineno)d] %(message)s'\nlog_message_date_format = '%Y-%m-%d %H:%M:%S'\n# Create a custom formatter. This will help with diagnosability.\nformatter = logging.Formatter(log_message_format, datefmt= log_message_date_format)\nplatform_handler = libs.PlatformHandler()\nplatform_handler.setFormatter(formatter)\nlogger = logging.getLogger()\nlogger.addHandler(platform_handler)\n# By default the root logger's level is logging.WARNING.\nlogger.setLevel(logging.DEBUG)\n# Setup the logger.\n_setup_logger()\n# logging.getLogger(__name__) is the convention way to get a logger in Python.\n# It returns a new logger per module and will be a child of the root logger.\n# Since we setup the root logger, nothing else needs to be done to set this\n# one up.\nlogger = logging.getLogger(__name__)\nplugin = Plugin()\n@plugin.discovery.repository()\ndef repository_discovery(source_connection): \nreturn [RepositoryDefinition('Logging Example')]\n@plugin.discovery.source_config()\ndef source_config_discovery(source_connection, repository):\nlogger.debug('About to get DB version')\nversion_result = libs.run_bash(source_connection, resources.read_text('resources', 'get_db_version.sh'))\nlogger.debug('About to get DB users')\nusers_result = libs.run_bash(source_connection, resources.read_text('resources', 'get_db_users.sh'))\nlogger.debug('About to get databases')\ndb_results = libs.run_bash(source_connection, resources.read_text('resources', 'get_databases.sh'))\nlogger.debug('About to get DB statuses')\nstatus_result = libs.run_bash(source_connection, resources.read_text('resources', 'get_database_statuses.sh'))\nlogger.debug('Done collecting data')\n# Return an empty list for simplicity. In reality\n# something would be done with the results above.\nreturn []\n</code></pre></p> <p>When you look at the log file, perhaps you'll see something like this:</p> <pre><code>[Worker-360|JOB-315|ENVIRONMENT_DISCOVER(UNIX_HOST_ENVIRONMENT-5)] [2019-04-30 12:10:42] [DEBUG] [python_runner.py:44] About to get DB version\n[Worker-360|JOB-316|DB_SYNC(APPDATA_CONTAINER-21)] [2019-04-30 12:19:35] [DEBUG] [python_runner.py:49] About to get DB users\n[Worker-325|JOB-280|ENVIRONMENT_REFRESH(UNIX_HOST_ENVIRONMENT-5)] [DEBUG] [plugin_runner.py:51] About to get databases\n[Worker-326|JOB-281|SOURCES_DISABLE(UNIX_HOST_ENVIRONMENT-5)] [DEBUG] [plugin_runner.py:53] About to get DB statuses\n</code></pre> <p>You can see that it only takes a few seconds for us do each of our data collection steps, with the exception of getting the users, which takes over 13 minutes!</p> <p>We now know that our slowdown is something to do with how our bash script is collecting all the users. Logging has gotten us a lot closer to figuring out the problem.</p>"},{"location":"References/Logging/#how-to-retrieve-logs","title":"How to retrieve logs","text":"<p>Download a support bundle by going to Help &gt; Support Logs  and select Download. The logs will be in a the support bundle under <code>log/mgmt_log/plugin_log/&lt;plugin name&gt;</code>.</p>"},{"location":"References/Logging/#logging-levels","title":"Logging Levels","text":"<p>Python has a number of preset logging levels and allows for custom ones as well. Since logging on the Virtualization Platform uses the <code>logging</code> framework, log statements of all levels are supported.</p> <p>However, the Virtualization Platform will map all logging levels into three files: <code>debug.log</code>, <code>info.log</code>, and <code>error.log</code> in the following way:</p> Python Logging Level Logging File DEBUG debug.log INFO info.log WARN error.log WARNING error.log ERROR error.log CRITICAL error.log <p>As is the case with the <code>logging</code> framework, logging statements are hierarchical: logging statements made at the <code>logging.DEBUG</code> level will be written only to <code>debug.log</code> while logging statements made at the <code>logging.ERROR</code> level will be written to <code>debug.log</code>, <code>info.log</code>, and <code>error.log</code>.</p>"},{"location":"References/Logging/#sensitive-data","title":"Sensitive data","text":"<p>Remember that logging data means writing that data out in cleartext. Make sure you never log any data that could be secret or sensitive (passwords, etc.). For more details please see our section on sensitive data</p>"},{"location":"References/Platform_Libraries/","title":"Platform Libraries","text":"<p>Delphix provides a set of functions that plugins can use for executing remote commands, etc.</p>"},{"location":"References/Platform_Libraries/#retrieve_credentials","title":"retrieve_credentials","text":"<p>Takes a credentials-supplier object and returns a <code>PasswordCredentials</code> or <code>KeyPairCredentials</code> object. If the credentials supplier refers to a password vault, the operation obtains the credentials from that vault.</p> <p>The operation accepts only credentials-supplier objects exactly as provided by parameters of the plugin operation, without any changes. Credential suppliers are effectively opaque to plugin code; their internals can change without notice.</p>"},{"location":"References/Platform_Libraries/#signature","title":"Signature","text":"<p><code>def retrieve_credentials(credentials_supplier)</code></p>"},{"location":"References/Platform_Libraries/#arguments","title":"Arguments","text":"Argument Type Description credentials_supplier dict Unmodified object provided within the <code>parameters</code> field of a plugin operation parameter that conforms to <code>credentialsSupplier</code>, <code>passwordCredentialsSupplier</code>, or <code>keyCredentialsSupplier</code>."},{"location":"References/Platform_Libraries/#returns","title":"Returns","text":"<p>An object of the abstract type <code>Credentials</code>. Concretely, a <code>PasswordCredentials</code> or <code>KeyPairCredentials</code>.</p>"},{"location":"References/Platform_Libraries/#throws","title":"Throws","text":"<p>An exception with a descriptive <code>message</code> attribute if either:</p> <ol> <li>The secret is returned by the vault and the type of this secret does not match the type(s) required by the <code>expectedSecretType</code> property of the credentials supplier. For example, this occurs when the secret is a <code>keyPair</code> but <code>expectedSecretType</code> is set to <code>password</code>. Or,</li> <li>The <code>credentials_supplier</code> parameter does not equal any credentials supplier passed to the plugin by the engine.</li> </ol>"},{"location":"References/Platform_Libraries/#example","title":"Example","text":"<pre><code>from dlpx.virtualization import libs\nfrom dlpx.virtualization.common import PasswordCredentials\n@plugin.virtual.stop()\ndef my_virtual_stop(virtual_source, repository, source_config):\ncredentials = libs.retrieve_credentials(virtual_source.parameters.db_credentials_supplier)\nenvironment_vars = { \"DATABASE_USERNAME\" : credentials.username }\nif isinstance(credentials, PasswordCredentials):\nenvironment_vars[\"DATABASE_PASSWORD\"] = credentials.password\nelse:\nenvironment_vars[\"DATABASE_KEY\"] = credentials.private_key\n</code></pre>"},{"location":"References/Platform_Libraries/#run_bash","title":"run_bash","text":"<p>Executes a bash command on a remote Unix host.</p>"},{"location":"References/Platform_Libraries/#signature_1","title":"Signature","text":"<p><code>def run_bash(remote_connection, command, variables=None, use_login_shell=False, check=False)</code></p>"},{"location":"References/Platform_Libraries/#arguments_1","title":"Arguments","text":"Argument Type Description remote_connection RemoteConnection Connection associated with the remote host to run the command on. command String Command to run on the host. variables dict[String, String] Optional. Environment variables to set when running the command. use_login_shell boolean Optional. Whether to use a login shell. check boolean Optional. Whether or not to raise an exception if the <code>exit_code</code> in the <code>RunBashResponse</code> is non-zero."},{"location":"References/Platform_Libraries/#returns_1","title":"Returns","text":"<p>An object of <code>RunBashResponse</code></p> Field Type Description exit_code Integer Exit code from the command. stdout String Stdout from the command. stderr String Stderr from the command."},{"location":"References/Platform_Libraries/#examples","title":"Examples","text":""},{"location":"References/Platform_Libraries/#calling-bash-with-an-inline-command","title":"Calling bash with an inline command.","text":"<pre><code>from dlpx.virtualization import libs\ncommand = \"echo 'Hi' &gt;&gt; /tmp/debug.log\"\nvariables = {\"var\": \"val\"}\nresponse = libs.run_bash(connection, command, variables)\nprint response.exit_code\nprint response.stdout\nprint response.stderr\n</code></pre>"},{"location":"References/Platform_Libraries/#using-parameters-to-construct-a-bash-command","title":"Using parameters to construct a bash command.","text":"<pre><code>from dlpx.virtualization import libs\nname = virtual_source.parameters.username\nport = virtual_source.parameters.port\ncommand = \"mysqldump -u {} -p {}\".format(name,port)\nresponse = libs.run_bash(connection, command)\n</code></pre>"},{"location":"References/Platform_Libraries/#running-a-bash-script-that-is-saved-in-a-directory","title":"Running a bash script that is saved in a directory.","text":""},{"location":"References/Platform_Libraries/#python-27-recommended-approach","title":"Python 2.7 recommended approach","text":"<pre><code> import pkgutil\nfrom dlpx.virtualization import libs\nscript_content = pkgutil.get_data('resources', 'get_date.sh')\n# Execute script on remote host\nresponse = libs.run_bash(direct_source.connection, script_content)\n</code></pre>"},{"location":"References/Platform_Libraries/#python-38-recommended-approach","title":"Python 3.8 recommended approach","text":"<p><pre><code> from importlib import resources\nfrom dlpx.virtualization import libs\nscript_content = resources.read_text('resources', 'get_date.sh')\n# Execute script on remote host\nresponse = libs.run_bash(direct_source.connection, script_content)\n</code></pre> For more information please go to Managing Scripts for Remote Execution section.</p>"},{"location":"References/Platform_Libraries/#run_expect","title":"run_expect","text":"<p>Executes a tcl command or script on a remote Unix host.</p>"},{"location":"References/Platform_Libraries/#signature_2","title":"Signature","text":"<p><code>def run_expect(remote_connection, command, variables=None)</code></p>"},{"location":"References/Platform_Libraries/#arguments_2","title":"Arguments","text":"Argument Type Description remote_connection RemoteConnection Connection associated with the remote host to run the command on. command String Expect(Tcl) command to run. variables dict[String, String] Optional. Environment variables to set when running the command."},{"location":"References/Platform_Libraries/#returns_2","title":"Returns","text":"<p>An object of <code>RunExpectResponse</code></p> Field Type Description exit_code Integer Exit code from the command. stdout String Stdout from the command. stderr String Stderr from the command."},{"location":"References/Platform_Libraries/#example_1","title":"Example","text":"<p>Calling expect  with an inline command.</p> <pre><code>from dlpx.virtualization import libs\ncommand = \"puts 'Hi'\"\nvariables = {\"var\": \"val\"}\nrepsonse = libs.run_expect(connection, command, variables)\nprint response.exit_code\nprint response.stdout\nprint response.stderr\n</code></pre>"},{"location":"References/Platform_Libraries/#run_powershell","title":"run_powershell","text":"<p>Executes a powershell command on a remote Windows host.</p>"},{"location":"References/Platform_Libraries/#signature_3","title":"Signature","text":"<p><code>def run_powershell(remote_connection, command, variables=None, check=False)</code></p>"},{"location":"References/Platform_Libraries/#arguments_3","title":"Arguments","text":"Argument Type Description remote_connection RemoteConnection Connection associated with the remote host to run the command on. command String Command to run to the remote host. variables dict[String, String] Optional. Environment variables to set when running the command. check boolean Optional. Whether or not to raise an exception if the <code>exit_code</code> in the <code>RunPowershellResponse</code> is non-zero."},{"location":"References/Platform_Libraries/#returns_3","title":"Returns","text":"<p>An object of <code>RunPowershellResponse</code></p> Field Type Description exit_code Integer Exit code from the command. stdout String Stdout from the command. stderr String Stderr from the command."},{"location":"References/Platform_Libraries/#example_2","title":"Example","text":"<p>Calling powershell with an inline command.</p> <pre><code>from dlpx.virtualization import libs\ncommand = \"Write-Output 'Hi'\"\nvariables = {\"var\": \"val\"}\nresponse = libs.run_powershell(connection, command, variables)\nprint response.exit_code\nprint response.stdout\nprint response.stderr\n</code></pre>"},{"location":"References/Platform_Libraries/#run_sync","title":"run_sync","text":"<p>Copies files from the remote source host directly into the dSource, without involving a staging host.</p>"},{"location":"References/Platform_Libraries/#signature_4","title":"Signature","text":"<p><code>def run_sync(remote_connection, source_directory, rsync_user=None, exclude_paths=None, sym_links_to_follow=None)</code></p>"},{"location":"References/Platform_Libraries/#arguments_4","title":"Arguments","text":"Argument Type Description remote_connection RemoteConnection Connection associated with the remote host to run the command on. source_directory String Directory of files to be synced. rsync_user String Optional User who has access to the directory to be synced. exclude_paths list[String] Optional Paths to be excluded. sym_links_to_follow list[String] Optional Symbollic links to follow if any."},{"location":"References/Platform_Libraries/#returns_4","title":"Returns","text":"<p>None</p>"},{"location":"References/Platform_Libraries/#example_3","title":"Example","text":"<pre><code>from dlpx.virtualization import libs\nsource_directory = \"sourceDirectory\"\nrsync_user = \"rsyncUser\"\nexclude_paths = [\"/path1\", \"/path2\"]\nsym_links_to_follow = [\"/path3\", \"/path4\"]\nlibs.run_sync(connection, source_directory, rsync_user, exclude_paths, sym_links_to_follow)\n</code></pre>"},{"location":"References/Platform_Libraries/#upgrade_password","title":"upgrade_password","text":"<p>Takes a plain password and, optionally, a user name and converts them to an object that conforms to <code>credentialsSupplier</code>. This function generalizes an existing password property to allow users to later select an alternative source, such as a password vault.</p> <p>This function can be called only from data migrations. The resulting object can be assigned to a property of type <code>credentialsSupplier</code> or  <code>passwordCredentialsSupplier</code>.</p>"},{"location":"References/Platform_Libraries/#signature_5","title":"Signature","text":"<p><code>def upgrade_password(password, username=None)</code></p>"},{"location":"References/Platform_Libraries/#arguments_5","title":"Arguments","text":"Argument Type Description password String A plain password. username String Optional. A user name."},{"location":"References/Platform_Libraries/#returns_5","title":"Returns","text":"<p>A <code>dict</code> object that conforms to <code>passwordCredentialsSupplier</code>.</p>"},{"location":"References/Platform_Libraries/#example_4","title":"Example","text":"<pre><code>from dlpx.virtualization import libs\n@plugin.upgrade.linked_source(\"2021.02.15\")\ndef convert_password_to_credentials_supplier(old_linked_source):\nnew_linked_source = dict(old_linked_source)\npassword = old_linked_source[\"credentials\"]\nusername = old_linked_source[\"username\"]\nnew_linked_source[\"credentials\"] = libs.upgrade_password(password, username)\ndel new_linked_source[\"username\"]\nreturn new_linked_source\n</code></pre>"},{"location":"References/Plugin_Config/","title":"Plugin Config","text":"<p>The plugin config is a YAML file that marks the root of a plugin and defines metadata about the plugin and its structure. The config file is read at build time to generate the upload artifact.</p> <p>The name of the file can be specified during the build. By default, the build looks for <code>plugin_config.yml</code> in the current working directory.</p>"},{"location":"References/Plugin_Config/#fields","title":"Fields","text":"Field Name Required Type Description id Y string The unique id of the plugin in a valid UUID format. name N string The display name of the plugin. This will be used in the UI. If it is not specified name will be equal to id. externalVersion N string The plugin's external version. This is a freeform string. If it is not supplied, the build number is used as an external version. buildNumber Y string The plugin's build number. This string must conform to the format described here. hostTypes Y list The host type that the plugin supports. Either <code>UNIX</code> or <code>WINDOWS</code>. schemaFile Y string The path to the JSON file that contains the plugin's schema definitions.This path can be absolute or relative to the directory containing the plugin config file. srcDir Y string The path to the directory that contains the source code for the plugin. During execution of a plugin operation, this directory will be the current working directory of the Python interpreter. Any modules or resources defined outside of this directory will be inaccessible at runtime.This path can be absolute or relative to the directory containing the plugin config file. entryPoint Y string A fully qualified Python symbol that points to the <code>dlpx.virtualization.platform.Plugin</code> object that defines the plugin.It must be in the form <code>importable.module:object_name</code> where <code>importable.module</code> is in <code>srcDir</code>. manualDiscovery N boolean True if the plugin supports manual discovery of source config objects. The default value is <code>true</code>. pluginType Y enum The ingestion strategy of the plugin. Can be either <code>STAGED</code> or <code>DIRECT</code>. language Y enum Must be <code>PYTHON38</code>. defaultLocale N enum The locale to be used by the plugin if the Delphix user does not specify one. Plugin messages will be displayed in this locale by default. The default value is <code>en-us</code>. rootSquashEnabled N boolean This dictates whether \"root squash\" is enabled on NFS mounts for the plugin (i.e. whether the <code>root</code> user on remote hosts has access to the NFS mounts). Setting this to <code>false</code> allows processes usually run as <code>root</code>, like Docker daemons, access to the NFS mounts. The default value is <code>true</code>. This field only applies to Unix hosts. extendedStartStopHooks N boolean This controls whether the user's pre-start and post-start hooks will run during enable operations (and, likewise, whether pre-stop and post-stop hooks will run during disable operations). The default value is <code>false</code>."},{"location":"References/Plugin_Config/#example","title":"Example","text":"<p>Assume the following basic plugin structure:</p> <pre><code>\u251c\u2500\u2500 plugin_config.yml\n\u251c\u2500\u2500 schema.json\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 mongo_runner.py\n</code></pre> <p><code>mongo_runner.py</code> contains:</p> <pre><code>from dlpx.virtualization.platform import Plugin\nmongodb = Plugin()\n</code></pre> <p>This is a valid plugin config for the plugin:</p> <p><pre><code>id: 7cf830f2-82f3-4d5d-a63c-7bbe50c22b32\nname: MongoDB\nhostTypes:\n- UNIX\nentryPoint: mongo_runner:mongodb\nsrcDir: src/\nschemaFile: schema.json\npluginType: DIRECT\nlanguage: PYTHON38\nbuildNumber: 0.1.0\n</code></pre> This is a valid plugin config for the plugin with <code>manualDiscovery</code> set to <code>false</code> and an <code>externalVersion</code> set:</p> <pre><code>id: 7cf830f2-82f3-4d5d-a63c-7bbe50c22b32\nname: MongoDB\nhostTypes:\n- UNIX\nentryPoint: mongo_runner:mongodb\nsrcDir: src/\nschemaFile: schema.json\nmanualDiscovery: false\npluginType: DIRECT\nlanguage: PYTHON38\nexternalVersion: \"MongoDB 1.0\"\nbuildNumber: \"1\"\n</code></pre>"},{"location":"References/Plugin_Operations/","title":"Plugin Operations","text":""},{"location":"References/Plugin_Operations/#summary","title":"Summary","text":"<p>Warning</p> <p>If a Plugin Operation is Required and is not present, the corresponding Delphix Engine Operation will fail when invoked. The plugin can still be built and uploaded to the Delphix Engine.</p> <p>Warning</p> <p>For each operation, the argument names must match exactly. For example, the Repository Discovery operation must have a single argument named <code>source_connection</code>.</p> Plugin Operation Required Decorator Delphix Engine Operations RepositoryDiscovery Yes <code>discovery.repository()</code> Environment DiscoveryEnvironment Refresh Source ConfigDiscovery Yes <code>discovery.source_config()</code> Environment DiscoveryEnvironment Refresh Direct Linked SourcePre-Snapshot No <code>linked.pre_snapshot()</code> Linked Source Sync Direct Linked SourcePost-Snapshot Yes <code>linked.post_snapshot()</code> Linked Source Sync Direct Linked SourceSource Size No <code>linked.source_size()</code> N/A Staged Linked SourcePre-Snapshot No <code>linked.pre_snapshot()</code> Linked Source Sync Staged Linked SourcePost-Snapshot Yes <code>linked.post_snapshot()</code> Linked Source Sync Staged Linked SourceStart-Staging No <code>linked.start_staging()</code> Linked Source Enable Staged Linked SourceStop-Staging No <code>linked.stop_staging()</code> Linked Source DisableLinked Source Delete Staged Linked SourceStatus No <code>linked.status()</code> N/A Staged Linked SourceWorker No <code>linked.worker()</code> N/A Staged Linked SourceMount Specification Yes <code>linked.mount_specification()</code> Linked Source SyncLinked Source Enable Staged Linked SourceSource Size No <code>linked.source_size()</code> N/A Virtual SourceInitialize No <code>virtual.initialize()</code> Virtual Source Create Empty VDB Virtual SourceConfigure Yes <code>virtual.configure()</code> Virtual Source ProvisionVirtual Source Refresh Virtual SourceUnconfigure No <code>virtual.unconfigure()</code> Virtual Source RefreshVirtual Source Delete Virtual SourceReconfigure Yes <code>virtual.reconfigure()</code> Virtual Source RollbackVirtual Source Enable Virtual SourceCleanup No <code>virtual.cleanup()</code> Virtual Source Delete Virtual SourceStart No <code>virtual.start()</code> Virtual Source Start Virtual SourceStop No <code>virtual.stop()</code> Virtual Source Stop Virtual SourcePre-Snapshot No <code>virtual.pre_snapshot()</code> Virtual Source Snapshot Virtual SourcePost-Snapshot Yes <code>virtual.post_snapshot()</code> Virtual Source Snapshot Virtual SourceMount Specification Yes <code>virtual.mount_specification()</code> Virtual Source EnableVirtual Source ProvisionVirtual Source RefreshVirtual Source RollbackVirtual Source Start Virtual SourceStatus No <code>virtual.status()</code> Virtual Source Enable Virtual SourceSource Size No <code>virtual.source_size()</code> N/A Repository Data Migration No <code>upgrade.repository(migration_id)</code> Upgrade Source Config Data Migration No <code>upgrade.source_config(migration_id)</code> Upgrade Linked Source Data Migration No <code>upgrade.linked_source(migration_id)</code> Upgrade Virtual Source Data Migration No <code>upgrade.virtual_source(migration_id)</code> Upgrade Snapshot Data Migration No <code>upgrade.snapshot(migration_id)</code> Upgrade"},{"location":"References/Plugin_Operations/#repository-discovery","title":"Repository Discovery","text":"<p>Discovers the set of repositories for a plugin on an environment. For a DBMS, this can correspond to the set of binaries installed on a Unix host.</p>"},{"location":"References/Plugin_Operations/#required-optional","title":"Required / Optional","text":"<p>Required.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations","title":"Delphix Engine Operations","text":"<ul> <li>Environment Refresh</li> <li>Environment Discovery</li> </ul>"},{"location":"References/Plugin_Operations/#signature","title":"Signature","text":"<p><code>def repository_discovery(source_connection)</code></p>"},{"location":"References/Plugin_Operations/#decorator","title":"Decorator","text":"<p><code>discovery.repository()</code></p>"},{"location":"References/Plugin_Operations/#arguments","title":"Arguments","text":"Argument Type Description source_connection RemoteConnection The connection associated with the remote environment to run repository discovery"},{"location":"References/Plugin_Operations/#returns","title":"Returns","text":"<p>A list of RepositoryDefinition objects.</p>"},{"location":"References/Plugin_Operations/#example","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom generated.defintions import RepositoryDefinition\nplugin = Plugin()\n@plugin.discovery.repository()\ndef repository_discovery(source_connection):\n# Initialize the object, filling in all required fields\nrepository = RepositoryDefinition(installPath=\"/usr/bin/install\")\n# Set any additional non-required properties\nrepository.version = \"1.2.3\"\n# Return one single repository\nreturn [repository]\n</code></pre> <p>The above command assumes a Repository Schema defined as:</p> <pre><code>{\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"required\": [\"installPath\"],\n\"properties\": {\n\"installPath\": { \"type\": \"string\" },\n\"version\": { \"type\": \"string\" }\n},\n\"identityFields\": [\"installPath\"],\n\"nameField\": [\"installPath\"]    }\n</code></pre>"},{"location":"References/Plugin_Operations/#source-config-discovery","title":"Source Config Discovery","text":"<p>Discovers the set of source configs for a plugin for a repository. For a DBMS, this can correspond to the set of unique databases running using a particular installation on a Unix host.</p>"},{"location":"References/Plugin_Operations/#required-optional_1","title":"Required / Optional","text":"<p>Required.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_1","title":"Delphix Engine Operations","text":"<ul> <li>Environment Refresh</li> <li>Environment Discovery</li> </ul>"},{"location":"References/Plugin_Operations/#signature_1","title":"Signature","text":"<p><code>def source_config_discovery(source_connection, repository)</code></p>"},{"location":"References/Plugin_Operations/#decorator_1","title":"Decorator","text":"<p><code>discovery.source_config()</code></p>"},{"location":"References/Plugin_Operations/#arguments_1","title":"Arguments","text":"Argument Type Description source_connection RemoteConnection The connection to the remote environment the corresponds to the repository. repository RepositoryDefinition The repository to discover source configs for."},{"location":"References/Plugin_Operations/#returns_1","title":"Returns","text":"<p>A list of SourceConfigDefinition objects.</p>"},{"location":"References/Plugin_Operations/#example_1","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom generated.definitions import SourceConfigDefinition\nplugin = Plugin()\n@plugin.discovery.source_config()\ndef source_config_discovery(source_connection, repository):\nsource_config = SourceConfigDefinition(name=\"my_name\", port=1000)\nreturn [source_config]\n</code></pre> <p>The above command assumes a Source Config Schema defined as:</p> <pre><code>{\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"required\": [\"name\"],\n\"properties\": {\n\"name\": { \"type\": \"string\" },\n\"port\": { \"type\": \"number\" }\n},\n\"identityFields\": [\"name\"],\n\"nameField\": [\"name\"]    }\n</code></pre>"},{"location":"References/Plugin_Operations/#direct-linked-source-pre-snapshot","title":"Direct Linked Source Pre-Snapshot","text":"<p>Sets up a dSource to ingest data. Only applies when using a Direct Linking strategy.</p>"},{"location":"References/Plugin_Operations/#required-optional_2","title":"Required / Optional","text":"<p>Optional</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_2","title":"Delphix Engine Operations","text":"<ul> <li>Linked Source Sync</li> </ul>"},{"location":"References/Plugin_Operations/#signature_2","title":"Signature","text":"<p><code>def linked_pre_snapshot(direct_source, repository, source_config, optional_snapshot_parameters)</code></p>"},{"location":"References/Plugin_Operations/#decorator_2","title":"Decorator","text":"<p><code>linked.pre_snapshot()</code></p>"},{"location":"References/Plugin_Operations/#arguments_2","title":"Arguments","text":"Argument Type Description direct_source DirectSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source. optional_snapshot_parameters SnapshotParametersDefinition The snapshot parameters. The value is <code>None</code> when executed during a snapshot policy."},{"location":"References/Plugin_Operations/#returns_2","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#example_2","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom generated.definitions import SourceConfigDefinition\nplugin = Plugin()\n@plugin.linked.pre_snapshot()\ndef linked_pre_snapshot(direct_source, repository, source_config):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#direct-linked-source-post-snapshot","title":"Direct Linked Source Post-Snapshot","text":"<p>Captures metadata from a dSource once data has been ingested. Only applies when using a Direct Linking strategy.</p>"},{"location":"References/Plugin_Operations/#required-optional_3","title":"Required / Optional","text":"<p>Required.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_3","title":"Delphix Engine Operations","text":"<ul> <li>Linked Source Sync</li> </ul>"},{"location":"References/Plugin_Operations/#signature_3","title":"Signature","text":"<p><code>def linked_post_snapshot(direct_source, repository, source_config, optional_snapshot_parameters)</code></p>"},{"location":"References/Plugin_Operations/#decorator_3","title":"Decorator","text":"<p><code>linked.post_snapshot()</code></p>"},{"location":"References/Plugin_Operations/#arguments_3","title":"Arguments","text":"Argument Type Description direct_source DirectSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source. optional_snapshot_parameters SnapshotParametersDefinition The snapshot parameters. The value is <code>None</code> when executed during a snapshot policy."},{"location":"References/Plugin_Operations/#returns_3","title":"Returns","text":"<p>SnapshotDefinition</p>"},{"location":"References/Plugin_Operations/#example_3","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom generated.definitions import SnapshotDefinition\nplugin = Plugin()\n@plugin.linked.post_snapshot()\ndef linked_post_snapshot(direct_source, repository, source_config, optional_snapshot_parameters):\nsnapshot = SnapshotDefinition()\nsnapshot.transaction_id = 1000\nreturn snapshot\n</code></pre> <p>The above command assumes a Snapshot Schema defined as:</p> <pre><code>{\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"properties\": {\n\"transactionId\": { \"type\": \"integer\" }\n}\n}\n</code></pre>"},{"location":"References/Plugin_Operations/#direct-linked-source-size","title":"Direct Linked Source Size","text":"<p>Determines the database size of a dSource once data has been ingested. Only applies when using a Direct Linking strategy.</p>"},{"location":"References/Plugin_Operations/#required-optional_4","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_4","title":"Delphix Engine Operations","text":"<ul> <li>N/A</li> </ul>"},{"location":"References/Plugin_Operations/#signature_4","title":"Signature","text":"<p><code>def linked_source_size(direct_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_4","title":"Decorator","text":"<p><code>linked.source_size()</code></p>"},{"location":"References/Plugin_Operations/#arguments_4","title":"Arguments","text":"Argument Type Description direct_source DirectSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_4","title":"Returns","text":"<p>Positive Numeric</p>"},{"location":"References/Plugin_Operations/#example_4","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.linked.source_size()\ndef linked_source_size(direct_source, repository, source_config):\ndatabase_size = 0\n# Implementation to fetch the database size.\nreturn database_size\n</code></pre>"},{"location":"References/Plugin_Operations/#staged-linked-source-pre-snapshot","title":"Staged Linked Source Pre-Snapshot","text":"<p>Sets up a dSource to ingest data. Only applies when using a Staged Linking strategy.</p>"},{"location":"References/Plugin_Operations/#required-optional_5","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_5","title":"Delphix Engine Operations","text":"<ul> <li>Linked Source Sync</li> </ul>"},{"location":"References/Plugin_Operations/#signature_5","title":"Signature","text":"<p><code>def linked_pre_snapshot(staged_source, repository, source_config, optional_snapshot_parameters)</code></p>"},{"location":"References/Plugin_Operations/#decorator_5","title":"Decorator","text":"<p><code>linked.pre_snapshot()</code></p>"},{"location":"References/Plugin_Operations/#arguments_5","title":"Arguments","text":"Argument Type Description staged_source StagedSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source. optional_snapshot_parameters SnapshotParametersDefinition The snapshot parameters. The value is <code>None</code> when executed during a snapshot policy."},{"location":"References/Plugin_Operations/#returns_5","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#example_5","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.linked.pre_snapshot()\ndef linked_pre_snapshot(staged_source, repository, source_config, optional_snapshot_parameters):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#staged-linked-source-post-snapshot","title":"Staged Linked Source Post-Snapshot","text":"<p>Captures metadata from a dSource once data has been ingested. Only applies when using a Staged Linking strategy.</p>"},{"location":"References/Plugin_Operations/#required-optional_6","title":"Required / Optional","text":"<p>Required.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_6","title":"Delphix Engine Operations","text":"<ul> <li>Linked Source Sync</li> </ul>"},{"location":"References/Plugin_Operations/#signature_6","title":"Signature","text":"<p><code>def linked_post_snapshot(staged_source, repository, source_config, optional_snapshot_parameters)</code></p>"},{"location":"References/Plugin_Operations/#decorator_6","title":"Decorator","text":"<p><code>linked.post_snapshot()</code></p>"},{"location":"References/Plugin_Operations/#arguments_6","title":"Arguments","text":"Argument Type Description staged_source StagedSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source. optional_snapshot_parameters SnapshotParametersDefinition The snapshot parameters. The value is <code>None</code> when executed during a snapshot policy."},{"location":"References/Plugin_Operations/#returns_6","title":"Returns","text":"<p>SnapshotDefinition</p>"},{"location":"References/Plugin_Operations/#example_6","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom generated.definitions import SnapshotDefinition\nplugin = Plugin()\n@plugin.linked.post_snapshot()\ndef linked_post_snapshot(staged_source, repository, source_config, optional_snapshot_parameters):\nsnapshot = SnapshotDefinition()\nif optional_snapshot_parameters is not None and optional_snapshot_parameters.resync:\nsnapshot.transaction_id = 1000\nelse:\nsnapshot.transaction_id = 10\nreturn snapshot\n</code></pre> <p>The above command assumes a Snapshot Schema defined as:</p> <pre><code>{\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"properties\": {\n\"transactionId\": { \"type\": \"integer\" }\n}\n}\n</code></pre>"},{"location":"References/Plugin_Operations/#staged-linked-source-start-staging","title":"Staged Linked Source Start-Staging","text":"<p>Sets up a Staging Source to ingest data. Only applies when using a Staged Linking strategy. Required to implement for Delphix Engine operations:</p>"},{"location":"References/Plugin_Operations/#required-optional_7","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_7","title":"Delphix Engine Operations","text":"<ul> <li>Linked Source Enable</li> </ul>"},{"location":"References/Plugin_Operations/#signature_7","title":"Signature","text":"<p><code>def start_staging(staged_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_7","title":"Decorator","text":"<p><code>linked.start_staging()</code></p>"},{"location":"References/Plugin_Operations/#arguments_7","title":"Arguments","text":"Argument Type Description staged_source StagedSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_7","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#example_7","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.linked.start_staging()\ndef start_staging(staged_source, repository, source_config):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#staged-linked-source-stop-staging","title":"Staged Linked Source Stop-Staging","text":"<p>Quiesces a Staging Source to pause ingestion. Only applies when using a Staged Linking strategy.</p>"},{"location":"References/Plugin_Operations/#required-optional_8","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_8","title":"Delphix Engine Operations","text":"<ul> <li>Linked Source Disable</li> <li>Linked Source Delete</li> </ul>"},{"location":"References/Plugin_Operations/#signature_8","title":"Signature","text":"<p><code>def stop_staging(staged_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_8","title":"Decorator","text":"<p><code>linked.stop_staging()</code></p>"},{"location":"References/Plugin_Operations/#arguments_8","title":"Arguments","text":"Argument Type Description staged_source StagedSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_8","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#examples","title":"Examples","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.linked.stop_staging()\ndef stop_staging(staged_source, repository, source_config):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#staged-linked-source-status","title":"Staged Linked Source Status","text":"<p>Determines the status of a Staging Source to show end users whether it is healthy or not. Only applies when using a Staged Linking strategy.</p>"},{"location":"References/Plugin_Operations/#required-optional_9","title":"Required / Optional","text":"<p>Optional. If not implemented, the platform assumes that the status is <code>Status.ACTIVE</code></p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_9","title":"Delphix Engine Operations","text":"<p>N/A</p>"},{"location":"References/Plugin_Operations/#signature_9","title":"Signature","text":"<p><code>def linked_status(staged_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_9","title":"Decorator","text":"<p><code>linked.status()</code></p>"},{"location":"References/Plugin_Operations/#arguments_9","title":"Arguments","text":"Argument Type Description staged_source StagedSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_9","title":"Returns","text":"<p>Status <code>Status.ACTIVE</code> if the plugin operation is not implemented.</p>"},{"location":"References/Plugin_Operations/#example_8","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom dlpx.virtualization.platform import Status\nplugin = Plugin()\n@plugin.linked.status()\ndef linked_status(staged_source, repository, source_config):\nreturn Status.ACTIVE\n</code></pre>"},{"location":"References/Plugin_Operations/#staged-linked-source-worker","title":"Staged Linked Source Worker","text":"<p>Monitors the status of a Staging Source on a reqular interval. It can be used to fix up any errors on staging if it is not functioning as expected. Only applies when using a Staged Linking strategy.</p>"},{"location":"References/Plugin_Operations/#required-optional_10","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_10","title":"Delphix Engine Operations","text":"<p>N/A</p>"},{"location":"References/Plugin_Operations/#signature_10","title":"Signature","text":"<p><code>def worker(staged_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_10","title":"Decorator","text":"<p><code>linked.worker()</code></p>"},{"location":"References/Plugin_Operations/#arguments_10","title":"Arguments","text":"Argument Type Description staged_source StagedSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_10","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#example_9","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.linked.worker()\ndef worker(staged_source, repository, source_config):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#staged-linked-source-mount-specification","title":"Staged Linked Source Mount Specification","text":"<p>Returns configurations for the mounts associated for data in staged source. The <code>ownership_specification</code> is optional. If not specified, the platform will default the ownership settings to the environment user used for the Delphix Operation.</p>"},{"location":"References/Plugin_Operations/#required-optional_11","title":"Required / Optional","text":"<p>Required.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_11","title":"Delphix Engine Operations","text":"<ul> <li>Linked Source Sync</li> <li>Linked Source Enable</li> </ul>"},{"location":"References/Plugin_Operations/#signature_11","title":"Signature","text":"<p><code>def linked_mount_specification(staged_source, repository)</code></p>"},{"location":"References/Plugin_Operations/#decorator_11","title":"Decorator","text":"<p><code>linked.mount_specification()</code></p>"},{"location":"References/Plugin_Operations/#arguments_11","title":"Arguments","text":"Argument Type Description staged_source StagedSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source."},{"location":"References/Plugin_Operations/#returns_11","title":"Returns","text":"<p>MountSpecification</p>"},{"location":"References/Plugin_Operations/#example_10","title":"Example","text":"<p>Info</p> <p><code>ownership_specification</code> only applies to Unix hosts.</p> <pre><code>from dlpx.virtualization.platform import Plugin\nfrom dlpx.virtualization.platform import Mount\nfrom dlpx.virtualization.platform import MountSpecification\nfrom dlpx.virtualization.platform import OwenershipSpecification\nfrom generated.definitions import SnapshotDefinition\nplugin = Plugin()\n@plugin.linked.mount_specification()\ndef linked_mount_specification(staged_source, repository):\nmount = Mount(staged_source.staged_connection.environment, \"/some/path\")\nownership_spec = OwenershipSpecification(repository.uid, repository.gid)\nreturn MountSpecification([mount], ownership_spec)\n</code></pre>"},{"location":"References/Plugin_Operations/#staged-linked-source-size","title":"Staged Linked Source Size","text":"<p>Determines the database size of a Staging Source once data has been ingested. Only applies when using a Staged Linking strategy.</p>"},{"location":"References/Plugin_Operations/#required-optional_12","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_12","title":"Delphix Engine Operations","text":"<ul> <li>N/A</li> </ul>"},{"location":"References/Plugin_Operations/#signature_12","title":"Signature","text":"<p><code>def linked_source_size(staged_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_12","title":"Decorator","text":"<p><code>linked.source_size()</code></p>"},{"location":"References/Plugin_Operations/#arguments_12","title":"Arguments","text":"Argument Type Description staged_source StagedSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_12","title":"Returns","text":"<p>Positive Numeric</p>"},{"location":"References/Plugin_Operations/#example_11","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.linked.source_size()\ndef linked_source_size(staged_source, repository, source_config):\ndatabase_size = 0\n# Implementation to fetch the database size.\nreturn database_size\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-initialize","title":"Virtual Source Initialize","text":"<p>Initializes a brand-new empty VDB. As with all VDBs, this new dataset will have access to mounted Delphix Engine storage, but of course there will be no data there at first.</p> <p>The job of the plugin is to do whatever is necessary to set up a new dataset from scratch. For example, this might involve running a <code>CREATE DATABASE</code> command.  This is an optional operation -- users will not be allowed to create empty VDBs for plugins that choose not to implement this operation.</p> <p>As with the <code>configure</code> operation, this <code>initialize</code> operation must return source config parameters that represent the new dataset.</p>"},{"location":"References/Plugin_Operations/#required-optional_13","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_13","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Create Empty VDB</li> </ul>"},{"location":"References/Plugin_Operations/#signature_13","title":"Signature","text":"<p><code>def initialize(virtual_source, repository)</code></p>"},{"location":"References/Plugin_Operations/#decorator_13","title":"Decorator","text":"<p><code>virtual.initialize()</code></p>"},{"location":"References/Plugin_Operations/#arguments_13","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source."},{"location":"References/Plugin_Operations/#returns_13","title":"Returns","text":"<p>SourceConfigDefinition</p>"},{"location":"References/Plugin_Operations/#example_12","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom generated.defintions import SourceConfigDefinition\nplugin = Plugin()\n@plugin.virtual.initialize()\ndef initialize(virtual_source, repository):\nsource_config = SourceConfigDefinition(name=\"config_name\")\nreturn source_config\n</code></pre> <p>The above command assumes a SourceConfig Schema defined as:</p> <pre><code>{\n\"type\": \"object\",\n\"required\": [\"name\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"name\": { \"type\": \"string\" }\n},\n\"identityFields\": [\"name\"],\n\"nameField\": [\"name\"]\n}\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-configure","title":"Virtual Source Configure","text":"<p>Configures the data in a particular snapshot to be usable on a target environment. For database data files, this may mean recovering from a crash consistent format or backup. For application files, this may mean reconfiguring XML files or rewriting hostnames and symlinks.</p>"},{"location":"References/Plugin_Operations/#required-optional_14","title":"Required / Optional","text":"<p>Required.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_14","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Provision</li> <li>Virtual Source Refresh</li> </ul>"},{"location":"References/Plugin_Operations/#signature_14","title":"Signature","text":"<p><code>def configure(virtual_source, snapshot, repository)</code></p>"},{"location":"References/Plugin_Operations/#decorator_14","title":"Decorator","text":"<p><code>virtual.configure()</code></p>"},{"location":"References/Plugin_Operations/#arguments_14","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. snapshot SnapshotDefinition The snapshot of the data set to configure. repository RepositoryDefinition The repository associated with this source."},{"location":"References/Plugin_Operations/#returns_14","title":"Returns","text":"<p>SourceConfigDefinition</p>"},{"location":"References/Plugin_Operations/#example_13","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom generated.defintions import SourceConfigDefinition\nplugin = Plugin()\n@plugin.virtual.configure()\ndef configure(virtual_source, repository, snapshot):\nsource_config = SourceConfigDefinition(name=\"config_name\")\nreturn source_config\n</code></pre> <p>The above command assumes a SourceConfig Schema defined as:</p> <pre><code>{\n\"type\": \"object\",\n\"required\": [\"name\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"name\": { \"type\": \"string\" }\n},\n\"identityFields\": [\"name\"],\n\"nameField\": [\"name\"]\n}\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-unconfigure","title":"Virtual Source Unconfigure","text":"<p>Prepares for the removal of virtual source data from a target host. Depending on your dataset, this might involve unregistering this dataset from the DBMS, modifying/deleting config files on the remote host, etc.</p> <p>It's important to clean up anything VDB-specific from the target host during this operation. For example, if you've stored such data in the scratch path, then you should delete it during unconfigure.</p>"},{"location":"References/Plugin_Operations/#required-optional_15","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_15","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Refresh</li> <li>Virtual Source Delete</li> <li>Virtual Source Disable</li> </ul>"},{"location":"References/Plugin_Operations/#signature_15","title":"Signature","text":"<p><code>def unconfigure(virtual_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_15","title":"Decorator","text":"<p><code>virtual.unconfigure()</code></p>"},{"location":"References/Plugin_Operations/#arguments_15","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_15","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#example_14","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.unconfigure()\ndef unconfigure(virtual_source, repository, source_config):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-reconfigure","title":"Virtual Source Reconfigure","text":"<p>Re-configures the data for a virtual source to point to the data in a prior snapshot for the virtual source. For database data files, this may mean recovering from a crash consistent format or backup of a new snapshot. For application files, this may mean reconfiguring XML files or rewriting hostnames and symlinks.</p>"},{"location":"References/Plugin_Operations/#required-optional_16","title":"Required / Optional","text":"<p>Required.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_16","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Rollback</li> <li>Virtual Source Enable</li> </ul>"},{"location":"References/Plugin_Operations/#signature_16","title":"Signature","text":"<p><code>def reconfigure(virtual_source, repository, source_config, snapshot)</code></p>"},{"location":"References/Plugin_Operations/#decorator_16","title":"Decorator","text":"<p><code>virtual.reconfigure()</code></p>"},{"location":"References/Plugin_Operations/#arguments_16","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. snapshot SnapshotDefinition The snapshot of the data set to configure. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_16","title":"Returns","text":"<p>SourceConfigDefinition</p>"},{"location":"References/Plugin_Operations/#example_15","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom generated.definitions import SourceConfigDefinition\nplugin = Plugin()\n@plugin.virtual.reconfigure()\ndef reconfigure(virtual_source, repository, source_config, snapshot):\nreturn SourceConfigDefinition(name=\"updated_config_name\")\n</code></pre> <p>The above command assumes a SourceConfig Schema defined as:</p> <pre><code>{\n\"type\": \"object\",\n\"required\": [\"name\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"name\": { \"type\": \"string\" }\n},\n\"identityFields\": [\"name\"],\n\"nameField\": [\"name\"]\n}\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-cleanup","title":"Virtual Source Cleanup","text":"<p>Intended to allow a final cleanup during a delete operation, unlike unconfigure which can be used to signal a temporary dissassociation with a database.</p> <p>Cleanup is called during the delete flow after unconfigure.</p>"},{"location":"References/Plugin_Operations/#required-optional_17","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_17","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Delete</li> </ul>"},{"location":"References/Plugin_Operations/#signature_17","title":"Signature","text":"<p><code>def cleanup(virtual_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_17","title":"Decorator","text":"<p><code>virtual.cleanup()</code></p>"},{"location":"References/Plugin_Operations/#arguments_17","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_17","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#example_16","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.cleanup()\ndef cleanup(virtual_source, repository, source_config):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-start","title":"Virtual Source Start","text":"<p>Executed whenever the data should be placed in a \"running\" state.</p>"},{"location":"References/Plugin_Operations/#required-optional_18","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_18","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Start</li> </ul>"},{"location":"References/Plugin_Operations/#signature_18","title":"Signature","text":"<p><code>def start(virtual_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_18","title":"Decorator","text":"<p><code>virtual.start()</code></p>"},{"location":"References/Plugin_Operations/#arguments_18","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_18","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#example_17","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.start()\ndef start(virtual_source, repository, source_config):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-stop","title":"Virtual Source Stop","text":"<p>Executed whenever the data needs to be shut down. Required to implement for Delphix Engine operations:</p>"},{"location":"References/Plugin_Operations/#required-optional_19","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_19","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Stop</li> </ul>"},{"location":"References/Plugin_Operations/#signature_19","title":"Signature","text":"<p><code>def stop(virtual_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_19","title":"Decorator","text":"<p><code>virtual.stop()</code></p>"},{"location":"References/Plugin_Operations/#arguments_19","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_19","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#example_18","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.stop()\ndef stop(virtual_source, repository, source_config):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-pre-snapshot","title":"Virtual Source Pre-Snapshot","text":"<p>Prepares the virtual source for taking a snapshot of the data.</p>"},{"location":"References/Plugin_Operations/#required-optional_20","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_20","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Snapshot</li> </ul>"},{"location":"References/Plugin_Operations/#signature_20","title":"Signature","text":"<p><code>def virtual_pre_snapshot(virtual_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_20","title":"Decorator","text":"<p><code>virtual.pre_snapshot()</code></p>"},{"location":"References/Plugin_Operations/#arguments_20","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_20","title":"Returns","text":"<p>None</p>"},{"location":"References/Plugin_Operations/#example_19","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.pre_snapshot()\ndef virtual_pre_snapshot(virtual_source, repository, source_config):\npass\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-post-snapshot","title":"Virtual Source Post-Snapshot","text":"<p>Captures metadata after a snapshot.</p>"},{"location":"References/Plugin_Operations/#required-optional_21","title":"Required / Optional","text":"<p>Required.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_21","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Snapshot</li> </ul>"},{"location":"References/Plugin_Operations/#signature_21","title":"Signature","text":"<p><code>def virtual_post_snapshot(virtual_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_21","title":"Decorator","text":"<p><code>virtual.post_snapshot()</code></p>"},{"location":"References/Plugin_Operations/#arguments_21","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_21","title":"Returns","text":"<p>SnapshotDefinition</p>"},{"location":"References/Plugin_Operations/#example_20","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom generated.defintions import SnapshotDefinition\nplugin = Plugin()\n@plugin.virtual.post_snapshot()\ndef virtual_post_snapshot(virtual_source, repository, source_config):\nsnapshot = SnapshotDefinition()\nsnapshot.transaction_id = 1000\nreturn snapshot\n</code></pre> <p>The above command assumes a Snapshot Schema defined as:</p> <pre><code>{\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"properties\": {\n\"transactionId\": { \"type\": \"string\" }\n}\n}\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-mount-specification","title":"Virtual Source Mount Specification","text":"<p>Returns configurations for the mounts associated for data in virtual source. The <code>ownership_specification</code> is optional. If not specified, the platform will default the ownership settings to the environment user used for the Delphix Operation.</p>"},{"location":"References/Plugin_Operations/#required-optional_22","title":"Required / Optional","text":"<p>Required.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_22","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Enable</li> <li>Virtual Source Provision</li> <li>Virtual Source Refresh</li> <li>Virtual Source Rollback</li> <li>Virtual Source Start</li> </ul>"},{"location":"References/Plugin_Operations/#signature_22","title":"Signature","text":"<p><code>def virtual_mount_specification(virtual_source, repository)</code></p>"},{"location":"References/Plugin_Operations/#decorator_22","title":"Decorator","text":"<p><code>virtual.mount_specification()</code></p>"},{"location":"References/Plugin_Operations/#arguments_22","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source."},{"location":"References/Plugin_Operations/#returns_22","title":"Returns","text":"<p>MountSpecification</p>"},{"location":"References/Plugin_Operations/#example_21","title":"Example","text":"<p>Info</p> <p><code>ownership_specification</code> only applies to Unix hosts.</p> <pre><code>from dlpx.virtualization.platform import Plugin\nfrom dlpx.virtualization.platform import Mount\nfrom dlpx.virtualization.platform import MountSpecification\nfrom dlpx.virtualization.platform import OwenershipSpecification\nfrom generated.definitions import SnapshotDefinition\nplugin = Plugin()\n@plugin.virtual.mount_specification()\ndef virtual_mount_specification(virtual_source, repository):\nmount = Mount(virtual_source.connection.environment, \"/some/path\")\nownership_spec = OwenershipSpecification(repository.uid, repository.gid)\nreturn MountSpecification([mount], ownership_spec)\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-status","title":"Virtual Source Status","text":"<p>Determines the status of a Virtual Source to show end users whether it is healthy or not.</p>"},{"location":"References/Plugin_Operations/#required-optional_23","title":"Required / Optional","text":"<p>Optional. If not implemented, the platform assumes that the status is <code>Status.ACTIVE</code>.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_23","title":"Delphix Engine Operations","text":"<ul> <li>Virtual Source Enable</li> </ul>"},{"location":"References/Plugin_Operations/#signature_23","title":"Signature","text":"<p><code>def virtual_status(virtual_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_23","title":"Decorator","text":"<p><code>virtual.status()</code></p>"},{"location":"References/Plugin_Operations/#arguments_23","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_23","title":"Returns","text":"<p>Status <code>Status.ACTIVE</code> if the plugin operation is not implemented.</p>"},{"location":"References/Plugin_Operations/#example_22","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nfrom dlpx.virtualization.platform import Status\nplugin = Plugin()\n@plugin.virtual.status()\ndef virtual_status(virtual_source, repository, source_config):\nreturn Status.ACTIVE\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-size","title":"Virtual Source Size","text":"<p>Determines the database size of a Virtual Source once data has been ingested.</p>"},{"location":"References/Plugin_Operations/#required-optional_24","title":"Required / Optional","text":"<p>Optional.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_24","title":"Delphix Engine Operations","text":"<ul> <li>N/A</li> </ul>"},{"location":"References/Plugin_Operations/#signature_24","title":"Signature","text":"<p><code>def virtual_source_size(virtual_source, repository, source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_24","title":"Decorator","text":"<p><code>virtual.source_size()</code></p>"},{"location":"References/Plugin_Operations/#arguments_24","title":"Arguments","text":"Argument Type Description virtual_source VirtualSource The source associated with this operation. repository RepositoryDefinition The repository associated with this source. source_config SourceConfigDefinition The source config associated with this source."},{"location":"References/Plugin_Operations/#returns_24","title":"Returns","text":"<p>Positive Numeric</p>"},{"location":"References/Plugin_Operations/#example_23","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.virtual.source_size()\ndef virtual_source_size(virtual_source, repository, source_config):\ndatabase_size = 0\n# Implementation to fetch the database size.\nreturn database_size\n</code></pre>"},{"location":"References/Plugin_Operations/#repository-data-migration","title":"Repository Data Migration","text":"<p>A Repository Data Migration migrates repository data from an older schema format to an updated schema format.</p>"},{"location":"References/Plugin_Operations/#required-optional_25","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all repository data will match your updated repository schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more repository data migrations.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_25","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"References/Plugin_Operations/#signature_25","title":"Signature","text":"<p><code>def migrate_repository(old_repository)</code></p>"},{"location":"References/Plugin_Operations/#decorator_25","title":"Decorator","text":"<p><code>upgrade.repository(migration_id)</code></p>"},{"location":"References/Plugin_Operations/#decorator-arguments","title":"Decorator Arguments","text":"Argument Type Description migration_id String The ID of this migration. An ID is a string containing one or more positive integers separated by periods. Each ID must be unique. More details here."},{"location":"References/Plugin_Operations/#function-arguments","title":"Function Arguments","text":"Argument Type Description old_repository Dictionary The plugin-specific data associated with a repository, that conforms to the previous schema. <p>Warning</p> <p>The function argument <code>old_repository</code> is a Python dictionary, where each property name appears exactly as described in the previous repository schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"References/Plugin_Operations/#returns_25","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_repository</code> input that must conform to the updated repository schema.</p>"},{"location":"References/Plugin_Operations/#example_24","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.repository(\"2019.12.15\")\ndef add_new_flag_to_repo(old_repository):\nnew_repository = dict(old_repository)\nnew_repository[\"useNewFeature\"] = False\nreturn new_repository\n</code></pre>"},{"location":"References/Plugin_Operations/#source-config-data-migration","title":"Source Config Data Migration","text":"<p>A Source Config Data Migration migrates source config data from an older schema format to an updated schema format.</p>"},{"location":"References/Plugin_Operations/#required-optional_26","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all source config data will match your source config schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more source config data migrations.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_26","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"References/Plugin_Operations/#signature_26","title":"Signature","text":"<p><code>def migrate_source_config(old_source_config)</code></p>"},{"location":"References/Plugin_Operations/#decorator_26","title":"Decorator","text":"<p><code>upgrade.source_config(migration_id)</code></p>"},{"location":"References/Plugin_Operations/#decorator-arguments_1","title":"Decorator Arguments","text":"Argument Type Description migration_id String The ID of this migration. An ID is a string containing one or more positive integers separated by periods. Each ID must be unique. More details here."},{"location":"References/Plugin_Operations/#function-arguments_1","title":"Function Arguments","text":"Argument Type Description old_source_config Dictionary The plugin-specific data associated with a source config, that conforms to the previous schema. <p>Warning</p> <p>The function argument <code>old_source_config</code> is a Python dictionary, where each property name appears exactly as described in the previous source config schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"References/Plugin_Operations/#returns_26","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_source_config</code> input that must conform to the updated source config schema.</p>"},{"location":"References/Plugin_Operations/#example_25","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.source_config(\"2019.12.15\")\ndef add_new_flag_to_source_config(old_source_config):\nnew_source_config = dict(old_source_config)\nnew_source_config[\"useNewFeature\"] = False\nreturn new_source_config\n</code></pre>"},{"location":"References/Plugin_Operations/#linked-source-data-migration","title":"Linked Source Data Migration","text":"<p>A Linked Source Data Migration migrates linked source data from an older schema format to an updated schema format.</p>"},{"location":"References/Plugin_Operations/#required-optional_27","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all linked source data will match your linked source schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more linked source data migrations.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_27","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"References/Plugin_Operations/#signature_27","title":"Signature","text":"<p><code>def migrate_linked_source(old_linked_source)</code></p>"},{"location":"References/Plugin_Operations/#decorator_27","title":"Decorator","text":"<p><code>upgrade.linked_source(migration_id)</code></p>"},{"location":"References/Plugin_Operations/#decorator-arguments_2","title":"Decorator Arguments","text":"Argument Type Description migration_id String The ID of this migration. An ID is a string containing one or more positive integers separated by periods. Each ID must be unique. More details here."},{"location":"References/Plugin_Operations/#function-arguments_2","title":"Function Arguments","text":"Argument Type Description old_linked_source Dictionary The plugin-specific data associated with a linked source, that conforms to the previous schema. <p>Warning</p> <p>The function argument <code>old_linked_source</code> is a Python dictionary, where each property name appears exactly as described in the previous linked source schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"References/Plugin_Operations/#returns_27","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_linked_source</code> input that must conform to the updated linked source schema.</p>"},{"location":"References/Plugin_Operations/#example_26","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.linked_source(\"2019.12.15\")\ndef add_new_flag_to_dsource(old_linked_source):\nnew_linked_source = dict(old_linked_source)\nnew_linked_source[\"useNewFeature\"] = False\nreturn new_linked_source\n</code></pre>"},{"location":"References/Plugin_Operations/#virtual-source-data-migration","title":"Virtual Source Data Migration","text":"<p>A Virtual Source Data Migration migrates virtual source data from an older schema format to an updated schema format.</p>"},{"location":"References/Plugin_Operations/#required-optional_28","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all virtual source data will match your virtual source schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more virtual source data migrations.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_28","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"References/Plugin_Operations/#signature_28","title":"Signature","text":"<p><code>def migrate_virtual_source(old_virtual_source)</code></p>"},{"location":"References/Plugin_Operations/#decorator_28","title":"Decorator","text":"<p><code>upgrade.virtual_source(migration_id)</code></p>"},{"location":"References/Plugin_Operations/#decorator-arguments_3","title":"Decorator Arguments","text":"Argument Type Description migration_id String The ID of this migration. An ID is a string containing one or more positive integers separated by periods. Each ID must be unique. More details here."},{"location":"References/Plugin_Operations/#function-arguments_3","title":"Function Arguments","text":"Argument Type Description old_virtual_source Dictionary The plugin-specific data associated with a virtual source, that conforms to the previous schema. <p>Warning</p> <p>The function argument <code>old_virtual_source</code> is a Python dictionary, where each property name appears exactly as described in the previous virtual source schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"References/Plugin_Operations/#returns_28","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_virtual_source</code> input that must conform to the updated virtual source schema.</p>"},{"location":"References/Plugin_Operations/#example_27","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.virtual_source(\"2019.12.15\")\ndef add_new_flag_to_vdb(old_virtual_source):\nnew_virtual_source = dict(old_virtual_source)\nnew_virtual_source[\"useNewFeature\"] = False\nreturn new_virtual_source\n</code></pre>"},{"location":"References/Plugin_Operations/#snapshot-data-migration","title":"Snapshot Data Migration","text":"<p>A Snapshot Data Migration migrates snapshot data from an older schema format to an updated schema format.</p>"},{"location":"References/Plugin_Operations/#required-optional_29","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all snapshot data will match your snapshot schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more snapshot migrations.</p>"},{"location":"References/Plugin_Operations/#delphix-engine-operations_29","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"References/Plugin_Operations/#signature_29","title":"Signature","text":"<p><code>def migrate_snapshot(old_snapshot)</code></p>"},{"location":"References/Plugin_Operations/#decorator_29","title":"Decorator","text":"<p><code>upgrade.snapshot(migration_id)</code></p>"},{"location":"References/Plugin_Operations/#decorator-arguments_4","title":"Decorator Arguments","text":"Argument Type Description migration_id String The ID of this migration. An ID is a string containing one or more positive integers separated by periods. Each ID must be unique. More details here."},{"location":"References/Plugin_Operations/#function-arguments_4","title":"Function Arguments","text":"Argument Type Description old_snapshot Dictionary The plugin-specific data associated with a snapshot, that conforms to the previous schema. <p>Warning</p> <p>The function argument <code>old_snapshot</code> is a Python dictionary, where each property name appears exactly as described in the previous snapshot schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"References/Plugin_Operations/#returns_29","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_snapshot</code> input that must conform to the updated snapshot schema.</p>"},{"location":"References/Plugin_Operations/#example_28","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.snapshot(\"2019.12.15\")\ndef add_new_flag_to_snapshot(old_snapshot):\nnew_snapshot = dict(old_snapshot)\nnew_snapshot[\"useNewFeature\"] = False\nreturn new_snapshot\n</code></pre>"},{"location":"References/Schemas/","title":"Schemas","text":""},{"location":"References/Schemas/#about-schemas","title":"About Schemas","text":"<p>Any time a plugin needs to store its own data, or needs to ask the user for data, the Delphix Engine needs to be told about the format of that data:</p> <ul> <li>What is the set of data needed and what should they be called?</li> <li>What is the type of each piece of data: Strings? Integers? Booleans?</li> </ul> <p>Plugins use schemas to describe the format of such data. Once a schema is defined, it is used in three ways</p> <ol> <li>It tells the Delphix Engine how to store the data for later use.</li> <li>It is used to autogenerate a custom user interface, and to validate user inputs.</li> <li>It is used to autogenerate Python classes that can be used by plugin code to access and manipulate user input and stored data.</li> </ol> <p>There are five plugin-customizable data formats:</p> Delphix Object Schema Autogenerated Class Repository RepositoryDefinition RepositoryDefinition Source Config SourceConfigDefinition SourceConfigDefinition Linked Source LinkedSourceDefinition LinkedSourceDefinition Virtual Source VirtualSourceDefinition VirtualSourceDefinition Snapshot SnapshotDefinition SnapshotDefinition Snapshot Parameters SnapshotParametersDefinition SnapshotParametersDefinition <p>Warning</p> <p>There are limits to how much data can be stored within a plugin defined schema. See Message Limits for details.</p>"},{"location":"References/Schemas/#json-schemas","title":"JSON Schemas","text":"<p>Plugins use JSON schemas for their custom datatypes. There are three main things to understand about them, which are explained just below:</p> <ul> <li>What is JSON?</li> <li>What is a JSON schema?</li> <li>How has Delphix augmented JSON schemas?</li> </ul>"},{"location":"References/Schemas/#json","title":"JSON","text":"<p>JSON stands for \"Javascript Object Notation\". JSON is a data-interchange format that is intended to be precise and also somewhat human-readable. Here are some simple examples of data in JSON format:</p> JSON Description <code>\"hello\"</code> A string. Note the double quotes. <code>17</code> An integer <code>true</code> A boolean <code>{\"name\": \"Julie\", \"age\": 37}</code> A JSON object with two fields, <code>name</code> (a string), and <code>age</code> (an integer). Objects are denoted with curly braces. <code>[ true, false, true]</code> A JSON array with three booleans. Arrays are denoted with square brackets. <p>For more details on JSON, please see https://www.json.org/.</p>"},{"location":"References/Schemas/#json-schemas_1","title":"JSON Schemas","text":"<p>The \"JSON schema\" format is built on top of JSON. This adds some special rules and keywords that are intended to facilitate the description of the format of data (whereas \"raw\" JSON is intended for storing data).</p> <p>Here is an example of a JSON schema that defines a (simplified) US address:</p> <pre><code>{\n\"type\": \"object\",\n\"required\": [\"name\", \"streetNumber\", \"street\", \"city\", \"state\", \"zip5\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"name\": { \"type\": \"string\" },\n\"streetNumber\": { \"type\": \"string\" },\n\"street\": { \"type\": \"string\" },\n\"unit\": { \"type\": \"string\" },\n\"city\": { \"type\": \"string\", \"pattern\": \"^[A-Z][A-Za-z ]*$\" },\n\"state\": { \"type\": \"string\", \"pattern\": \"^[A-Z]{2}$\" },\n\"zip5\": { \"type\": \"string\", \"pattern\": \"^[0-9]{5}\"},\n\"zipPlus4\": { \"type\": \"string\", \"pattern\": \"^[0-9]{4}\"}\n}\n}\n</code></pre> <p>Note that this is perfectly valid JSON data. It's a JSON object with four fields: <code>type</code> (a JSON string), <code>required</code> (A JSON array), <code>additionalProperties</code> (a JSON boolean), and <code>properties</code>. <code>properties</code>, in turn is a JSON object with with 8 fields, each of which is a JSON object, with its own properties, etc.</p> <p>But, this isn't just a JSON object. This is a JSON schema. It uses special keywords like <code>type</code> <code>required</code>, and <code>additionalProperties</code>. These have specially-defined meanings in the context of JSON schemas.</p> <p>Here is a list of the special keywords used by the above schema. Note that this is only a small subset of JSON schema keywords.</p> keyword description <code>additionalProperties</code> Determines whether the schema allows properties that are not explicitly listed in the <code>properties</code> specification. Must be a <code>true</code> or <code>false</code>. <code>pattern</code> Used with string types to specify a regular expression that the property must conform to. <code>required</code> A list of required properties. Properties not listed in this list are optional. <code>string</code> Used with <code>type</code> to declare that a property must be a string. <code>type</code> Specifies a datatype. Common values are <code>object</code>, <code>array</code>, <code>number</code>, <code>integer</code>, <code>boolean</code>, and <code>string</code>. <p>Some points to note about the address schema above:</p> <ul> <li>Because of the <code>required</code> list, all valid addresses must have fields called <code>name</code>, <code>streetNumber</code> and so on.</li> <li><code>unit</code> and <code>zipPlus4</code> do not appear in the <code>required</code> list, and therefore are optional.</li> <li>Because of <code>additionalProperties</code> being <code>false</code>, valid addresses cannot make up their own fields like <code>nickname</code> or <code>doorbellLocation</code>.</li> <li>Because of the <code>pattern</code>, any <code>state</code> field in a valid address must consist of exactly two capital letters.</li> <li>Similarly, <code>city</code> must only contain letters and spaces, and <code>zip</code> and <code>zipPlus4</code> must only contain digits.</li> <li>Each property has its own valid subschema that describes its own type definition.</li> </ul> <p>Here is a JSON object that conforms to the above schema:</p> <pre><code>{\n\"name\": \"Delphix\",\n\"streetNumber\": \"220\",\n\"street\": \"Congress St.\",\n\"unit\": \"200\",\n\"city\": \"Boston\",\n\"state\": \"MA\",\n\"zip\": \"02210\"\n}\n</code></pre> <p>Info</p> <p>A common point of confusion is the distinction between a JSON schema and a JSON object that conforms to a schema. Remember, a schema describes the form of data. In our example, the schema describes what an address looks like. The address itself is not a schema.</p> <p>For much more detail on JSON schemas, including which keywords are available, what they mean, and where you can use them, see https://json-schema.org/understanding-json-schema/.</p> <p>Info</p> <p>Be careful when using the JSON schema keyword <code>default</code>. This keyword is commonly misunderstood. Specifically, it does not mean \"If the user does not provide a value, then this default value will be auto-substituted instead\", as you might expect. In fact, in JSON schemas, <code>default</code> has no semantic meaning at all! Currently, the only thing the Delphix Engine will use this for is to pre-fill widgets on the UI.</p>"},{"location":"References/Schemas/#delphix-specific-extensions-to-json-schema","title":"Delphix-specific Extensions to JSON Schema","text":"<p>The JSON schema vocabulary is designed to be extensible for special uses, and Delphix has taken advantage of this to add some new Delphix-specific keywords.</p> <p>The list below outlines each of these keywords, and provides minimal examples of how they might be used.</p>"},{"location":"References/Schemas/#description","title":"<code>description</code>","text":"Summary Required or Optional? Optional Where? In any property subschema, at the same level as <code>type</code>. <p>The <code>description</code> keyword can optionally appear on any property. If it does appear, it is used by the UI as explanatory text for the UI widget associated with the property. If it does not appear, then no explanatory text is shown.</p> <p>In this example, the UI would show \"User-readable name for the provisioned database\" in small text under the widget.</p> <pre><code>{\n\"properties\": {\n\"name\": {\n\"type\": \"string\",\n\"description\": \"User-readable name for the provisioned database\"\n}\n}\n}\n</code></pre>"},{"location":"References/Schemas/#identityfields","title":"<code>identityFields</code>","text":"Summary Required or Optional? Required (for repository and source config schemas only) Where? At the top level of a repository or source config schema, at the same level as <code>type</code> and <code>properties</code>. <p>The <code>identityFields</code> is a list of property names that, together, serve as a unique identifier for a repository or source config.</p> <p>When a plugin's automatic discovery code is called, it will return a list of repositories (or source configs). The Delphix Engine needs to be able to compare this new list with whatever repositories it already knows about.</p> <p>For example, suppose the engine already knows about a single repository with data <code>{\"dbname\": \"my_databsae\", \"path\": \"/var/db/db01\"}</code> (note the misspelling!). And, then suppose that automatic discovery is re-run and it returns repository data <code>{ \"dbname\": \"my_database\", \"path\": \"/var/db/db01\"}</code>.</p> <p>What should the Delphix Engine do? Should it conclude that \"my_databsae\" has been deleted, and there is a completely new repository named \"my_database\"? Or, should it conclude that we still have the same old repository, but with an updated name?</p> <p><code>identityFields</code> is used to handle this. When the engine compares \"new\" data with \"old\" data, it concludes that they belong to the same repository if all of the identity fields match. If any of the identity fields do not match, then the \"new\" repository data is judged to represent a different repository than the old data.</p> <p><code>identityFields</code> is required for RepositoryDefinition and SourceConfigDefinition schemas, and may not be used in any other schemas.</p> <p>In this example, we'll tell the Delphix Engine that <code>path</code> is the sole unique identifier.</p> <pre><code>{\n\"properties\": {\n\"dbname\": {\"type\": \"string\"},\n\"path\": {\"type\": \"string\"}\n},\n\"identityFields\": [\"path\"]\n}\n</code></pre>"},{"location":"References/Schemas/#namefield","title":"<code>nameField</code>","text":"Summary Required or Optional? Required (for repository and source config schemas only) Where? At the top level of a repository or source config schema, at the same level as <code>type</code> and <code>properties</code>. <p>The <code>nameField</code> keyword specifies a single property that is to be used to name the object in the Delphix Engine. The property must be a string field. This keyword is used at the same level as <code>properties</code>. It is required for RepositoryDefinition and SourceConfigDefinition schemas, and may not be used in any other schemas.</p> <p>In this example, we will use the <code>path</code> property as the user-visible name.</p> <pre><code>{\n\"properties\": {\n\"path\": { \"type\": \"string\" },\n\"port\": { \"type\": \"integer\" }\n},\n\"nameField\": \"path\"\n}\n</code></pre> <p>So, if we have an repository object that looks like</p> <p><pre><code>{\n\"path\": \"/usr/bin\",\n\"port\": 8800\n}\n</code></pre> then the user will be able to refer to this object as <code>/usr/bin</code>.</p>"},{"location":"References/Schemas/#ordering","title":"<code>ordering</code>","text":"Summary Required or Optional? Optional Where? At the top level, same level as <code>type</code> and <code>properties</code>. <p>The <code>ordering</code> keyword can be used to order the fields when the UI is autogenerated.</p> <pre><code>{\n\"properties\": {\n\"path\": { \"type\": \"string\" },\n\"port\": { \"type\": \"integer\" }\n},\n\"ordering\": [\"port\", \"path\"]\n}\n</code></pre> <p>In the example above, the <code>port</code> will be the first field in the autogenerated UI wizard followed by <code>path</code>.</p>"},{"location":"References/Schemas/#password","title":"<code>password</code>","text":"Summary Required or Optional? Optional Where? As the value for the <code>format</code> keyword in any string property's subschema. <p>The <code>password</code> keyword can be used to specify the <code>format</code> of a <code>string</code>. (Note that <code>format</code> is a standard keyword and is not Delphix-specific). If a property is tagged as a password, then the UI will never show the value on screen, and the value will be encrypted before being stored as described here.</p> <p>In this example, the <code>dbPass</code> field on any object will be treated as a password.</p> <pre><code>{\n\"properties\": {\n\"dbPass\": {\n\"type\": \"string\",\n\"format\": \"password\"\n}\n}\n}\n</code></pre>"},{"location":"References/Schemas/#prettyname","title":"<code>prettyName</code>","text":"Summary Required or Optional? Optional Where? In any property subschema, at the same level as <code>type</code>. <p>The <code>prettyName</code> keyword can optionally appear on any property. If it does appear, it is used by the UI as a title for the UI widget associated with the property. If it does not appear, then the name of the property is used.</p> <p>In this example, the user would see \"Name of Database\" on the UI, instead of just \"name\".</p> <pre><code>{\n\"properties\": {\n\"name\": {\n\"type\": \"string\",\n\"prettyName\": \"Name of Database\"\n}\n}\n}\n</code></pre>"},{"location":"References/Schemas/#unixpath","title":"<code>unixpath</code>","text":"Summary Required or Optional? Optional Where? As the value for the <code>format</code> keyword in any string property's subschema. <p>The <code>unixpath</code> keyword is used to specify the <code>format</code> of a string. This will allow the Delphix Engine to verify and enforce that a particular field can be parsed as a valid Unix path.</p> <pre><code>{\n\"properties\": {\n\"datapath\": {\n\"type\": \"string\",\n\"format\": \"unixpath\"\n}\n}\n}\n</code></pre>"},{"location":"References/Schemas/#reference","title":"<code>reference</code>","text":"Summary Required or Optional? Optional Where? As the value for the <code>format</code> keyword in any string property's subschema. <p>The <code>reference</code> keyword is used to specify the <code>format</code> of a string. This will allow the plugin author to ask the user to select environments and environment users on the Delphix Engine.</p> <pre><code>\"properties\": {\n\"env\": {\n\"type\": \"string\",\n\"format\": \"reference\",\n\"referenceType\": \"UNIX_HOST_ENVIRONMENT\"\n},\n\"envUser\": {\n\"type\": \"string\",\n\"format\": \"reference\",\n\"referenceType\": \"HOST_USER\",\n\"matches\": \"env\"\n}\n}\n</code></pre>"},{"location":"References/Schemas/#referencetype","title":"<code>referenceType</code>","text":"Summary Required or Optional? Optional Where? In any property subschema of type <code>string</code> and format <code>reference</code>, at the same level as type. <p>The <code>referenceType</code> keyword is used to specify the reference type. Possible values:</p> <ul> <li>Environment: <code>UNIX_HOST_ENVIRONMENT</code></li> <li>Environment User: <code>HOST_USER</code></li> </ul> <pre><code>\"properties\": {\n\"env\": {\n\"type\": \"string\",\n\"format\": \"reference\",\n\"referenceType\": \"UNIX_HOST_ENVIRONMENT\"\n},\n\"envUser\": {\n\"type\": \"string\",\n\"format\": \"reference\",\n\"referenceType\": \"HOST_USER\",\n\"matches\": \"env\"\n}\n}\n</code></pre>"},{"location":"References/Schemas/#matches","title":"<code>matches</code>","text":"Summary Required or Optional? Optional Where? In any property subschema of type <code>string</code> and format <code>reference</code>, at the same level as type. <p>The <code>matches</code> keyword is used to map an environment user to an environment by specifying the environment's property name.</p> <pre><code>\"properties\": {\n\"env\": {\n\"type\": \"string\",\n\"format\": \"reference\",\n\"referenceType\": \"UNIX_HOST_ENVIRONMENT\"\n},\n\"envUser\": {\n\"type\": \"string\",\n\"format\": \"reference\",\n\"referenceType\": \"HOST_USER\",\n\"matches\": \"env\"\n}\n}\n</code></pre> <p>In the example above, environment user <code>envUser</code> maps to environment <code>env</code>.</p>"},{"location":"References/Schemas/#dxformproperties","title":"<code>dxFormProperties</code>","text":"Summary Required or Optional? Optional Where? In any property subschema, at the same level as <code>type</code>. <p>The <code>dxFormProperties</code> keyword is used to generate dynamic UI and better show the configuration details to user on Delphix Engine UI.</p> <pre><code>\"properties\": {\n\"textAreaField\": {\n\"type\": \"string\",\n\"dxFormProperties\": {\n\"rows\": 5 }\n},\n\"userName\": {\n\"type\": \"string\",\n\"minLength\": 8,\n\"pattern\": \"postgre.*\",\n\"dxFormProperties\": {\n\"validationMessages\": {\n\"minLength\": \"The minimum length for userName should be 8.\",\n\"pattern\": \"The userName should start with \\\"postgre\\\".\"\n}\n}\n}\n}\n</code></pre> <p>In the example above, </p> <ul> <li>providing <code>rows</code> to <code>textAreaField</code> of type <code>string</code> convert it to a Text Area in UI. </li> <li>For <code>userName</code> providing <code>custom validation message</code> for inputs helps user better understand the input requirements.</li> </ul>"},{"location":"References/Schemas/#delphix-specific-pre-defined-types","title":"Delphix-specific Pre-defined Types","text":"<p>Plugins can also take advantage of pre-defined object types offered by Delphix. Currently, these object types let users supply credentials to plugins directly or via password vaults. Password vaults have a number of benefits for securing and managing secrets.</p> <p>These pre-defined types can be referenced by JSON schemas via the external schema identifier <code>https://delphix.com/platform/api</code>. This is only an identifier, not a web address.</p> <p>The list below describes each of these definitions and shows how they can be referenced by plugins and users. (To understand how to use these objects at runtime, see this section.)</p>"},{"location":"References/Schemas/#credentialssupplier","title":"<code>credentialsSupplier</code>","text":"<p>Defines an object type that lets users supply credentials consisting of a username (optional) and a secret. The secret can be a password or a private key. In case of a private key, a corresponding public key may also be included. This data can be entered directly by the user or supplied by a password vault. If as password or private key is entered directly, the UI will never show the value on screen, and the value will be encrypted before being stored as described here.</p> <p>An example of a JSON schema using this type is:</p> <p><pre><code>\"properties\": {\n\"myCredentials\": {\n\"$ref\": \"https://delphix.com/platform/api#/definitions/credentialsSupplier\"\n}\n}\n</code></pre> where <code>credentialsSupplier</code> is a definition in the external schema <code>https://delphix.com/platform/api</code>.</p> <p>When providing data for a property of this type, the user has the following four options.</p>"},{"location":"References/Schemas/#option-1-username-and-password","title":"Option 1: Username and password","text":"<p>For this option, the user must provide data that satisfies this definition: <pre><code>{\n\"type\": \"object\",\n\"required\": [\"type\", \"password\"],\n\"properties\": {\n\"type\": {\n\"type\": \"string\",\n\"const\": \"NamedPasswordCredential\"\n},\n\"username\": {\n\"type\": \"string\"\n},\n\"password\": {\n\"type\": \"string\",\n\"format\": \"password\"\n}\n}\n}\n</code></pre> where <code>type</code> is a constant of value <code>NamedPasswordCredential</code>. This value is needed by the Delphix engine to determine the option being used. The graphical user interface will not show this element; it will send this constant value automatically to the Delphix engine.</p> <p>The <code>username</code> property is optional.</p> <p>For example, the user, or the user interface on behalf of the user, can provide: <pre><code>\"properties\": {\n\"myCredentials\": {\n\"type\": \"NamedPasswordCredential\",\n\"username\": \"my user name\",\n\"password\": \"my password\"\n}\n}\n</code></pre></p>"},{"location":"References/Schemas/#option-2-username-and-keys","title":"Option 2: Username and key(s)","text":"<p>For this option, the user must provide data that satisfies this definition: <pre><code>{\n\"type\": \"object\",\n\"required\": [\"type\", \"privateKey\"],\n\"properties\": {\n\"type\": {\n\"type\": \"string\",\n\"const\": \"NamedKeyPairCredential\"\n},\n\"username\": {\n\"type\": \"string\"\n},\n\"publicKey\": {\n\"type\": \"string\"\n},\n\"privateKey\": {\n\"type\": \"string\",\n\"format\": \"password\"\n}\n}\n}\n</code></pre> where the <code>username</code> and <code>publicKey</code> properties are optional, and <code>type</code> is a constant that the user interface will submit automatically on behalf of the user.</p> <p>For example, the user, or the user interface on behalf of the user, can provide: <pre><code>\"properties\": {\n\"myCredentials\": {\n\"type\": \"NamedKeyPairCredential\",\n\"username\": \"my user name\",\n\"publicKey\": \"AAA4QG...HBCDD3=\",\n\"privateKey\": \"-----BEGIN RSA PRIVATE KEY-----...-----END RSA PRIVATE KEY-----\"\n}\n}\n</code></pre></p>"},{"location":"References/Schemas/#option-3-cyberark-vault-credentials","title":"Option 3: CyberArk vault credentials","text":"<p>For this option, the user must provide data that satisfies this definition: <pre><code>{\n\"type\": \"object\",\n\"required\": [\"type\", \"vault\", \"queryString\"],\n\"properties\": {\n\"type\": {\n\"type\": \"string\",\n\"const\": \"CyberArkVaultCredential\"\n},\n\"vault\": {\n\"type\": \"string\",\n\"format\": \"reference\",\n\"referenceType\": \"CyberArkPasswordVault\"\n},\n\"queryString\": {\n\"type\": \"string\"\n},\n\"expectedSecretType\": {\n\"type\": \"string\",\n\"enum\": [\"any\", \"password\", \"keyPair\"],\n\"default\": \"any\"\n}\n}\n}\n</code></pre> where <code>type</code> is a constant that the user interface will submit automatically on behalf of the user, <code>vault</code> is a reference to a CyberArk vault configured in the system, and <code>queryString</code> is a parameter for locating the credentials in the vault. For details on configuring and using CyberArk vaults, see the password-vaults documentation for the Delphix engine.</p> <p>Optionally, <code>expectedSecretType</code> lets the user constrain the secret returned by the vault to passwords or keys (the default is to allow <code>any</code> of those two types of secret). An unexpected type of secret returned by the vault will result in a runtime exception.</p> <p>For example, the user, or the user interface on behalf of the user, can provide: <pre><code>\"properties\": {\n\"myCredentials\": {\n\"type\": \"CyberArkVaultCredential\",\n\"vault\": \"CYBERARK_PASSWORD_VAULT-1\",\n\"queryString\": \"Safe=test;Object=myObject\"\n}\n}\n</code></pre></p>"},{"location":"References/Schemas/#option-4-hashicorp-vault-credentials","title":"Option 4: HashiCorp vault credentials","text":"<p>For this option, the user must provide data that satisfies this definition: <pre><code>{\n\"type\": \"object\",\n\"required\": [\"type\", \"vault\", \"engine\", \"path\", \"usernameKey\", \"secretKey\"],\n\"properties\": {\n\"type\": {\n\"type\": \"string\",\n\"const\": \"HashiCorpVaultCredential\"\n},\n\"vault\": {\n\"type\": \"string\",\n\"format\": \"reference\",\n\"referenceType\": \"HashiCorpVault\"\n},\n\"engine\": {\n\"type\": \"string\"\n},\n\"path\": {\n\"type\": \"string\"\n},\n\"usernameKey\": {\n\"type\": \"string\"\n},\n\"secretKey\": {\n\"type\": \"string\"\n},\n\"expectedSecretType\": {\n\"type\": \"string\",\n\"enum\": [\"any\", \"password\", \"keyPair\"],\n\"default\": \"any\"\n}\n}\n}\n</code></pre> where <code>type</code> is a constant that the user interface will submit automatically on behalf of the user, <code>vault</code> is a reference to a HashiCorp vault configured in the system, and <code>engine</code>, <code>path</code>, <code>usernameKey</code> and <code>secretKey</code> are parameters for locating the credentials in the vault. For details on configuring and using HashiCorp vaults, see the password-vaults documentation for the Delphix engine.</p> <p>Optionally, <code>expectedSecretType</code> lets the user constrain the secret returned by the vault to passwords or keys (the default is to allow <code>any</code> of those two types of secret). An unexpected type of secret returned by the vault will result in a runtime exception.</p> <p>The <code>type</code> property is a constant that the user interface will submit automatically on behalf of the user.</p> <p>For example, the user, or the user interface on behalf of the user, can provide: <pre><code>\"properties\": {\n\"myCredentials\": {\n\"type\": \"HashiCorpVaultCredential\",\n\"vault\": \"HASHICORP_VAULT-2\",\n\"engine\": \"kv-v2\",\n}\n}\n</code></pre></p>"},{"location":"References/Schemas/#keycredentialssupplier","title":"<code>keyCredentialsSupplier</code>","text":"<p>This object type is identical to <code>credentialsSupplier</code> but requires the secrets to be keys. The available options are keys, CyberArk vaults and HashiCorp vaults. The property <code>expectedSecretType</code> is required in all cases and must have the value <code>keyPair</code>.</p>"},{"location":"References/Schemas/#passwordcredentialssupplier","title":"<code>passwordCredentialsSupplier</code>","text":"<p>This object type is identical to <code>credentialsSupplier</code> but requires the secrets to be passwords. The available options are passwords, CyberArk vaults and HashiCorp vaults. The property <code>expectedSecretType</code> is required in all cases and must have the value <code>keyPair</code>.</p>"},{"location":"References/Schemas/#json-schema-limitations","title":"JSON Schema Limitations","text":"<p>To be able to autogenerate Python classes there are some restrictions to the JSON Schemas that are supported.</p>"},{"location":"References/Schemas/#generation-error","title":"Generation Error","text":"<p>There are some valid JSON schemas that will cause the property to not be generated in the autogenerated Python classes. Unfortunately the build command will silently fail so be sure to look at the generated classes and verify all the properties exist.</p>"},{"location":"References/Schemas/#multiple-types","title":"Multiple types","text":"<p>For the <code>type</code> keyword, only a single type may be specified. Arrays of types are not supported. <pre><code>{\n\"repositoryDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\": \"false\",\n\"properties\": {\n\"data\": {\n\"type\": [\"integer\", \"string\"]\n}\n},\n\"nameField\": \"data\",\n\"identityFields\": [\"data\"]\n}\n}\n</code></pre> The <code>data</code> property will not even exist: <pre><code>from generated.defintions import RepositoryDefinition\nrepository = RepositoryDefinition()\nrepository.data = 3\nprint(repository)\n</code></pre> This would print: <pre><code>{}\n</code></pre></p>"},{"location":"References/Schemas/#combining-schemas","title":"Combining schemas","text":"<p>For the following keywords, if they are specified the property will not exist in the class. * anyOf * allOf * oneOf * not <pre><code>{\n\"repositoryDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\": \"false\",\n\"properties\": {\n\"any\": {\n\"anyOf\": [\n{\"type\": \"integer\", \"minimum\": 2},\n{\"type\": \"string\", \"minLength\": 4}\n]\n},\n\"one\": {\n\"oneOf\": [\n{\"type\": \"integer\", \"minimum\": 3},\n{\"type\": \"integer\", \"maximum\": 5}\n]\n}\n},\n\"nameField\": \"data\",\n\"identityFields\": [\"data\"]\n}\n}\n</code></pre> The <code>any</code> and <code>one</code> properties would not exist: <pre><code>from generated.defintions import RepositoryDefinition\nrepository = RepositoryDefinition()\nrepository.any = \"string\"\nrepository.one = 6\nprint(repository)\n</code></pre> This would print: <pre><code>{}\n</code></pre></p>"},{"location":"References/Schemas/#object-additional-properties","title":"Object Additional Properties","text":"<p>The <code>additionalProperties</code> keyword inside the object property can either be a boolean or a JSON schema. If it is a schema it needs to have the keyword <code>type</code>. If the <code>additionalProperties</code> is set to a JSON schema then the <code>properties</code> keyword will be ignored. If the keyword is set to a boolean the behaviour will be the same regardless of if it was set to <code>true</code> or <code>false</code>.</p> <p><pre><code>{\n\"repositoryDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\": \"false\",\n\"properties\": {\n\"dataOne\": {\n\"type\": \"object\",\n\"addtionalProperties\": {\"type\": \"string\"}\n},\n\"dataTwo\": {\n\"type\": \"object\",\n\"addtionalProperties\": {\"type\": \"string\"},\n\"properties\": {\n\"data\": {\"type\": \"string\"}\n}\n},\n\"dataThree\": {\n\"type\": \"object\",\n\"addtionalProperties\": \"false\",\n\"properties\": {\n\"data\": {\"type\": \"string\"}\n}\n},\n\"dataFour\": {\n\"type\": \"object\",\n\"addtionalProperties\": \"true\",\n\"properties\": {\n\"data\": {\"type\": \"string\"}\n}\n},\n\"dataFive\": {\n\"type\": \"object\",\n\"addtionalProperties\": \"false\",\n},\n\"dataSix\": {\n\"type\": \"object\",\n\"addtionalProperties\": \"true\",\n}\n},\n\"nameField\": \"dataOne\",\n\"identityFields\": [\"dataOne\"]\n}\n}\n</code></pre> From the schema above, the properties <code>dataOne</code> and <code>dataTwo</code>, <code>dataThree</code> and <code>dataFour</code>, and <code>dataFive</code> and <code>dataSix</code> will have an identical validations. The first two will validate that the object passed in is a dict with key and value both <code>string</code> type. The next two will create a new inner Python class called either <code>OtherDefinitionDataThree</code> or <code>OtherDefinitionDataFour</code>, they optomize for creating only one as they are identical. Inside that object will be one property <code>data</code>. The last two properties will validate that the object passed in is a dict with the key as a <code>string</code> type, and the value can be anything.</p>"},{"location":"References/Schemas/#validation-keywords","title":"Validation Keywords","text":"<p>In general all property types are supported however some validation keywords will be ignored during the execution of the Python code. This means that if these keywords are used, no error would be raised within Python if the object violates the schema. Listed below are the keywords ignored for each type that wouldn't validate. Some have examples to be more clear.</p>"},{"location":"References/Schemas/#number-integer","title":"Number / Integer","text":"<ul> <li>multipleOf <pre><code>{\n\"repositoryDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\": \"false\",\n\"properties\": {\n\"data\": {\n\"type\": \"integer\",\n\"multipleOf\": 2\n}\n},\n\"nameField\": \"data\",\n\"identityFields\": [\"data\"]\n}\n}\n</code></pre> This would work even though it would fail the schema check: <pre><code>from generated.defintions import RepositoryDefinition\nrepository = RepositoryDefinition()\nrepository.data = 3\n</code></pre></li> </ul>"},{"location":"References/Schemas/#arrays-tuples","title":"Arrays / Tuples","text":"<ul> <li>additionalItems</li> <li>minItems</li> <li>maxItems</li> <li>uniqueItems</li> <li>contains</li> <li>items<ul> <li>Must be a single type, not an array (tuples are not supported): <pre><code>{\n\"repositoryDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\": \"false\",\n\"properties\": {\n\"data\": {\n\"type\": \"array\",\n\"items\": [\n{\"type\": \"number\"},\n{\"type\": \"string\"},\n{\"type\": \"boolean\"}\n]\n}\n},\n\"nameField\": \"data\",\n\"identityFields\": [\"data\"]\n}\n}\n</code></pre> This would work even though it would fail the schema check: <pre><code>from generated.defintions import RepositoryDefinition\nrepository = RepositoryDefinition()\nrepository.data = [\"string\", False, 3]\n</code></pre></li> </ul> </li> </ul>"},{"location":"References/Schemas/#objects","title":"Objects","text":"<ul> <li>minProperties</li> <li>maxProperties</li> <li>patternProperties</li> <li>dependencies</li> <li>propertyNames</li> </ul>"},{"location":"References/Schemas/#enumerated-values","title":"Enumerated values","text":"<p>If the <code>enum</code> keyword is used within a subobject, <code>type</code> has to be <code>string</code>. <pre><code>{\n\"repositoryDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\": \"false\",\n\"properties\": {\n\"stringData\": {\n\"enum\": [\"A\", \"B\", \"C\"]\n},\n\"arrayData\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\"DO\", \"RE\", \"MI\"]\n}\n},\n\"objectData\": {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"enum\": [\"ONE\", \"TWO\", \"THREE\"]\n}\n},\n\"definedObjectData\": {\n\"type\": \"object\",\n\"properties\": {\n\"objectStringData\": {\n\"enum\": [\"o.A\", \"o.B\", \"o.C\"]\n},\n},\n\"additionalProperties\": \"false\"\n}\n},\n\"nameField\": \"stringData\",\n\"identityFields\": [\"stringData\"]\n}\n}\n</code></pre> In the above example there are four properties: <code>stringData</code>, <code>arrayData</code>, <code>objectData</code>, and <code>definedObjectData</code>. Validation works for stringData but are skipped for the other three. In fact the definedObjectData which with properties would usually create a separte Python class does not at all. This means the following code would work even though it would fail the schema check: <pre><code>from generated.defintions import RepositoryDefinition\nrepository = RepositoryDefinition()\nrepository.array_data = [10, 11, 12]\nrepository.object_data = {\"key\": 1}\nrepository.defined_object_data = {\"key\": 2}\n</code></pre> And this code would actually fail with a <code>GeneratedClassesError</code> during the Python execution saying <code>Invalid enum value D for 'string_data', must be one of [A, B, C] if defined.</code>: <pre><code>from generated.defintions import RepositoryDefinition\nrepository = RepositoryDefinition()\nrepository.string_data = \"D\"\n</code></pre></p>"},{"location":"References/Schemas_and_Autogenerated_Classes/","title":"Schemas and Autogenerated Classes","text":"<p>Plugin operations will sometimes need to work with data in these custom formats. For example, the <code>configure</code> operation will accept snapshot data as an input, and must produce source config data as an output.</p> <p>To enable this, Python classes are generated from the snapshot schema. The aforementioned inputs and outputs are instances of these autogenerated classes.</p> <p>Info</p> <p>Autogenerated Python code will use <code>lower_case_with_underscores</code> as attribute names as per Python variable naming conventions. That is, if we were to use <code>mountLocation</code> as the schema property name, it would be called <code>mount_location</code> in the generated Python code.</p> <p>Info</p> <p>Note that, wherever they can, these generated Python classes will enforce the constraints made by the schema. For example, if a property is listed as <code>required</code> in the schema, then every Python object will be required to always have this property. This implies that all <code>required</code> fields must be given values when the object is constructed. For various examples of this, see the examples below.</p>"},{"location":"References/Schemas_and_Autogenerated_Classes/#repositorydefinition","title":"RepositoryDefinition","text":"<p>Defines properties used to identify a Repository.</p>"},{"location":"References/Schemas_and_Autogenerated_Classes/#repositorydefinition-schema","title":"RepositoryDefinition Schema","text":"<p>The plugin must also decide on a name field and a set of identityFields to display and uniquely identify the repository.</p> <pre><code>{\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"required\": [\"name\", \"path\"],\n\"properties\": {\n\"name\": { \"type\": \"string\" },\n\"path\": { \"type\": \"string\" }\n},\n\"identityFields\": [\"name\", \"path\"],\n\"nameField\": \"name\"\n}\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#repositorydefinition-class","title":"RepositoryDefinition Class","text":"<p>Autogenerated based on the RepositoryDefinition Schema.</p> <pre><code>class RepositoryDefinition:\ndef __init__(self, name, path):\nself._inner_dict = {\"name\": name, \"path\": path}\n</code></pre> <p>To use the class:</p> <pre><code>from generated.defintions import RepositoryDefinition\n# Since both properties are required, they must be specified when constructing the object\nrepository = RepositoryDefinition(name=\"name\", path=\"/some/path\")\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#sourceconfigdefinition","title":"SourceConfigDefinition","text":"<p>Defines properties used to identify a Source Config.</p>"},{"location":"References/Schemas_and_Autogenerated_Classes/#sourceconfigdefinition-schema","title":"SourceConfigDefinition Schema","text":"<p>The plugin must also decide on a name field and a set of identityFields to display and uniquely identify the source config.</p> <pre><code>{\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"required\": [\"name\"],\n\"properties\": {\n\"name\": { \"type\": \"string\" },\n\"path\": { \"type\": \"string\" }\n},\n\"identityFields\": [\"name\"],\n\"nameField\": \"name\"\n}\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#sourceconfigdefinition-class","title":"SourceConfigDefinition Class","text":"<p>Autogenerated based on the SourceConfigDefinition Schema.</p> <pre><code>class SourceConfigDefinition:\ndef __init__(self, name, path):\nself._inner_dict = {\"name\": name, \"path\": path}\n</code></pre> <p>To use the class:</p> <pre><code>from generated.defintions import SourceConfigDefinition\n# A source config that only defines the required \"name\" property.\nsource_config1 = SourceConfigDefinition(name=\"sc1\")\n# A Source config that defines both \"name\" and \"path\".\nsource_config2 = SourceConfigDefinition(name=\"sc2\", path=\"/some/path\")\n# Setting the optional \"path\" property after construction\nsource_config3 = SourceConfigDefinition(name=\"sc3\")\ninstall_path = find_install_path()\nsource_config3.path = install_path\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#linkedsourcedefinition","title":"LinkedSourceDefinition","text":"<p>Defines properties used to identify linked sources.</p>"},{"location":"References/Schemas_and_Autogenerated_Classes/#linkedsourcedefinition-schema","title":"LinkedSourceDefinition Schema","text":"<pre><code>{\n\"type\": \"object\",\n\"required\": [\"name\", \"port\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"name\": { \"type\": \"string\" },\n\"port\": { \"type\": \"integer\" }\n}\n}\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#linkedsourcedefinition-class","title":"LinkedSourceDefinition Class","text":"<p>Autogenerated based on the LinkedSourceDefinition Schema.</p> <pre><code>class LinkedSourceDefinition:\ndef __init__(self, name, port):\nself._inner_dict = {\"name\": name, \"port\": port}\n</code></pre> <p>To use the class:</p> <pre><code>from generated.defintions import LinkedSourceDefinition\nsource = LinkedSourceDefinition(name=\"name\", port=1000)\n# Retrieve the properties from the object and log them\nname = source.name\nport = source.port\nlogger.debug(\"Creating source \\\"{}\\\" with port {}\".format(name, port))\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#virtualsourcedefinition","title":"VirtualSourceDefinition","text":"<p>Defines properties used to identify virtual sources.</p>"},{"location":"References/Schemas_and_Autogenerated_Classes/#virtualsourcedefinition-schema","title":"VirtualSourceDefinition Schema","text":"<pre><code>{\n\"type\": \"object\",\n\"required\": [\"name\", \"port\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"name\": { \"type\": \"string\" },\n\"port\": { \"type\": \"integer\" }\n}\n}\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#virtualsourcedefinition-class","title":"VirtualSourceDefinition Class","text":"<p>Autogenerated based on the VirtualSourceDefinition Schema.</p> <pre><code>class VirtualSourceDefinition:\ndef __init__(self, name, port):\nself._inner_dict = {\"name\": name, \"port\": port}\n</code></pre> <p>To use the class:</p> <pre><code>from generated.defintions import VirtualSourceDefinition\nsource = VirtualSourceDefinition(name=\"name\", port=1000)\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#snapshotdefinition","title":"SnapshotDefinition","text":"<p>Defines properties used to snapshots.</p>"},{"location":"References/Schemas_and_Autogenerated_Classes/#snapshotdefinition-schema","title":"SnapshotDefinition Schema","text":"<pre><code>{\n\"type\": \"object\",\n\"properties\": {\n\"version\": { \"type\": \"string\" },\n\"transation_id\": { \"type\": \"integer\" }\n}\n}\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#snapshotdefinition-class","title":"SnapshotDefinition Class","text":"<p>Autogenerated based on the Snapshot Schema.</p> <pre><code>class SnapshotDefinition:\ndef __init__(self, version, transaction_id):\nself._inner_dict =\n{\n\"version\": version,\n\"transaction_id\": transaction_id\n}\n</code></pre> <p>To use the class:</p> <pre><code>from generated.defintions import SnapshotDefinition\n# A snapshot with both properties defined at construction time\nsnapshot1 = SnapshotDefinition(version=\"1.2.3\", transaction_id=1000)\n# A snapshot with properties defined after construction\nsnapshot2 = SnapshotDefinition()\nsnapshot2.version = \"2.0.0\"\nsnapshot2.transaction_id = 1500\n# A snapshot that omits the optional \"transaction_id\" property\nsnapshot3 = SnapshotDefinition(version=\"1.0.0\")\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#snapshotparametersdefinition","title":"SnapshotParametersDefinition","text":"<p>Defines Snapshot Parameters for the snapshot operation.</p>"},{"location":"References/Schemas_and_Autogenerated_Classes/#snapshotparametersdefinition-schema","title":"SnapshotParametersDefinition Schema","text":"<pre><code>{\n\"type\": \"object\",\n\"required\": [\"resync\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"resync\": { \"type\": \"boolean\" }\n}\n}\n</code></pre>"},{"location":"References/Schemas_and_Autogenerated_Classes/#snapshotparametersdefinition-class","title":"SnapshotParametersDefinition Class","text":"<p>Autogenerated based on the Snapshot Parameters Definition Schema.</p> <pre><code>class SnapshotParametersDefinition:\ndef __init__(self, resync):\nself._inner_dict = { \"resync\": resync }\n</code></pre> <p>To use the class:</p> <pre><code>from generated.defintions import SnapshotParametersDefinition\n# Since \"resync\" is required, it must be specified when constructing the object\nsnapshot_parameter_definition = SnapshotParametersDefinition(resync=True)\n</code></pre>"},{"location":"References/Version_Compatibility/","title":"Virtualization SDK Version Compatibility","text":""},{"location":"References/Version_Compatibility/#virtualization-sdk-and-delphix-engine-de-compatibility-map","title":"Virtualization SDK and Delphix Engine (DE) Compatibility Map","text":"vSDK Version Earliest Supported DE Version Latest Supported DE Version 4.1.0 12.0.0.0 Latest Release 4.0.5 6.0.16.0 Latest Release 4.0.2 6.0.12.0 Latest Release 3.1.0 6.0.7.0 Latest Release 3.0.0 6.0.6.0 Latest Release 2.1.0 6.0.3.0 Latest Release 2.0.0 6.0.2.0 Latest Release 1.0.0 6.0.2.0 14.0.0.0 0.4.0 5.3.5.0 6.0.1.0"},{"location":"References/Version_Compatibility/#virtualization-sdk-and-python-compatibility-map","title":"Virtualization SDK and Python Compatibility Map","text":"vSDK Version Python Version 4.1.0 3.8 4.0.5 3.8 4.0.2 3.8 3.1.0 2.7 3.0.0 2.7 2.1.0 2.7 2.0.0 2.7 1.0.0 2.7 0.4.0 2.7"},{"location":"References/Workflows/","title":"Workflows","text":""},{"location":"References/Workflows/#legend","title":"Legend","text":""},{"location":"References/Workflows/#environment-discovery-refresh","title":"Environment Discovery / Refresh","text":""},{"location":"References/Workflows/#linked-source-sync","title":"Linked Source Sync","text":""},{"location":"References/Workflows/#linked-source-enable","title":"Linked Source Enable","text":""},{"location":"References/Workflows/#linked-source-disable","title":"Linked Source Disable","text":""},{"location":"References/Workflows/#linked-source-delete","title":"Linked Source Delete","text":""},{"location":"References/Workflows/#virtual-source-provision","title":"Virtual Source Provision","text":""},{"location":"References/Workflows/#virtual-source-snapshot","title":"Virtual Source Snapshot","text":""},{"location":"References/Workflows/#virtual-source-create-empty-vdb","title":"Virtual Source Create Empty VDB","text":""},{"location":"References/Workflows/#virtual-source-refresh","title":"Virtual Source Refresh","text":""},{"location":"References/Workflows/#virtual-source-rollback","title":"Virtual Source Rollback","text":""},{"location":"References/Workflows/#virtual-source-delete","title":"Virtual Source Delete","text":""},{"location":"References/Workflows/#virtual-source-start","title":"Virtual Source Start","text":""},{"location":"References/Workflows/#virtual-source-stop","title":"Virtual Source Stop","text":""},{"location":"References/Workflows/#virtual-source-enable","title":"Virtual Source Enable","text":"<p>Note: pre- and post-start hooks are only run if <code>extendedStartStopHooks</code> is set to <code>true</code> in the plugin config.</p>"},{"location":"References/Workflows/#virtual-source-disable","title":"Virtual Source Disable","text":"<p>Note: pre- and post-stop hooks are only run if <code>extendedStartStopHooks</code> is set to <code>true</code> in the plugin config.</p>"},{"location":"References/Workflows/#upgrade","title":"Upgrade","text":""},{"location":"References/Dynamic_UI_Schema_Configuration/Collapsible_Section/","title":"Collapsible Section","text":"<p>Collapsible Section provides plugin developers capability to create properties that can be collapsed or expanded as per  user choice. <code>Collapsible Section</code> allows to reduce number of properties shown on the UI at a time to help better  understand the configuration.</p> <p>The <code>collapsible</code> and <code>expanded</code> accepts a boolean value that helps in collapsing all the properties of the <code>array</code>  and <code>object</code> type.</p>"},{"location":"References/Dynamic_UI_Schema_Configuration/Collapsible_Section/#schema-configuration","title":"Schema Configuration","text":""},{"location":"References/Dynamic_UI_Schema_Configuration/Collapsible_Section/#attributes","title":"Attributes","text":"Attribute Value Description collapsible boolean If <code>true</code>, the property will be allowed to collapse as per user choice. expanded boolean If <code>true</code>, the property will be expanded by default. The attribute is used when <code>collapsible</code> is set to <code>true</code>."},{"location":"References/Dynamic_UI_Schema_Configuration/Collapsible_Section/#where","title":"Where","text":"<ul> <li>As a Sub-schema of dxFormProperties, for <code>array</code> and <code>object</code> type properties.</li> </ul>"},{"location":"References/Dynamic_UI_Schema_Configuration/Collapsible_Section/#applicable-data-types","title":"Applicable Data Types","text":"<ul> <li>object</li> <li>array</li> </ul>"},{"location":"References/Dynamic_UI_Schema_Configuration/Collapsible_Section/#usage","title":"Usage","text":"Schema<pre><code>{\n\"&lt;Property_Name&gt;\": {\n\"type\": \"object\",\n\"dxFormProperties\": {\n\"collapsible\": &lt;boolean true or false&gt;,\n\"expanded\": &lt;boolean true or false&gt;\n}\n}\n}\n</code></pre>"},{"location":"References/Dynamic_UI_Schema_Configuration/Collapsible_Section/#examples","title":"Examples","text":"Examples Example 1Example 2 <p><code>userDetails</code> is an object property which is allowed to collapse and is collapsed by default. <code>userName</code> and <code>password</code> are part of the collapsed section.  <pre><code>{\n\"userDetails\": {\n\"type\": \"object\",\n\"dxFormProperties\": {\n\"collapsible\": true,\n\"expanded\": false\n},\n\"properties\": {\n\"userName\": {\n\"type\": \"string\"\n},\n\"password\": {\n\"type\": \"string\"\n}\n}\n}\n}\n</code></pre> </p> <p><code>addressDetails</code> is an array property which is allowed to collapse and is expanded by default. Each array item with <code>pinCode</code> and <code>number</code> is allowed to collapse and is collapsed by default. <pre><code>{\n\"addressDetails\": {\n\"type\": \"array\",\n\"dxFormProperties\": {\n\"collapsible\": true,\n\"expanded\": true\n},\n\"items\": {\n\"type\": \"object\",\n\"dxFormProperties\": {\n\"collapsible\": true,\n\"expanded\": false\n},\n\"properties\": {\n\"pinCode\": {\n\"type\": \"string\"\n},\n\"number\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n</code></pre> </p>"},{"location":"References/Dynamic_UI_Schema_Configuration/Hidden_Fields/","title":"Hidden Properties","text":"<p>Hidden Properties provides plugin developers capability to provide properties that will be shown to user once certain conditions or  checks are successful based on user inputs. <code>Hidden Properties</code> help plugin developers control the flow of user inputs by  showing only the required properties at first and show the remaining properties based on the user input afterward.</p> <p>The <code>hideExpression</code> accepts an expression that evaluates to a boolean value. The expression can access values from  other properties. Access values from other properties as below:</p> model.&lt;property_name&gt; <pre><code>{\n\"X\": \"\", \"Y\": \"\"\n}\n</code></pre> <ul> <li>Use the <code>model.&lt;property_name&gt;</code> when the properties are <code>string</code>, <code>boolean</code>, <code>number</code> or <code>integer</code>.</li> <li>To hide Y based on X, use <code>model.X</code> or <code>model?.X</code></li> </ul> field.parent.&lt;N&gt;.parent.model?.&lt;property_name&gt; <p>Use the <code>field.parent.&lt;N&gt;.parent.model?.&lt;property_name&gt;</code> when the properties are <code>object</code> or <code>array</code>.</p> Object SchemaArray Schema <pre><code>{\n\"X\": \"\", \"Y\": {\n\"Z\": \"\"\n}\n}\n</code></pre> <ul> <li>To hide Y (object itself), use <code>field.parent.model?.X</code>.</li> <li>To hide Z based on X, use <code>field.parent.parent.model?.X</code>.</li> </ul> <pre><code>{\n\"X\": \"\", \"Y\": [\n{\n\"Z\": \"\"\n}\n]\n}\n</code></pre> <ul> <li>To hide Y (array object) based on X, use <code>field.parent.model?.X</code></li> <li>To hide Z based on X, use <code>field.parent.parent.parent.model?.X</code></li> </ul> field.parent.&lt;N&gt;.parent.model?.&lt;root_names&gt;?.&lt;property_name&gt; <pre><code>{\n\"A\": {\n\"B\": \"\"\n}, \"X\": {\n\"Y\": \"\"\n}\n}        </code></pre> <ul> <li>Use the <code>field.parent.&lt;N&gt;.parent.model?.&lt;root_names&gt;?.&lt;property_name&gt;</code> when the properties have different root object.</li> <li>To hide Y based on B, use <code>field.parent.parent.model?.A?.B</code></li> </ul> <p>Info</p> <p><code>parent.&lt;N&gt;.parent</code> - Parent repeated N times as per JSON structure</p>"},{"location":"References/Dynamic_UI_Schema_Configuration/Hidden_Fields/#schema-configuration","title":"Schema Configuration","text":""},{"location":"References/Dynamic_UI_Schema_Configuration/Hidden_Fields/#attributes","title":"Attributes","text":"Attribute Value Description hideExpression boolean If the value evaluates to true, the property is not shown in the UI."},{"location":"References/Dynamic_UI_Schema_Configuration/Hidden_Fields/#where","title":"Where","text":"<ul> <li>As a Sub-schema of dxFormProperties, for all data types property.</li> </ul>"},{"location":"References/Dynamic_UI_Schema_Configuration/Hidden_Fields/#applicable-data-types","title":"Applicable Data Types","text":"<ul> <li>string</li> <li>integer</li> <li>number</li> <li>array</li> <li>object</li> <li>boolean</li> </ul>"},{"location":"References/Dynamic_UI_Schema_Configuration/Hidden_Fields/#usage","title":"Usage","text":"Schema<pre><code>{\n\"&lt;Property_Name&gt;\": {\n\"type\": \"string\",\n\"dxFormProperties\": {\n\"hideExpression\": \"&lt;expression that evaluates to a boolean value&gt;\"\n}\n}  }\n</code></pre> <p>Warning</p> <p>The expression works across a definition only. Plugin developers will not be able to use properties from multiple  definitions as defined in schemas. For example, a property from  linkedSourceDefinition can not be used  in snapshotDefinition.</p>"},{"location":"References/Dynamic_UI_Schema_Configuration/Hidden_Fields/#examples","title":"Examples","text":"Examples ExpressionsCommon Root ObjectDifferent Root Object Expression Description <code>!model.userName</code> Returns true if the userName property is EMPTY. <code>model.booleanFlag</code> Returns true or false based on the booleanFlag property <code>model.backupType === 'PRIMARY'</code> Returns true if the backupType property is PRIMARY. <code>model.backupType !== 'PRIMARY' &amp;&amp; !model.userName</code> Return true if backupType property is not PRIMARY and userName property is EMPTY. <p><code>password</code> is a string property which will be shown in the UI if <code>userName</code> is present and not empty. <pre><code>{\n\"userName\": {\n\"type\": \"string\"\n},\n\"password\": {\n\"type\": \"string\",\n\"dxFormProperties\": {\n\"hideExpression\": \"!model.userName\"\n}\n}\n}\n</code></pre> </p> <p><code>password</code> is a string property which will be shown in the UI if <code>userName</code> is present and not empty. <pre><code>{\n\"userDetails\": {\n\"type\": \"object\",\n\"properties\": {\n\"userName\": {\n\"type\": \"string\"\n}\n}\n},\n\"securityDetails\": {\n\"type\": \"object\",\n\"properties\": {\n\"password\": {\n\"type\": \"string\",\n\"dxFormProperties\": {\n\"hideExpression\": \"!field.parent.parent.model?.userDetails?.userName\"\n}\n}\n}\n}\n}\n</code></pre> </p>"},{"location":"References/Dynamic_UI_Schema_Configuration/Overview/","title":"Overview","text":"<p>Before Delphix Engine 14.0.0.0 release, virtualization SDK only supported basic UI configuration which made UI configuration  for plugin defined schema complex and cluttered. Plugin developers were not able to modify the behaviour of Delphix Engine UI  based on the plugin defined schema.</p> <p>From 14.0.0.0 onwards, plugin developers can modify the Delphix Engine UI based on the plugin defined schema. </p> <p><code>Dynamic UI Schema Configuration</code> creates Delphix Engine UI which helps user better understand the plugin configuration  and also helps plugin developers control the flow of the configuration.</p>"},{"location":"References/Dynamic_UI_Schema_Configuration/Overview/#schema-attribute","title":"Schema Attribute","text":"<p>Plugin developers need to add a single attribute dxFormProperties to any field they would like  to control the UI. Other attributes like <code>rows</code>, <code>hideExpression</code> can be provided to dxFormProperties  to create a specific type of Dynamic UI behaviour.</p> <p>Table below lists all the allowed attributes within dxFormProperties to create UI.</p> Attribute Description Collapsible Section Allows to collapse and expand <code>object</code> and <code>array</code> type properties. Hidden Fields Allows to hide properties based on conditions. Text Area Convert any string field to multi line text input property. Validation Messages Add custom validation messages to user inputs."},{"location":"References/Dynamic_UI_Schema_Configuration/Overview/#version-compatibility","title":"Version Compatibility","text":"Dynamic UI Schema Configuration Earliest Supported vSDK Version Latest Supported vSDK Version Earliest Supported DE Version Latest Supported DE Version Collapsible Section 4.0.2 Latest Release 14.0.0.0 Latest Release Hidden Fields 4.0.2 Latest Release 14.0.0.0 Latest Release Text Area 4.0.2 Latest Release 14.0.0.0 Latest Release Validation Messages 4.0.2 Latest Release 14.0.0.0 Latest Release"},{"location":"References/Dynamic_UI_Schema_Configuration/Text_Area/","title":"Text Area","text":"<p>Text Area Property provides plugin developers capability to create properties in Delphix engine UI which is used  for <code>multi line text</code> input. <code>Text Area</code> allows users to enter large amount of text, for example a shell script or comments.</p> <p>All <code>string</code> type properties can be converted to <code>Text Area</code> properties by providing <code>rows</code> configuration to adjust the height of the property. </p> <ul> <li>The number of visible lines or <code>rows</code> count does not limit the number of input lines.</li> <li>A user can input <code>n</code> number of lines but at a time UI will only show lines as provided in <code>rows</code> configuration.<ul> <li>A user can scroll to see all the lines.</li> </ul> </li> </ul>"},{"location":"References/Dynamic_UI_Schema_Configuration/Text_Area/#schema-configuration","title":"Schema Configuration","text":""},{"location":"References/Dynamic_UI_Schema_Configuration/Text_Area/#attributes","title":"Attributes","text":"Attribute Value Description rows number Specifies the height and number of visible lines for text area."},{"location":"References/Dynamic_UI_Schema_Configuration/Text_Area/#where","title":"Where","text":"<ul> <li>As a Sub-schema of dxFormProperties, for <code>string</code> type property.</li> </ul>"},{"location":"References/Dynamic_UI_Schema_Configuration/Text_Area/#applicable-data-types","title":"Applicable Data Types","text":"<ul> <li>string</li> </ul>"},{"location":"References/Dynamic_UI_Schema_Configuration/Text_Area/#usage","title":"Usage","text":"Schema<pre><code>{\n\"&lt;Property_Name&gt;\": {\n\"type\": \"string\",\n\"dxFormProperties\": {\n\"rows\": 5\n}\n}\n}\n</code></pre>"},{"location":"References/Dynamic_UI_Schema_Configuration/Text_Area/#examples","title":"Examples","text":"Examples Example 1Example 2 <p><code>userName</code> is a string property which will be shown in the UI as a Single line. <pre><code>{\n\"userName\": {\n\"type\": \"string\"\n}\n}\n</code></pre> </p> <p><code>textAreaField</code> is a string property which will be shown in the UI as a Text Area with 20 visible lines. <pre><code>{\n\"textAreaField\": {\n\"type\": \"string\",\n\"dxFormProperties\": {\n\"rows\": 20\n}\n}\n}\n</code></pre> </p>"},{"location":"References/Dynamic_UI_Schema_Configuration/Validation_Messages/","title":"Validation Messages","text":"<p>Validation messages provides plugin developers capability to provide custom validation error messages for user inputs in Delphix Engine UI. <code>Validation messages</code> helps user better understand the input requirements and provide the input that matches the plugin developers requirements.</p> <p>Data types which provide validations for the user input, for example</p> <ul> <li><code>pattern</code>, <code>minLength</code> for <code>string</code></li> <li><code>minItems</code>, <code>maxItems</code> for <code>array</code> </li> </ul> <p>can have <code>Custom Validation Messages</code>.</p> <p>For each validation check within a property, plugin developers can provide a validation message. The validation message will be shown for the first failed validation check.</p>"},{"location":"References/Dynamic_UI_Schema_Configuration/Validation_Messages/#schema-configuration","title":"Schema Configuration","text":""},{"location":"References/Dynamic_UI_Schema_Configuration/Validation_Messages/#attributes","title":"Attributes","text":"Attribute Value Description validationMessages Object Key-value to define validation messages for various input validation check keywords."},{"location":"References/Dynamic_UI_Schema_Configuration/Validation_Messages/#supported-keys","title":"Supported Keys","text":"Keys Applicable Data Type minLength, pattern string maxItems, minItems, uniqueItems array multipleOf integer, number"},{"location":"References/Dynamic_UI_Schema_Configuration/Validation_Messages/#where","title":"Where","text":"<ul> <li>As a Sub-schema of dxFormProperties.</li> </ul>"},{"location":"References/Dynamic_UI_Schema_Configuration/Validation_Messages/#applicable-data-types","title":"Applicable Data Types","text":"<ul> <li>string</li> <li>array</li> <li>integer</li> <li>number</li> </ul>"},{"location":"References/Dynamic_UI_Schema_Configuration/Validation_Messages/#usage","title":"Usage","text":"Schema<pre><code>{\n\"userName\": {\n\"type\": \"string\",\n\"minLength\": 8,\n\"pattern\": \"postgre.*\",\n\"dxFormProperties\": {\n\"validationMessages\": {\n\"minLength\": \"&lt;Your Custom Validation Message which represents \\\"minLength\\\" validation check.&gt;\",\n\"pattern\": \"&lt;Your Custom Validation Message which represents \\\"pattern\\\" validation check.&gt;\"\n}\n}\n}\n}\n</code></pre>"},{"location":"References/Dynamic_UI_Schema_Configuration/Validation_Messages/#examples","title":"Examples","text":"Examples Example 1Example 2Example 3 <p>No error message will be shown in case of validation check failure. <pre><code>{\n\"userName\": {\n\"type\": \"string\",\n\"minLength\": 8,\n\"pattern\": \"postgre.*\"\n}\n}\n</code></pre> </p> <p>Only <code>minLength</code> validation error message will be shown in case of length constraint failure. <pre><code>{\n\"userName\": {\n\"type\": \"string\",\n\"minLength\": 8,\n\"pattern\": \"postgre.*\",\n\"dxFormProperties\": {\n\"validationMessages\": {\n\"minLength\": \"The minimum length for \\\"userName\\\" should be 8.\"\n}\n}\n}\n}\n</code></pre> </p> <p>Both <code>minLength</code> and <code>pattern</code> validation error message will be shown based on input validation check failure. <pre><code>{\n\"userName\": {\n\"type\": \"string\",\n\"minLength\": 8,\n\"pattern\": \"postgre.*\",\n\"dxFormProperties\": {\n\"validationMessages\": {\n\"minLength\": \"The minimum length for \\\"userName\\\" should be \\\"8\\\".\",\n\"pattern\": \"The \\\"userName\\\" should start with \\\"postgre\\\".\"\n}\n}\n}\n}\n</code></pre> </p>"},{"location":"Release_Notes/0.4.0/0.4.0/","title":"Release - Early Preview 2 (v0.4.0)","text":"<p>To install or upgrade the SDK, refer to instructions here.</p>"},{"location":"Release_Notes/0.4.0/0.4.0/#new-improved","title":"New &amp; Improved","text":"<ul> <li>Added a new CLI command download-logs to enable downloading plugin generated logs from the Delphix Engine.</li> <li> <p>Added an optional argument named <code>check</code> to the following platform library functions:</p> <ul> <li>run_bash</li> <li>run_powershell</li> </ul> <p>With <code>check=true</code>, the platform library function checks the <code>exit_code</code> and raises an exception if it is non-zero.</p> </li> <li> <p>Modified init to auto-generate default implementations for all required plugin operations.</p> </li> <li>Improved build validation for:<ul> <li>Required plugin operations.</li> <li>Incorrect plugin operation argument names.</li> <li>Plugin Config <code>entryPoint</code>: The <code>entryPoint</code> is now imported during the build as part of the validation.</li> <li>Schemas: Validated to conform to the JSON Schema Draft-07 Specification.</li> </ul> </li> <li> <p>Improved runtime validation and error messages for:</p> <ul> <li>Objects returned from plugin operations.</li> <li>Platform Classes during instantiation.</li> <li>Platform Library function arguments.</li> </ul> </li> <li> <p>Added support for Docker based plugins by specifying <code>rootSquashEnabled: false</code> in the plugin config.</p> </li> <li>Added Job and thread information to plugin generated log messages to increase diagnosability and observability.</li> </ul>"},{"location":"Release_Notes/0.4.0/0.4.0/#breaking-changes","title":"Breaking Changes","text":"<ul> <li> <p>A new argument <code>snapshot_parameters</code> was added to the following staged plugin operations:</p> <ul> <li>Staged Linked Source Pre-Snapshot</li> <li>Staged Linked Source Post-Snapshot</li> </ul> <p>This argument will allow the end user to indicate to the plugin whether or not to initiate a full ingestion for a dSource. More details about the new argument are here.</p> <p>Detailed steps to detect and make changes.</p> </li> <li> <p>Properties of the StagedSource class were modified:</p> <ul> <li><code>connection</code> was renamed to <code>source_connection</code>.</li> <li><code>staged_connection</code> was added to allow connecting to the staging environment.</li> </ul> <p>This will enable plugins to connect to both the source and staging environments. More details about these properties are here.</p> <p>Detailed steps to detect and make changes.</p> </li> </ul>"},{"location":"Release_Notes/0.4.0/0.4.0/#fixed","title":"Fixed","text":"<ul> <li>Allow access to nested package resources via <code>pkgutil.get_data</code>.</li> <li>Fixed Out of Memory exceptions.</li> <li> <p>Fixed missing or incorrectly populated properties for the following classes:</p> Class Properties VirtualSource <code>mounts</code> RemoteUser <code>name</code> RemoteEnvironment <code>name</code> RemoteHost <code>name</code> <code>binary_path</code> </li> <li> <p>Updated Job warnings during discovery to display the underlying Python exceptions if one is raised by the plugin operations.</p> </li> <li>Recreate the plugin's log directory if a plugin is deleted and re-uploaded to the Delphix Engine.</li> <li>Mark incorrectly provisioned VDBs as unusable and prevent subsequent Delphix Engine operations on such VDBs.</li> <li>Better error messages when incorrect environment types are used for Platform Libraries.</li> <li>Better error messages when a plugin's schema is updated and the plugin is re-uploaded to the Delphix Engine, with clear instructions on how to proceed.</li> <li>Fixed build failures on Windows.</li> </ul>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/","title":"Breaking Changes - Early Preview 2 (v.0.4.0)","text":""},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#new-argument-snapshot_parameters","title":"New Argument <code>snapshot_parameters</code>","text":"<p>A new argument <code>snapshot_parameters</code> was added to the following staged plugin operations:</p> <ul> <li>Staged Linked Source Pre-Snapshot</li> <li>Staged Linked Source Post-Snapshot</li> </ul> <p>This argument will allow the end user to indicate to the plugin whether or not to initiate a full ingestion for a dSource. More details about the new argument are here.</p>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#what-is-affected","title":"What is affected","text":"<p>This argument applies only to staged plugins. The plugin's source code will have to be updated for the following staged plugin operations:</p> <ul> <li>Staged Linked Source Pre-Snapshot: This plugin operation is optional and will need to be updated if the plugin implements it.</li> <li>Staged Linked Source Post-Snapshot: This plugin operation is required and will need to be updated.</li> </ul>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#how-does-it-fail","title":"How does it fail","text":"<p>build will fail with the following error message if the new argument is not added to the affected staged plugin operations:</p> <pre><code>$ dvp build\nError: Number of arguments do not match in method staged_post_snapshot. Expected: ['staged_source', 'repository', 'source_config', 'snapshot_parameters'], Found: ['repository', 'source_config', 'staged_source'].\nError: Number of arguments do not match in method staged_pre_snapshot. Expected: ['staged_source', 'repository', 'source_config', 'snapshot_parameters'], Found: ['repository', 'source_config', 'staged_source'].\n\n0 Warning(s). 2 Error(s).\n\nBUILD FAILED.\n</code></pre>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#how-to-fix-it","title":"How to fix it","text":"<p>Update the affected staged plugin operations to include the new argument <code>snapshot_parameters</code>.</p> <ul> <li>Previous releases</li> </ul> <pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.linked.pre_snapshot()\ndef linked_pre_snapshot_prior(staged_source, repository, source_config):\n# This was the function signature prior to 0.4.0\npass\n@plugin.linked.post_snapshot()\ndef linked_post_snapshot_prior(staged_source, repository, source_config):\n# This was the function signature prior to 0.4.0\nreturn SnapshotDefinition()\n</code></pre> <ul> <li>0.4.0</li> </ul> <pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.linked.pre_snapshot()\ndef linked_pre_snapshot_040(staged_source, repository, source_config, snapshot_parameters):\n# Updated function signature in 0.4.0\npass\n@plugin.linked.post_snapshot()\ndef linked_post_snapshot_040(staged_source, repository, source_config, snapshot_parameters):\n# Updated function signature in 0.4.0\nreturn SnapshotDefinition()\n</code></pre>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#stagedsource-properties-modified","title":"StagedSource Properties Modified","text":"<p>Properties of the StagedSource class were modified:</p> <ul> <li><code>connection</code> was renamed to <code>source_connection</code>.</li> <li><code>staged_connection</code> was added to allow connecting to the staging environment.</li> </ul> <p>This will enable plugins to connect to both the source and staging environments. More details about these properties are here.</p>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#what-is-affected_1","title":"What is affected","text":"<p>This change applies only to staged plugins.</p>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#required-changes","title":"Required Changes","text":"<p>The plugin's source code will have to be updated for any staged plugin operations that accesses the <code>connection</code> propery of a StagedSource object.</p>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#optional-changes","title":"Optional Changes","text":"<p>The plugin can choose to use the new <code>staged_connection</code> property to connect to the staging environment of a dSource.</p>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#how-does-it-fail_1","title":"How does it fail","text":"<p>Any Delphix Engine operation that calls a plugin operation that has not been fixed would fail with the following stack trace as part of the output of the user exception:</p> <pre><code>AttributeError: 'StagedSource' object has no attribute 'connection'\n</code></pre>"},{"location":"Release_Notes/0.4.0/0.4.0_Breaking_Changes/#how-to-fix-it_1","title":"How to fix it","text":"<p>Update any staged plugin operations that access the renamed property.</p> <ul> <li>Previous releases</li> </ul> <pre><code>from dlpx.virtualization.platform import Plugin\nfrom dlpx.virtualization import libs\nplugin = Plugin()\n@plugin.linked.pre_snapshot()\ndef linked_pre_snapshot_prior(staged_source, repository, source_config):\n# Property name was 'connection' was the name of the property for staged_source prior to 0.4.0\nlibs.run_bash(staged_source.connection, 'date')\n</code></pre> <ul> <li>0.4.0</li> </ul> <pre><code>from dlpx.virtualization.platform import Plugin\nfrom dlpx.virtualization import libs\nplugin = Plugin()\n@plugin.linked.pre_snapshot()\ndef linked_pre_snapshot_prior(staged_source, repository, source_config):\n# Property name was updated to 'source_connection' in 0.4.0\nlibs.run_bash(staged_source.source_connection, 'date')\n</code></pre>"},{"location":"Release_Notes/1.0.0/1.0.0/","title":"Release - v1.0.0","text":"<p>To install or upgrade the SDK, refer to instructions here.</p>"},{"location":"Release_Notes/1.0.0/1.0.0/#new-improved","title":"New &amp; Improved","text":"<ul> <li>Added support for a CLI configuration file to specify default options for <code>dvp</code> commands. More details here.</li> <li> <p>Improved speed and scalability of plugin operations:</p> <ul> <li>Reduced startup time for plugin operations from seconds to milliseconds.</li> <li>Improved memory utilization on the Delphix Engine to enable a large number of plugin operations to execute in parallel.</li> </ul> </li> <li> <p>Added the ability for plugins to raise user visible messages with a custom message, action and output related to a failure during a plugin operation. Refer to the User Visible Errors section for more details.</p> </li> <li>Improved validation for type and range checks for autogenerated classes.</li> <li>Improved security for the plugin's runtime when executed on the Delphix Engine.</li> <li>Removed the Delphix Engine feature flag <code>PYTHON_TOOLKITS</code> as the Delphix Engine supports plugins built on the SDK by default. The Getting Started section has been updated has well.</li> </ul>"},{"location":"Release_Notes/1.0.0/1.0.0/#breaking-changes","title":"Breaking Changes","text":"<ul> <li> <p>The following fields in the Plugin Config were renamed:</p> Previous Updated <code>name</code> <code>plugin_id</code> <code>prettyName</code> <code>name</code> <p>Additionally, the <code>plugin_id</code> is now required to be a UUID with a format: <code>[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}</code>.</p> <p>Detailed steps to detect and make changes.</p> </li> </ul>"},{"location":"Release_Notes/1.0.0/1.0.0/#fixed","title":"Fixed","text":"<ul> <li>Updated remote host operations to execute as the RemoteUser specfied instead of the primary environment user.</li> <li>Fixed an incorrect user exception when the required plugin operation <code>linked.post_snapshot</code> was missing.</li> <li>Updated run_expect to return an <code>exit_code</code>, <code>stdout</code>, <code>stderr</code> like other platform library functions.</li> <li>Fixed run_powershell to not automatically redirect <code>stderr</code> to <code>stdout</code>.</li> <li>Ensured that all exceptions raised by the Staged Linked Source Worker plugin operation are converted to faults for the user.</li> <li>Enabled the MountSpecification to be constructed with <code>mounts</code> that refer to different environments.</li> <li>Sanitized the Python stack traces from exceptions during plugin execution and removed paths that reference where the plugin was built.</li> <li>Removed a spurious build warning for <code>DIRECT</code> plugins that incorrectly suggested implementing  the Staged Linked Source Mount Specification plugin operation.</li> <li>Removed a spurious message <code>global name 'exit' is not defined</code> which was displayed when a plugin library function failed.</li> <li>Updated <code>manualDiscovery</code> to be optional in the Plugin Config. The default value will be <code>True</code>.</li> </ul>"},{"location":"Release_Notes/1.0.0/1.0.0_Breaking_Changes/","title":"Breaking Changes - GA (v.1.0.0)","text":""},{"location":"Release_Notes/1.0.0/1.0.0_Breaking_Changes/#plugin-config-fields-renamed","title":"Plugin Config Fields Renamed","text":"<p>The following fields in the Plugin Config were renamed:</p> Previous Updated <code>name</code> <code>plugin_id</code> <code>prettyName</code> <code>name</code> <p>Additionally, the <code>plugin_id</code> is now required to be a UUID with format: <code>[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}</code>. This will allow the plugins to be uniquely identified across plugin developers.</p>"},{"location":"Release_Notes/1.0.0/1.0.0_Breaking_Changes/#what-is-affected","title":"What is affected","text":"<p>All plugins built with v0.3.0 or v0.4.0 will be affected. The Plugin Config fields will have to be updated.</p>"},{"location":"Release_Notes/1.0.0/1.0.0_Breaking_Changes/#how-does-it-fail","title":"How does it fail","text":"<p>dvp build will fail with the following error message if the Plugin Config fields are not updated:</p> <pre><code>$ dvp build\nError: Additional properties are not allowed ('prettyName' was unexpected) on []\n{\n\"pluginType\": \"DIRECT\", \"name\": \"My Plugin\", \"language\": \"PYTHON27\", \"manualDiscovery\": true, \"hostTypes\": [\n\"UNIX\"\n], \"version\": \"0.1.0\", \"entryPoint\": \"plugin_runner:plugin\", \"srcDir\": \"src\", \"prettyName\": \"My Plugin\", \"schemaFile\": \"schema.json\"\n}\nError: 'id' is a required property on []\n{\n\"pluginType\": \"DIRECT\", \"name\": \"My Plugin\", \"language\": \"PYTHON27\", \"manualDiscovery\": true, \"hostTypes\": [\n\"UNIX\"\n], \"version\": \"0.1.0\", \"entryPoint\": \"plugin_runner:plugin\", \"srcDir\": \"src\", \"prettyName\": \"My Plugin\", \"schemaFile\": \"schema.json\"\n}\nValidation failed on plugin_config.yml. 0 Warning(s). 2 Error(s) BUILD FAILED.\n</code></pre>"},{"location":"Release_Notes/1.0.0/1.0.0_Breaking_Changes/#how-to-fix-it","title":"How to fix it","text":"<p>Rename the Plugin Config fields. Make sure that the <code>id</code> is a UUID of the format <code>[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}</code>. A UUID can be generated manually using an online generator or via Python:</p> <pre><code>$ python\n&gt;&gt;&gt; import uuid\n&gt;&gt;&gt; uuid.uuid4()\nUUID('4174f1b8-45df-43cc-8e4c-21d309c17861')\n</code></pre> <ul> <li>Previous releases</li> </ul> <pre><code>name: my_plugin\nprettyName: My Plugin\nversion: 0.1.0\nlanguage: PYTHON27\nhostTypes:\n- UNIX\npluginType: DIRECT\nmanualDiscovery: true\nentryPoint: plugin_runner:plugin\nsrcDir: src\nschemaFile: schema.json\n</code></pre> <ul> <li>1.0.0</li> </ul> <pre><code>id: 4174f1b8-45df-43cc-8e4c-21d309c17861\nname: My Plugin\nversion: 0.1.0\nlanguage: PYTHON27\nhostTypes:\n- UNIX\npluginType: DIRECT\nmanualDiscovery: true\nentryPoint: plugin_runner:plugin\nsrcDir: src\nschemaFile: schema.json\n</code></pre>"},{"location":"Release_Notes/2.0.0/2.0.0/","title":"Release - v2.0.0","text":"<p>To install or upgrade the SDK, refer to instructions here.</p>"},{"location":"Release_Notes/2.0.0/2.0.0/#new-improved","title":"New &amp; Improved","text":"<ul> <li> <p>Added the ability for plugins to upgrade across plugin versions with schema changes. Some highlights:</p> <ul> <li>Schema updates using data migrations.</li> <li>Flexiblity for plugins to pick any release strategy.</li> <li>Plugin upgrades supported across multiple plugin versions. </li> <li>Zero dSource and VDB downtime during plugin upgrade.</li> </ul> <p>More details about Plugin Upgrade can be found here.</p> </li> <li> <p>Added a new field <code>externalVersion</code> to the Plugin Config that allows plugins to display an end-user friendly version. More details here.</p> </li> <li>Added a new option to init to select a host type for the plugin (<code>Unix</code> or <code>Windows</code>) to make it easier to get started with plugins that support either host platform.</li> <li>Added a new option to upload to block and wait for the upload job to finish on the Delphix Engine before the command returns.</li> </ul>"},{"location":"Release_Notes/2.0.0/2.0.0/#breaking-changes","title":"Breaking Changes","text":"<ul> <li> <p>The following field in the Plugin Config was renamed:</p> Previous Updated <code>version</code> <code>buidNumber</code> <p>Additionally <code>buildNumber</code> has to conform to the format described here.</p> <p>Detailed steps to detect and make changes.</p> </li> </ul>"},{"location":"Release_Notes/2.0.0/2.0.0_Breaking_Changes/","title":"Breaking Changes - GA (v.2.0.0)","text":""},{"location":"Release_Notes/2.0.0/2.0.0_Breaking_Changes/#plugin-config-field-renamed","title":"Plugin Config Field Renamed","text":"<p>The following field in the Plugin Config were replaced:</p> Previous Updated <code>version</code> <code>buildNumber</code> <p>Additionally, the <code>buildNumber</code> must be a string that conforms to the following rules:</p> <ul> <li>The string must be composed of a sequence of non-negative integers, not all zero, separated by periods.</li> <li>Trailing zeros are ignored. So, \"1.0.0\" is treated the same as \"1\".</li> <li>Build numbers are sortable numerically, with earlier numbers having more significance than later numbers. So, \"2.0\" comes after \"1.99999\", and \"1.10\" comes after \"1.2\".</li> <li>The Delphix Engine will never allow installation of plugin with a build number that is ordered before the the already-installed build number.</li> </ul> <p>More details about the format are here.</p>"},{"location":"Release_Notes/2.0.0/2.0.0_Breaking_Changes/#what-is-affected","title":"What is affected","text":"<p>All plugins built with v1.0.0 or below will be affected. The Plugin Config field <code>version</code> will have to be updated to <code>buildNumber</code>.</p>"},{"location":"Release_Notes/2.0.0/2.0.0_Breaking_Changes/#how-does-it-fail","title":"How does it fail","text":"<p>dvp build will fail with the following error message if the Plugin Config <code>version</code> field is not updated to <code>buildNumber</code>:</p> <pre><code>$ dvp build\nError: Additional properties are not allowed ('version' was unexpected) on ['additionalProperties']\nError: 'buildNumber' is a required property on ['required']\nValidation failed on /private/var/tmp/fp/plugin_config.yml. 0 Warning(s). 2 Error(s) BUILD FAILED.\n</code></pre>"},{"location":"Release_Notes/2.0.0/2.0.0_Breaking_Changes/#how-to-fix-it","title":"How to fix it","text":"<p>Rename the Plugin Config <code>version</code> field to <code>buildNumber</code>. Make sure that the <code>buildNumber</code> conforms to the format described here.</p> <ul> <li>Previous releases</li> </ul> <pre><code>id: 4174f1b8-45df-43cc-8e4c-21d309c17861\nname: My Plugin\nversion: 1.0.0\nlanguage: PYTHON27\nhostTypes:\n- UNIX\npluginType: DIRECT\nmanualDiscovery: true\nentryPoint: plugin_runner:plugin\nsrcDir: src\nschemaFile: schema.json\n</code></pre> <ul> <li>2.0.0</li> </ul> <pre><code>id: 4174f1b8-45df-43cc-8e4c-21d309c17861\nname: My Plugin\nbuildNumber: 1.0.0\nlanguage: PYTHON27\nhostTypes:\n- UNIX\npluginType: DIRECT\nmanualDiscovery: true\nentryPoint: plugin_runner:plugin\nsrcDir: src\nschemaFile: schema.json\n</code></pre>"},{"location":"Release_Notes/2.1.0/2.1.0/","title":"Release - v2.1.0","text":"<p>To install or upgrade the SDK, refer to instructions here.</p>"},{"location":"Release_Notes/2.1.0/2.1.0/#new-improved","title":"New &amp; Improved","text":"<ul> <li> <p>Added the ability to migrate existing Lua toolkits to SDK plugins.</p> <ul> <li>Convert any existing Lua upgrade scripts to Python migrations by using new Lua upgrade decorators.</li> <li>Added new optional fields <code>luaName</code> and <code>minimumLuaVersion</code> to the Plugin Config. These properties allow a plugin to specify which Lua toolkit(s) the plugin can migrate.</li> </ul> <p>More details about Lua toolkit migration can be found here.</p> </li> </ul>"},{"location":"Release_Notes/2.1.0/2.1.0/#breaking-changes","title":"Breaking Changes","text":"<p>No breaking changes in this release!</p>"},{"location":"Release_Notes/3.0.0/3.0.0/","title":"Release - v3.0.0","text":"<p>To install or upgrade the SDK, refer to instructions here.</p>"},{"location":"Release_Notes/3.0.0/3.0.0/#new-improved","title":"New &amp; Improved","text":"<ul> <li> <p>Added the ability to define snapshot parameters in a Snapshot Parameters Definition.</p> <ul> <li>Provide end-users with configurable options prior to taking a snapshot.</li> <li>The options selected are provided as input to pre/post-snapshot functions.</li> </ul> </li> <li> <p>Added support to initialize an empty VDB.</p> <ul> <li>Create an empty virtual dataset within Delphix, instead of creating it externally and ingesting it.</li> <li>Utilize this functionality by implementing the initialize operation.</li> </ul> </li> <li> <p>Added a <code>scratch_path</code> property on the RemoteHost object which can be used as:</p> <ul> <li>A location to store small amounts of persistent data.</li> <li>A location to mount VDB data.</li> </ul> </li> </ul> <p>More details about <code>scratch_path</code> can be found here</p>"},{"location":"Release_Notes/3.0.0/3.0.0/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>Added a new required schema Snapshot Parameters Definition.</li> </ul> <p>For more information and detailed steps to detect and make changes.</p> <ul> <li>Added a new parameter to the Direct Linked Source Pre-Snapshot and Direct Linked Source Post-Snapshot plugin operations.</li> </ul> <p>For more information and detailed steps to detect and make changes.</p> <ul> <li>Renamed a parameter in the Staged Linked Source Pre-Snapshot and Staged Linked Source Post-Snapshot plugin operations.</li> </ul> <p>For more information and detailed steps to detect and make changes.</p>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/","title":"Breaking Changes - v.3.0.0","text":""},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#new-required-schema","title":"New required schema","text":"<p>Snapshot Parameters Definition allows plugin authors to define snapshot parameters which can be displayed to an end-user whenever a linked source snapshot is taken.</p>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#what-is-affected","title":"What is affected","text":"<p>All plugins built with v2.0.0 or below will be affected. The Schema must contain a <code>snapshotParametersDefinition</code>.</p>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#how-does-it-fail","title":"How does it fail","text":"<p>dvp build will fail with the following error message if the SnapshotParametersDefinition Schema is not added to the schema file:</p> <pre><code>$ dvp build\nError: 'snapshotParametersDefinition' is a required property on ['required']\nValidation failed on /private/var/tmp/fp/schemas/schema.json.\n0 Warning(s). 1 Error(s)\nBUILD FAILED.\n</code></pre>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#how-to-fix-it","title":"How to fix it","text":"<p>Add a SnapshotParametersDefinition Schema to the <code>schemaFile</code> defined in the Plugin Config.</p> <p>Example: <pre><code>\"snapshotParametersDefinition\": {\n\"additionalProperties\": false,\n\"properties\": {\n\"resync\": {\n\"type\": \"boolean\"\n}\n},\n\"type\": \"object\"\n}\n</code></pre></p>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#new-parameter-in-direct-prepost-snapshot-functions","title":"New Parameter in Direct Pre/Post-Snapshot Functions","text":"<p><code>optional_snapshot_parameters</code> has been added as a parameter in Direct Linked Source Pre-Snapshot and Direct Linked Source Post-Snapshot.</p>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#what-is-affected_1","title":"What is affected","text":"<p>All direct plugins built with v2.1.0 or below will be affected.</p>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#how-does-it-fail_1","title":"How does it fail","text":"<p>dvp build will fail with the following error message if the <code>optional_snapshot_parameters</code> is not added:</p> <pre><code>$ dvp build\nError: Named argument mismatch in method linked_post_snapshot. Expected: ['staged_source', 'repository', 'source_config', 'optional_snapshot_parameters'], Found: ['staged_source', 'repository', 'source_config'].\n\n0 Warning(s). 1 Error(s).\n\nBUILD FAILED.\n</code></pre>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#how-to-fix-it_1","title":"How to fix it","text":"<p>Add <code>optional_snapshot_parameters</code> as a parameter in Direct Linked Source Pre-Snapshot and Direct Linked Source Post-Snapshot.</p> <ul> <li>Previous releases</li> </ul> <pre><code> @plugin.linked.post_snapshot()\ndef linked_post_snapshot(direct_source, repository, source_config):\nreturn SnapshotDefinition()\n</code></pre> <ul> <li>3.0.0</li> </ul> <pre><code> @plugin.linked.post_snapshot()\ndef linked_post_snapshot(direct_source, repository, source_config, optional_snapshot_parameters):\nreturn SnapshotDefinition()\n</code></pre>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#parameter-renamed-in-staged-prepost-snapshot-functions","title":"Parameter Renamed in Staged Pre/Post-Snapshot Functions","text":"<p>The following parameter was renamed in the Staged Linked Source Pre-Snapshot and Staged Linked Source Post-Snapshot functions:</p> Previous Updated <code>snapshot_parameters</code> <code>optional_snapshot_parameters</code>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#what-is-affected_2","title":"What is affected","text":"<p>All staged plugins built with v2.1.0 or below will be affected.</p>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#how-does-it-fail_2","title":"How does it fail","text":"<p>dvp build will fail with the following error message if the parameter is not renamed from <code>snapshot_parameters</code> to <code>optional_snapshot_parameters</code>:</p> <pre><code>$ dvp build\nError: Named argument mismatch in method linked_post_snapshot. Expected: ['staged_source', 'repository', 'source_config', 'optional_snapshot_parameters'], Found: ['staged_source', 'repository', 'source_config', 'snapshot_parameters'].\n\n0 Warning(s). 1 Error(s).\n\nBUILD FAILED.\n</code></pre>"},{"location":"Release_Notes/3.0.0/3.0.0_Breaking_Changes/#how-to-fix-it_2","title":"How to fix it","text":"<p>Rename <code>snapshot_parameters</code> to <code>optional_snapshot_parameters</code> in Staged Linked Source Pre-Snapshot and Staged Linked Source Post-Snapshot.</p> <ul> <li>Previous releases</li> </ul> <pre><code> @plugin.linked.post_snapshot()\ndef linked_post_snapshot(staged_source, repository, source_config, snapshot_parameters):\nreturn SnapshotDefinition()\n</code></pre> <ul> <li>3.0.0</li> </ul> <pre><code> @plugin.linked.post_snapshot()\ndef linked_post_snapshot(staged_source, repository, source_config, optional_snapshot_parameters):\nreturn SnapshotDefinition()\n</code></pre>"},{"location":"Release_Notes/3.1.0/3.1.0/","title":"Release - v3.1.0","text":"<p>To install or upgrade the SDK, refer to instructions here.</p>"},{"location":"Release_Notes/3.1.0/3.1.0/#new-improved","title":"New &amp; Improved","text":"<ul> <li>Added the ability for plugins to use password vaults to manage credentials.</li> </ul>"},{"location":"Release_Notes/3.1.0/3.1.0/#breaking-changes","title":"Breaking Changes","text":"<p>No breaking changes in this release!</p>"},{"location":"Release_Notes/4.0.2/4.0.2/","title":"Release - v4.0.2","text":"<p>To install or upgrade the SDK, refer to instructions here.</p>"},{"location":"Release_Notes/4.0.2/4.0.2/#new-improved","title":"New &amp; Improved","text":"<ul> <li>Added support for plugins written in Python 3.8.</li> </ul>"},{"location":"Release_Notes/4.0.2/4.0.2/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>The CLI now requires Python 3.8 for installation and usage.</li> </ul>"},{"location":"Release_Notes/4.0.2/4.0.2_Breaking_Changes/","title":"Breaking Changes - v.4.0.2","text":""},{"location":"Release_Notes/4.0.2/4.0.2_Breaking_Changes/#new-language-requirement","title":"New Language Requirement","text":"<p>The vSDK now requires Python 3.8.</p>"},{"location":"Release_Notes/4.0.5/4.0.5/","title":"Release - v4.0.5","text":"<p>To install or upgrade the SDK, refer to instructions here.</p>"},{"location":"Release_Notes/4.0.5/4.0.5/#new-improved","title":"New &amp; Improved","text":"<ul> <li>Added Direct Source Size, Staged Source Size and Virtual Source Size decorators. </li> <li>Updated Delphix logo in developer.delphix.com.</li> <li>Internet connectivity requirements added to getting started page.</li> <li>hash() default implementation added for auto generated classes.</li> <li>Support added for symlinks folder within src folder.</li> <li>Handled empty system password during Lua to Platform upgrade.</li> </ul>"},{"location":"Release_Notes/4.0.5/4.0.5/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>No breaking changes in this release!</li> </ul>"},{"location":"Release_Notes/4.1.0/4.1.0/","title":"Release - v4.1.0","text":"<p>To install or upgrade the SDK, refer to instructions here.</p>"},{"location":"Release_Notes/4.1.0/4.1.0/#new-improved","title":"New &amp; Improved","text":"<ul> <li> <p>Added a <code>mounts</code> property on the StagedSource object which can be used as:</p> <ul> <li>To set multiple mountSpecification generated from linked_mount_specification.</li> <li>To access multiple mounts present in the StagedSource.</li> </ul> </li> <li> <p>Updated dependencies to latest versions in the <code>dvp</code> packages. </p> <ul> <li>For Flake8 6.x versions, users can face some issues related to validations and linting. Visit Flake8 release history page for changes in 6.0.0 version.</li> </ul> </li> </ul>"},{"location":"Release_Notes/4.1.0/4.1.0/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>No breaking changes in this release!</li> </ul>"},{"location":"Versioning_And_Upgrade/Backports_And_Hotfixes/","title":"Backports and Hotfixes","text":"<p>If your plugin uses an \"enterprise-style\" release strategy, then you'll probably want to occasionally provide new \"minor\" or \"patch\" versions that build atop older versions.</p> <p>Code changes that are applied atop old releases are usually called \"backports\". Sometimes, they are also called \"hotfixes\", if the change is specifically created for a single user.</p> <p>These releases present a problem: although they are built atop an older code branch, they are still newer than some releases from a newer code branch. Below, we'll walk through how we prevent users from \"upgrading\" to a new-branch release that would be incompatible with an installed old-branch release.</p>"},{"location":"Versioning_And_Upgrade/Backports_And_Hotfixes/#motivating-example","title":"Motivating Example","text":"<p>Let's take a look at an example of a possible timeline of releases.</p> <p>February: The initial version of a plugin is released, with build number \"1.0\". This is a simple plugin that uses a simple strategy for syncing dSources.</p> <p>April: A new version is released, with build number \"1.1\". This adds some bugfixes and adds some small optimizations to improve the performance of syncing.</p> <p>August: A new version is released, with build number \"2.0\". This uses a completely new syncing strategy that is far more sophisticated and efficient.</p> <p>Let's assume that not all users will want to upgrade to the 2.0 release immediately. So, even months later, you expect to have a significant number of users still on version 1.0 or 1.1.</p> <p>Later, in October, a bug is found which impacts all releases. This bug is important enough that you want to fix it for all of your end users (not just the ones using 2.0).</p> <p>Here are the behaviors we need:</p> <ul> <li>Our 2.0 end users should be able to get the new bugfix without giving up any of the major new features that were part of 2.0.</li> <li>Our 1.0 and 1.1 end users should be able to get the new bugfix without also needing to accept all the major new features that were part of 2.0.</li> <li>Once an end user has received the bugfix, it should be impossible to lose the bugfix in an upgrade.</li> </ul>"},{"location":"Versioning_And_Upgrade/Backports_And_Hotfixes/#strategy","title":"Strategy","text":"<p>You can include a data migration along with your bugfix. If your bugfix involves a schema change, you will have to do this anyways. If not, you can still include a data migration that simply does nothing. If a user with the bugfix attempts to \"upgrade\" to 2.0, the Delphix Engine will prevent it, because the 2.0 releases does not include this migration.</p> <p>You would typically follow these steps:</p> <ul> <li>Fix the bug by applying a code change atop the 2.0 code.</li> <li>Include the new data migration in your 2.1 release.</li> <li>Separately, apply the same bugfix atop the 1.1 code. Note: depending on how code changed between 1.1 and 2.0, this 1.1-based bugfix might not contain the exact same code as we used with 2.0.</li> <li>Make another new release of the plugin, this time with build number \"1.2\". This release includes the 1.1-based bugfix. It also should include the new data migration.</li> </ul> <p>This meets our requirements:</p> <ul> <li>Our 2.0 end users can install version 2.1. This gives them the bugfix, and keeps all the features from 2.0.</li> <li>Our 1.0 and 1.1 end users can install version 1.2. This gives them the bugfix without any of the 2.0 features.</li> <li>It is impossible for a 2.1 end user to lose the bugfix, because the Delphix Engine will not allow the build number to go \"backwards\". So, a 2.1 end user will not be able to install versions 2.0, 1.1, or 1.0.</li> <li>It is also impossible for a 1.2 end user to lose the bugfix.<ul> <li>They cannot install 1.0 or 1.1 because the build number is not allowed to decrease.</li> <li>They also cannot install 2.0. The missing data migration on 2.0 will prevent this.</li> </ul> </li> </ul> <p>Note that a 1.2 end user can still upgrade to 2.1 at any time. This will allow them to keep the bugfix, and also take advantage of the new features that were part of 2.0.</p>"},{"location":"Versioning_And_Upgrade/Compatibility/","title":"Compatibility","text":"<p>Before we allow a newly-uploaded plugin to replace an already-installed plugin, we have to make sure that it will not cause any problems.</p> <p>For example:</p> <ul> <li>The newly-uploaded plugin must be able to accept any existing data that has been written using the already-installed plugin.</li> <li>The user should not unexpectedly lose any features or bug fixes that are present in the already-installed plugin.</li> </ul> <p>These restrictions are enforced by the Delphix Engine, and sometimes, the plugin itself.</p>"},{"location":"Versioning_And_Upgrade/Compatibility/#delphix-engine-rules","title":"Delphix Engine Rules","text":"<p>The Delphix Engine will enforce these rules before a newly-uploded plugin is allowed to be installed:</p> <ul> <li>The build number may only move forward, not backwards.</li> <li>All data migration IDs that are present in the already-installed plugin must also be present on the newly-uploaded plugin. The newly-uploaded plugin may add more data migrations, of course.</li> </ul>"},{"location":"Versioning_And_Upgrade/Overview/","title":"Overview","text":"<p>Once you start writing and releasing your plugin, you\u2019ll reach a point when bug fixes or new features may require schema changes. The plugin upgrade process enables objects that have been created with a prior schema to be migrated to the newly defined schema. When this happens, a new version of the plugin must be created. The following few pages will walk through how versions need to change between upgrades and what needs to be written in the plugin to make sure upgrade is successful.</p>"},{"location":"Versioning_And_Upgrade/Overview/#plugin-versioning","title":"Plugin Versioning","text":"<p>Like any other piece of software, plugins change over time. Every so often, there will be a new release. To keep track of the different releases, each plugin release has its own versioning information. Depending on what changes are included in a particular release, there are different rules and recommendations for how the versioning information should be changed. More information on versioning is located here.</p>"},{"location":"Versioning_And_Upgrade/Overview/#upgrade","title":"Upgrade","text":"<p>Upgrade is the process by which an older version of a plugin is replaced by a newer version. Depending on what has changed between the two versions, this process may also include modifying pre-existing plugin defined objects so they conform to the new schema expected by the new version of the plugin. Information on the upgrade process can be found here.</p>"},{"location":"Versioning_And_Upgrade/Replication/","title":"Replication","text":"<p>A Delphix Engine (source) can be setup to replicate data objects to another Delphix Engine (target). Plugins built using the Virtualization SDK work seamlessly with Delphix Engine replication with no additional development required from plugin developers.</p> <p>Only a single version of a plugin can be active on a Delphix Engine at a time. We discuss some basic scenarios below. For more detailed information refer to the Delphix Engine Documentation.</p>"},{"location":"Versioning_And_Upgrade/Replication/#replica-provisioning","title":"Replica Provisioning","text":"<p>Replicated dSource or VDB snapshots can be used to provision new VDBs onto a target Delphix Engine, without failing over any of the objects. When provisioning a VDB from a replicated snapshot:</p> <ul> <li>A version of the plugin has to be installed on the target Delphix Engine.</li> <li>The versions of the plugins installed on the source and target Delphix Engines have to be compatible.</li> </ul> <p>Once provisioned, the VDB on the target Delphix Engine will be associated with the version of the plugin installed on the target Delphix Engine, any required data migrations will be run as part of the provisioning process. For more details refer to the Delphix Engine Documentation.</p>"},{"location":"Versioning_And_Upgrade/Replication/#replication-failover","title":"Replication Failover","text":"<p>On failover, there are three scenarios for each plugin:</p> Scenario Outcome Source plugin not installed on target Delphix Engine The plugin will be failed over and marked as <code>active</code> on the target Delphix Engine. Source plugin version is equal to the target plugin version The plugin from the source will be merged with the plugin on the target Delphix Engine. Source plugin version is not equal to the target plugin version The plugin from the source will be marked <code>inactive</code> on the target Delphix Engine. An <code>inactive</code> plugin can be subsequently activated, after failover, if it is compatible with the existing <code>active</code> plugin. Activating a plugin will do an upgrade and merge the <code>inactive</code> plugin, and all its associated objects, with the <code>active</code> plugin. For more details refer to the Delphix Engine Documentation."},{"location":"Versioning_And_Upgrade/Upgrade/","title":"Upgrade","text":"<p>Upgrade is the process of moving from an older version of a plugin to a newer version. Upgrading is not as simple as just replacing the installed plugin with a newer one.  The main complication comes when the new plugin version makes changes to its schemas.</p> <p>Consider the case of a plugin that works with collections of text files -- the user points it to a directory tree containing text files, and the plugin syncs the files from there.</p> <p>The first release of such a plugin might have no link-related user options. So the plugin's linked source schema might define no properties at all:</p> <pre><code>\"linkedSourceDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\" : false,\n\"properties\" : {\n}\n}\n</code></pre> <p>And, the syncing code is very simple: <pre><code>@plugin.linked.pre_snapshot()\ndef linked_pre_snapshot(direct_source, repository, source_config):\nlibs.run_sync(\nremote_connection = direct_source.connection,\nsource_directory = source_config.path\n)\n</code></pre></p> <p>But, later, some users request a new feature -- they want to avoid syncing any backup or hidden files. So, a new plugin version is released. This time, there is a new boolean property in the linked source schema where users can elect to skip these files, if desired. <pre><code>\"linkedSourceDefinition\": {\n\"type\": \"object\",\n\"additionalProperties\" : false,\n\"required\": [\"skipHiddenAndBackup\"],\n\"properties\" : {\n\"skipHiddenAndBackup\": { \"type\": \"boolean\" }\n}\n}\n</code></pre></p> <p>The plugin code that handles the syncing can now pay attention to this new boolean property: <pre><code>_HIDDEN_AND_BACKUP_SPECS = [\n\"*.bak\",\n\"*~\",  # Backup files from certain editors\n\".*\"  # Unix-style hidden files\n]\n@plugin.linked.pre_snapshot()\ndef linked_pre_snapshot(direct_source, repository, source_config):\nexclude_spec = _HIDDEN_AND_BACKUP_SPECS if direct_source.parameters.skip_hidden_and_backup else []\nlibs.run_sync(\nremote_connection = direct_source.connection,\nsource_directory = source_config.path,\nexclude_paths = exclude_spec\n)\n</code></pre></p> <p>Suppose a user has an engine with linked sources created by the older version of this plugin. That is, the existing linked sources have no <code>skipHiddenAndBackup</code> property.</p> <p>If the user installs the new version of the plugin, we have a problem! The above <code>pre_snapshot</code> code from the new plugin will attempt to access the <code>skip_hidden_and_backup</code> property, which we've just seen will not exist!</p> <p>The solution to this problem is to use data migrations, explained below.</p> <p>Zero dSource and VDB downtime during plugin upgrade</p> <p>dSources and VDBs do not need to be disabled before a plugin upgrade is initiated. End users can continue to access data from existing VDBs during a plugin upgrade. However, while a particular plugin is in the process of being upgraded, no administrative Delphix Engine operations like: VDB Refresh, VDB Provision, dSource Disable/Enable etc will be allowed on the objects associated with that plugin. Objects associated with other plugins will not be affected.</p>"},{"location":"Versioning_And_Upgrade/Upgrade/#data-migrations","title":"Data Migrations","text":""},{"location":"Versioning_And_Upgrade/Upgrade/#what-is-a-data-migration","title":"What is a Data Migration?","text":"<p>Whenever a new version of a plugin is installed on a Delphix Engine, the engine needs to migrate pre-existing data from its old format (as specified by the schemas in the old version of the plugin), to its new format (as specified by the schemas in the new version of the plugin).</p> <p>A data migration is a function that is responsible for doing this conversion. It is provided by the plugin.</p> <p>Thus, when the new plugin version is installed, the engine will call all applicable data migrations provided by the new plugin. This ensures that all data is always in the format expected by the new plugin.</p>"},{"location":"Versioning_And_Upgrade/Upgrade/#a-simple-example","title":"A Simple Example","text":"<p>Let's go back to the above example of the plugin that adds a new boolean option to allow users to avoid syncing backup and hidden files. Here is a data migration that the new plugin can provide to handle the data format change:</p> <pre><code>@plugin.upgrade.linked_source(\"2019.11.20\")\ndef add_skip_option(old_linked_source):\nreturn {\n\"skipHiddenAndBackup\": false\n}\n</code></pre> <p>The exact rules for data migrations are covered in detail below. Here, we'll just walk through this code line by line and make some observations.</p> <p><pre><code>@plugin.upgrade.linked_source(\"2019.11.20\")\n</code></pre> The above line is a decorator that identifies the following function as a data migration. This particular migration will handle linked sources. It is given an ID of <code>2019.11.20</code> -- this controls when this migration is run in relation to other data migrations.</p> <pre><code>def add_skip_option(old_linked_source):\n</code></pre> <p>Note that the data migration takes an argument representing the old-format data. In this simple example, we know that there are no properties in the old-format data, so we can just ignore it.</p> <pre><code>    return {\n\"skipHiddenAndBackup\": false\n}\n</code></pre> <p>Here, we are returning a Python dictionary representing the new format of the data. In this example, the dictionary has only one field: <code>skipHiddenAndBackup</code>. Because the old version of the plugin had no ability to skip files, we default this property to <code>false</code> to match the new schema.</p>"},{"location":"Versioning_And_Upgrade/Upgrade/#rules-for-data-migrations","title":"Rules for Data Migrations","text":"<p>As shown above, the a data migration receives old-format input and produces new-format output. The rules and recommendations for data migrations follow:</p>"},{"location":"Versioning_And_Upgrade/Upgrade/#rules","title":"Rules","text":"<ul> <li> <p>Input and output are Python dictionaries, with properties named exactly as specified in the schemas. Note that this differs from other plugin operations, where the inputs are defined with autogenerated Python classes, and whose properties use Python-style naming.</p> </li> <li> <p>Each data migration must be tagged with an ID string. This string must consist of one or more positive integers separated by periods.</p> </li> <li> <p>Data migration IDs must be numerically unique. Note that <code>\"1.2\"</code>, <code>\"01.02\"</code>, and \"<code>1.2.0.0.0\"</code> are all considered to be identical.</p> </li> <li> <p>Once released, a data migration must never be deleted. An attempted upgrade will fail if the already-installed plugin version has a data migration that does not appear in the to-be-installed version.</p> </li> <li> <p>At upgrade time, the engine will find the set of new migrations provided by the new version that are not already part of the already-installed version. Each of these migrations will then be run, in the order specified below.</p> </li> <li> <p>After running all applicable migrations, the engine will confirm that the resultant data conforms to the new version's schemas. If not, the upgrade will fail.</p> </li> <li> <p>Note that there is no requirement or guarantee that the input or output of any particular data migration will conform to a schema. We only guarantee that the input to the first data migration conforms to the schema of the already-installed plugin version. And, we only require that the output of the final data migration conforms to the schema of the new plugin version.</p> </li> <li> <p>Data migrations are run in the order specified by their IDs. The ordering is numerical, not lexicographical. Thus <code>\"1\"</code> would run before <code>\"2\"</code>, which would run before <code>\"10\"</code>.</p> </li> <li> <p>With the exception of <code>upgrade_password</code>, data migrations have no access to most Platform Libraries or remote hosts. For example: If a data migration attempts to use run_bash the upgrade will fail.</p> </li> <li> <p>Password properties can be generalized to credential-supplying objects that offer alternative mechanisms for obtaining passwords and secrets, such as password vaults. To achieve that, a data migration must call <code>upgrade_password</code>.</p> </li> <li> <p>Note that the above rules imply that at least one data migration is required any time a schema change is made that would invalidate any data produced using a previous version of the plugin. For example: adding a <code>\"required\"</code> property to the new schema.</p> </li> </ul>"},{"location":"Versioning_And_Upgrade/Upgrade/#recommendations","title":"Recommendations","text":"<ul> <li> <p>We recommend using a \"Year.Month.Date\" format like <code>\"2019.11.04\"</code> for migration IDs. You can use trailing integers as necessary (e.g. use <code>\"2019.11.04.5\"</code> if you need something to be run between <code>\"2019.11.04\"</code> and <code>\"2019.11.05\"</code>).</p> </li> <li> <p>Even though they follow similar naming rules, migration IDs are not the same thing as plugin versions. We do not recommend using your plugin version in your migration IDs.</p> </li> <li> <p>We recommend using small, single-purpose data migrations. That is, if you end up making four schema changes over the course of developing a new plugin version, we recommend writing four different data migrations, one for each change.</p> </li> </ul>"},{"location":"Versioning_And_Upgrade/Upgrade/#data-migration-example","title":"Data Migration Example","text":"<p>Here is a very simple data migration. <pre><code>@plugin.upgrade.repository(\"2019.12.15\")\ndef add_new_flag_to_repo(old_repository):\nnew_repository = dict(old_repository)\nnew_repository[\"useNewFeature\"] = False\nreturn new_repository\n</code></pre></p>"},{"location":"Versioning_And_Upgrade/Upgrade/#debugging-data-migration-problems","title":"Debugging Data Migration Problems","text":"<p>During the process of upgrading to a new version, the Delphix Engine will run all applicable data migrations, and then ensure that the resulting object matches the new schema. But, what if there is a bug, and the resulting object does not match the schema?</p>"},{"location":"Versioning_And_Upgrade/Upgrade/#security-concerns-prevent-detailed-error-messages","title":"Security Concerns Prevent Detailed Error Messages","text":"<p>One problem here is that the Delphix Engine is limited in the information that it can provide in the error message. Ideally, the engine would say exactly what was wrong with the object (e.g.: \"The field <code>port</code> has the value <code>15</code>, but the schema says it has to have a value between <code>256</code> and <code>1024</code>\").</p> <p>But, the Delphix Engine cannot do this for security reasons. Ordinarily, the Delphix Engine knows which fields contain sensitive information, and can redact such fields from error messages. But, the only reason the Delphix Engine has that knowledge is because the schema provides that information. If an object does not conform to the schema, then the Delphix Engine can't know what is sensitive and what isn't.</p> <p>Therefore, the error message here might lack the detail necessary to debug the problem.</p>"},{"location":"Versioning_And_Upgrade/Upgrade/#one-solution-temporary-logging","title":"One Solution: Temporary Logging","text":"<p>During development of a new plugin version, you may find yourself trying to find and fix such a bug. One technique is to use temporary logging.</p> <p>For example, while you are trying to locate and fix the bug, you could put a log statement at the very end of each of your data migrations, like so: <pre><code>  logger.debug(\"Migration 2010.03.01 returning {}\".format(new_object))\n  return new_object\n</code></pre></p> <p>See the Logging section for more information about logging works.</p> <p>From the logs, you'll be able to see exactly what each migration is returning. From there, hopefully the problem will become apparent. As a supplemental tool, consider pasting these results (along with your schema) into an online JSON validator for more information.</p> <p>Warning</p> <p>It is very important that you only use logging as a temporary debugging strategy. Such logging must be removed before you release the plugin to end users. If this logging ends up in your end product, it could cause a serious security concern. Please see our sensitive data best practices for more information.</p>"},{"location":"Versioning_And_Upgrade/Upgrade/#when-data-migrations-are-insufficient","title":"When Data Migrations Are Insufficient","text":"<p>New versions of plugins often require some modification of data that was written using an older version of the same plugin. Data migrations handle this modification. Unfortunately, data migrations cannot always fully handle all possible upgrade scenarios by themselves.</p> <p>For example, a new plugin version might want to add a new required field to one of its schemas. But, the correct value for this new field might not be knowable while the upgrade is underway -- perhaps it must be entered by the user, or perhaps it would require automatic discovery to be rerun.</p> <p>Such a situation will require some user intervention after the upgrade.</p> <p>In all cases, of course you will want to clearly document to your users that there will extra work required so they can make sure they known what they are getting into before they decide to upgrade.</p> <p>Tip</p> <p>It should also be said that you should try to avoid cases like this.  As much as possible, try to make your post-upgrade plugin function with no user intervention. Only resort to user intervention as a last resort.</p> <p>The recommended strategy here is to arrange for the affected objects to be in an \"invalid\" state, and for your plugin code to detect this state, and throw errors when the objects are used.</p> <p>For such a situation, we recommend the following process:</p> <ul> <li>Make your schema changes so that the affected property can be set in such a way that plugin code can identify it as being invalid. Typically this is done by allowing for some \"sentinel\" value. This may require you to have a less-strict schema definition than you might otherwise want.</li> <li>In your data migrations, make sure the affected properties are indeed marked invalid.</li> <li>In any plugin code that needs to use these properties, first check them for validity. If they are invalid, then raise an error that explains the situation to the user, and tells them what steps they need to take.</li> </ul> <p>Following are two examples of schema changes that need extra user intervention after upgrade. One will require a rediscovery, and the other will require the user to enter information.</p>"},{"location":"Versioning_And_Upgrade/Upgrade/#autodiscovery-example","title":"Autodiscovery Example","text":"<p>Suppose that a new plugin version adds a new required field to its repository schema. This new field specifies a full path to a database installation. The following listing shows what we'd ideally like the new repository schema to look like (<code>installationPath</code> is the new required property)</p> <pre><code>\"repositoryDefinition\": {\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": { \"type\": \"string\" },\n        \"installationPath\": { \"type\": \"string\", \"format\": \"unixpath\"}\n    },\n    \"required\": [\"name\", \"installationPath\"],\n    \"nameField\": \"name\",\n    \"identityFields\": [\"name\"]\n}\n</code></pre> <p>The new plugin's autodiscovery code will know how to find this full path. Therefore, any repositories that are discovered (or rediscovered) after the upgrade will have this path filled in correctly.</p> <p>But, there may be repositories that were discovered before the upgrade. The data migrations will have to ensure that some value is provided for this new field. However, a data migration will not be able to determine what the correct final value is.</p> <p>One way to handle this is to modify the schema to allow a special value to indicate that the object needs to be rediscovered. In this example, we'll change the schema from the ideal version above, removing the <code>unixpath</code> constraint on this string: <pre><code>\"installationPath\": { \"type\": \"string\" }\n</code></pre></p> <p>Now, our data migration can set this property to some special sentinel value that will never be mistaken for an actual installation path. <pre><code>_REDISCOVERY_TOKEN = \"###_REPOSITORY_NEEDS_REDISCOVERY_###\"\n\n@plugin.upgrade.repository(\"2020.02.04.01\")\ndef repo_path(old_repository):\n    # We need to add in a repository path, but there is no way for us to know\n    # what the correct path is here, so we cannot set this to anything useful.\n    # Instead, we'll set a special sentinel value that will indicate that the\n    # repository is unusable until the remote host is rediscovered.\n    old_repository[\"installationPath\"] = _REDISCOVERY_TOKEN\n    return old_repository\n</code></pre></p> <p>Now, wherever the plugin needs to use this path, we'll need to check for this sentinel value, and error out if we find it.  For example, we might need a valid path during the <code>configure</code> operation: <pre><code>@plugin.virtual.configure()\ndef configure(virtual_source, snapshot, repository):\n    if repository.installation_path == _REDISCOVERY_TOKEN:\n        # We cannot use this repository as/is -- it must be rediscovered.\n        msg = 'Unable to use repository \"{}\" because it has not been updated ' \\\n        'since upgrade. Please re-run discovery and try again'\n        raise UserError(msg.format(repository.name))\n\n    # ... actual configure code goes here\n</code></pre></p>"},{"location":"Versioning_And_Upgrade/Upgrade/#manual-entry","title":"Manual Entry","text":"<p>Above, we looked at an example where the plugin could handle filling in new values for a new field at discovery time, so the user was simply asked to rediscover.</p> <p>Sometimes, though, users themselves will have to be the ones to supply new values.</p> <p>Suppose that a new plugin version wants to add a required field to the <code>virtualSource</code> object. This new property will tell which port the database should be accessible on. Ideally, we might want our new field to look like this:</p> <pre><code>\"port\": {\"type\": \"integer\", \"minimum\": 1024, \"maximum\": 65535}\n</code></pre> <p>Again, however, the data migration will not know which value is correct here. This is something the user must decide. Still, the data migration must provide some value. As before, we'll change the schema a bit from what would be ideal:</p> <pre><code>\"port\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 65535}\n</code></pre> <p>Now, our data migration can use the value <code>0</code> as code for \"this VDB needs user intervention\".</p> <pre><code>@plugin.upgrade.virtual_source(\"2020.02.04.02\")\ndef add_dummy_port(old_virtual_source):\n    # Set the \"port\" property to 0 to act as a placeholder.\n    old_virtual_source[\"port\"] = 0\n    return old_virtual_source\n</code></pre> <p>As with the previous example, our plugin code will need to look for this special value, and raise an error so that the user knows what to do. This example shows the Virtual Source Reconfigure operation, but of course, similar code will be needed anywhere else that the new <code>port</code> property is required.</p> <pre><code>@plugin.virtual.reconfigure()\ndef virtual_reconfigure(virtual_source, repository, source_config, snapshot):\n    if virtual_source.parameters.port == 0:\n        raise UserError('VDB \"{}\" cannot function properly. Please choose a ' \\\n        'port number for this VDB to use.'.format(virtual_source.parameters.name))\n\n    # ... actual reconfigure code goes here\n</code></pre>"},{"location":"Versioning_And_Upgrade/Versioning/","title":"Versioning","text":"<p>Almost all software products are periodically updated to include new features and bug fixes. Plugins are no exception -- a plugin's code will very likely be different two years from now.</p> <p>To deal with this, plugins use versioning. This just means that a plugin communicates (to the user, and to the Delphix Engine) exactly what code is in use.</p>"},{"location":"Versioning_And_Upgrade/Versioning/#versioning-information","title":"Versioning Information","text":"<p>There are three different pieces of version-related information, each used for different purposes.</p>"},{"location":"Versioning_And_Upgrade/Versioning/#external-version","title":"External Version","text":"<p>This field is intended only for use by the end user. The Delphix Engine does not use this field, and therefore imposes no restrictions on its content. This is a free-form string which the plugin can use in any way it feels like.</p> <p>Examples might be \"5.3.0\", \"2012B\", \"MyPlugin Millennium Edition, Service Pack 3\", \"Playful Platypus\" or \"Salton City\".</p> <p>The external version is specified using the <code>externalVersion</code> property in your plugin config file.</p> <p>Tip</p> <p>Use an external version that makes it easier for end users to determine newer vs older plugins.</p>"},{"location":"Versioning_And_Upgrade/Versioning/#build-number","title":"Build Number","text":"<p>Unlike \"external version\", this field is intended to convey information to the Delphix Engine. This is a string of integers, separated by periods. Examples would be \"5.3.0\", \"7\", \"5.3.0.0.0.157\".</p> <p>The Delphix Engine uses the build number to guard against end users trying to \"downgrade\" their plugin to an older, incompatible version. So, if a user has build number \"3.4.1\" installed, then they may not install a version with a build number like \"2.x.y\", \"3.3.y\" or \"3.4.0\".</p> <p>The build number is specified using the <code>buildNumber</code> property in your plugin config file.</p> <p>This field is required to be a string. You might need to enclose your build number in quotes in order to prevent YAML from interpreting the field as a number. Examples:</p> <code>buildNumber</code> Allowed Details 1 No YAML will interpret this as an integer. 1.2 No YAML will interpret this as a floating-point number. \"1\" Yes The quotes mean this is a string. \"1.2\" Yes The quotes mean this is a string. 1.2.3 Yes YAML treats this as a string, since it cannot be a number."},{"location":"Versioning_And_Upgrade/Versioning/#build-number-format-rules","title":"Build Number Format Rules","text":"<p>Your build number must be a string, conforming to these rules:</p> <ul> <li>The string must be composed of a sequence of non-negative integers, not all zero, separated by periods.</li> <li>Trailing zeros are ignored. So, \"1.0.0\" is treated the same as \"1\".</li> <li>Build numbers are sortable numerically, with earlier numbers having more significance than later numbers. So, \"2.0\" comes after \"1.99999\", and \"1.10\" comes after \"1.2\".</li> <li>The Delphix Engine will never allow installation of plugin with a build number that is ordered before the the already-installed build number.</li> </ul> <p>Tip</p> <p>You can upload a plugin with the same <code>buildNumber</code> as the installed plugin. However this should only be done while a plugin is being developed. Plugin releases for end users should never have the same <code>buildNumber</code></p> <p>Please also see the App-Style vs. Enterprise-Style section below. We generally recommend using a single integer build number for app-style development. Build numbers need to have multiple parts if you are doing enterprise-style development.</p>"},{"location":"Versioning_And_Upgrade/Versioning/#release-strategies","title":"Release Strategies","text":"<p>There are two main strategies for releasing software:</p>"},{"location":"Versioning_And_Upgrade/Versioning/#app-style-release-strategy","title":"\"App-style\" Release Strategy","text":"<p>Here, all users are expected to use the latest available version of the software. Most consumer software works this way today -- websites, phone apps, etc. An app-style strategy is much simpler, but also more limiting:</p> <ul> <li>At any time, there is only one branch under active development.</li> <li>Customers that want bugfixes must upgrade to the latest version.</li> <li>The plugin's build number can be a simple integer that is incremented with each new release.</li> </ul>"},{"location":"Versioning_And_Upgrade/Versioning/#enterprise-style-release-strategy","title":"\"Enterprise-style\" Release Strategy","text":"<p>Here, you might distinguish \"major\" releases of your software from \"minor\" releases. You might expect some customers to continue to use older major releases for a long time, even after a new major release comes out. This strategy is often used for software like operating systems and DBMSs, where upgrading can cause significant disruption. An enterprise-style strategy is more flexible, but also more cumbersome:</p> <ul> <li>There may be multiple branches under active development at any time. Typically one branch for every \"major release\" that is still being supported. This requires careful coordination to make sure that each new code change ends up on the correct branch (or branches).</li> <li>It is possible to supply bugfix-only minor releases (often called \"patch releases\") which build atop older major releases. Customers do not need to move to the new major version in order to get these bugfixes.</li> <li>The plugin's build number needs to be composed of multiple integers.</li> </ul> <p>If you are using this strategy read more here about how to deal with backports and hotfixes.</p> <p>You may use whichever of these strategies works best for you. The SDK and the Delphix Engine support either strategy. You can even change your mind later and switch to the other strategy.</p>"},{"location":"Versioning_And_Upgrade/Versioning/#recommendations","title":"Recommendations","text":"<ul> <li>Build your plugin with the newest Virtualization SDK version available.</li> <li>Only publish one artifact built for a given official version of the plugin.</li> <li>The official release of a plugin should not use the same build number as a development build.</li> <li>Use an external version that helps easily identify newer plugins.</li> <li>Publish a plugin version compatibility matrix which lists out the plugin version, the Virtualization SDK it was built with and the Delphix Engine version(s) it supports.</li> </ul>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Converting_Migration_Scripts/","title":"Converting Lua Upgrade Scripts to Python Data Migrations","text":"<p>To convert migrations (a.k.a. \"upgrade scripts\") that were originally written in Lua, we need to get the version that the migration upgrades from, the object type the migration is written for, and lastly convert the code into Python code using the decorators described previously.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Converting_Migration_Scripts/#example","title":"Example","text":"<p>Assume there are two versions of a lua toolkit, <code>1.0.0</code> and <code>1.1.0</code> where the <code>1.1.0</code> version is following the basic toolkit directory structure (actually containing all operations):</p> <pre><code>\u251c\u2500\u2500 main.json\n\u251c\u2500\u2500 discovery \n\u2502   \u251c\u2500\u2500 repositoryDiscovery.lua\n\u2502   \u2514\u2500\u2500 sourceConfigDiscovery.lua\n\u251c\u2500\u2500 staged \n\u2502   \u251c\u2500\u2500 mountSpec.lua\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 worker.lua\n\u251c\u2500\u2500 virtual \n\u2502   \u251c\u2500\u2500 configure.lua\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 unconfigure.lua\n\u251c\u2500\u2500 upgrade \n\u2502   \u2514\u2500\u2500 1.0\n\u2502       \u251c\u2500\u2500 upgradeLinkedSource.lua\n\u2502       \u251c\u2500\u2500 ...\n\u2502       \u2514\u2500\u2500 upgradeVirtualSource.lua\n\u251c\u2500\u2500 resources \n\u2514\u2500\u2500 \u251c\u2500\u2500 log.sh\n    \u251c\u2500\u2500 ...\n    \u2514\u2500\u2500 stop.sh\n</code></pre> <p><code>upgradeLinkedSource.lua</code> contains:</p> <pre><code>parameters.dsOldValue = \"remove\"\nparameters.dsUpdateValue = 1\nparameters.dsLanguage = \"LUA\"\nreturn parameters\n</code></pre> <p>This can be equalivalently converted into the python code:</p> <pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.linked_source(\"1.0\", MigrationType.LUA)\ndef upgrade_linked_source(old_linked_source):\nnew_linked_source = dict(old_linked_source)\nnew_linked_source[\"dsOldValue\"] = \"remove\"\nnew_linked_source[\"dsUpdateValue\"] = 1\nnew_linked_source[\"dsLanguage\"] = \"LUA\"\nreturn new_linked_source\n</code></pre> <p>You will need to determine how far back in the Lua upgrade chain you want to support multi-step upgrade from, and convert all of those upgrade scripts accordingly. Remember that the execution of these scripts relies on there not being any missing migrations from the <code>minimumLuaVersion</code> defined in the plugin config to the last toolkit version written. Lua migrations will be executed from the lowest to highest version that exists. When executing, these migrations are run to the highest Lua toolkit version only. Any migrations needed to get from that toolkit to the Python plugin would need to be written as a regular Python migration.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Decorators/","title":"Decorators","text":"<p>The Virtualization SDK exposes decorators as mentioned in the regular documentation. Below we list the additional operations added to suport Lua to Python migrations. This assumes <code>Plugin()</code> is instantiated as <code>plugin</code>:</p> Plugin Operation Decorator Lua Repository Data Migration <code>@plugin.upgrade.repository(lua_version, MigrationType.LUA)</code> Lua Source Config Data Migration <code>@plugin.upgrade.source_config(lua_version, MigrationType.LUA)</code> Lua Linked Source Data Migration <code>@plugin.upgrade.linked_source(lua_version, MigrationType.LUA)</code> Lua Virtual Source Data Migration <code>@plugin.upgrade.virtual_source(lua_version, MigrationType.LUA)</code> Lua Snapshot Data Migration <code>@plugin.upgrade.snapshot(lua_version, MigrationType.LUA)</code> <p>lua_version format</p> <p>The <code>lua_version</code> field in this decorator should be the (major,minor) version of the Lua toolkit. This means if the version is set to <code>1.1.HOTFIX123</code> in the <code>main.json</code> file for the Lua toolkit, the <code>lua_version</code> passed into this decorator should be <code>1.1</code>.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Overview/","title":"Overview","text":"<p>Before the Virtualization SDK was written, Delphix only supported toolkits written in Lua. There was only limited documentation to help people write, build, and upload toolkits. Multiple toolkits were released and are still used by customers today, so as we move towards only supporting SDK Plugins, there needs to be a way to get customers off of Lua toolkits and onto SDK plugins.</p> <p>If you are reading this and have no idea what a Lua toolkit is, there is no reason to read further into this section. Everything written in these pages will assume the goal is to write specific code as part of a plugin to convert objects created using Lua toolkits to use the newly uploaded Python plugin.</p> <p>In the next few pages, we also make the assumption that you've written both a Lua toolkit and a Python plugin before and know some of the terminology already established. If this is not true, please try building a plugin and writing some upgrade migrations first before coming back here to learn how to add upgrading from Lua toolkits into the mix as described below.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Overview/#basic-no-schema-migration","title":"Basic no-schema Migration","text":"<p>One way to migrate from a Lua toolkit to a plugin is to write an exactly equivalent plugin that does not make any schema changes to the objects that were defined originally in the Lua toolkit. If this is the scenario you are in, then you only need to update the plugin config with a couple of new Lua migration specific fields.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Overview/#migration-with-schema-changes","title":"Migration with schema changes","text":"<p>The other way to migrate from a Lua toolkit to a plugin is to wait and write a python plugin only once you have new features you want to release. These new features may include schema changes to any of the objects. In this case you will need to update both the plugin config and write new Lua upgrade operations for each of the objects that needs to be modified during the upgrade.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Overview/#supporting-migrations-with-older-versions-of-lua","title":"Supporting migrations with older versions of Lua","text":"<p>Having the ability to define Lua upgrade operations in the new plugin code means that older Lua version migration scripts can be converted, enabling multi-step upgrades from older Lua versions to migrate and become plugins.</p> <p>New versions of a Lua toolkit is strongly discouraged after Python Plugin is written</p> <p>After having written a Plugin to migrate a specific Lua toolkit, while possible, you should avoid writing new major/minor versions of the toolkit in Lua. Patch releases with no schema changes can still be done. If you need to write a new Lua toolkit version please contact the Delphix Virtualization SDK Engineering team to get help on updating migrations accordingly.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Config/","title":"Plugin Config","text":"<p>For all regular fields in a plugin config go here. The following fields described are the ones needed to migrate Lua toolkits to Python plugins.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Config/#fields","title":"Fields","text":"Field Name Required Type Description luaName N string The name of the Lua toolkit this plugin should upgrade from. This field is required if the minimumLuaVersion is defined. minimumLuaVersion N string The lowest major minor version of the Lua toolkit that upgrade is supported from. This field is required if the luaName is defined."},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Config/#example","title":"Example","text":"<p>Assume a lua toolkit with the following <code>main.json</code> file:</p> <pre><code>{\n\"type\": \"Toolkit\",\n\"name\": \"delphixdb\",\n\"prettyName\": \"DelphixDB\",\n\"version\": \"1.0.0\",\n\"defaultLocale\": \"en-us\",\n\"hostTypes\": [\"UNIX\"],\n\"discoveryDefinition\": {\n\"type\": \"ToolkitDiscoveryDefinition\",\n\"repositorySchema\": {\n\"type\": \"object\",\n\"properties\": {\n\"installPath\": {\n\"type\": \"string\",\n\"prettyName\": \"Delphix DB Binary Installation Path\",\n\"description\": \"The path to the Delphix DB installation binaries\"\n},\n\"version\": {\n\"type\": \"string\",\n\"prettyName\": \"Version\",\n\"description\": \"The version of the Delphix DB binaries\"\n}\n}\n},\n\"repositoryIdentityFields\": [\"installPath\"],\n\"repositoryNameField\": \"installPath\",\n\"sourceConfigSchema\": {\n\"type\": \"object\",\n\"properties\": {\n\"dataPath\": {\n\"type\": \"string\",\n\"prettyName\": \"Data Path\",\n\"description\": \"The path to the Delphix DB instance's data\"\n},\n\"port\": {\n\"type\": \"integer\",\n\"prettyName\": \"Port\",\n\"description\": \"The port of the Delphix DB\"\n},\n\"dbName\": {\n\"type\": \"string\",\n\"prettyName\": \"Delphix DB Name\",\n\"description\": \"The name of the Delphix DB instance.\"\n}\n}\n},\n\"sourceConfigIdentityFields\": [\"dataPath\"],\n\"sourceConfigNameField\": \"dataPath\"\n},\n\"linkedSourceDefinition\": {\n\"type\": \"ToolkitLinkedStagedSource\",\n\"parameters\": {\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"properties\": {\n\"primaryDbName\": {\n\"type\": \"string\",\n\"prettyName\": \"Primary DB Name\",\n\"description\": \"The name of the primary database to link.\",\n\"default\": \"primaryDB\"\n},\n\"stagingDbName\": {\n\"type\": \"string\",\n\"prettyName\": \"Staging DB Name\",\n\"description\": \"The name of the staging database to create.\"\n},\n\"stagingPort\": {\n\"type\": \"integer\",\n\"prettyName\": \"Staging Port\",\n\"description\": \"The port of the staging database to create.\",\n\"default\": 1234\n}\n}\n}\n},\n\"virtualSourceDefinition\": {\n\"type\": \"ToolkitVirtualSource\",\n\"parameters\": {\n\"type\": \"object\",\n\"additionalProperties\": false,\n\"properties\": {\n\"port\": {\n\"type\": \"integer\",\n\"prettyName\": \"Port\",\n\"description\": \"Port that provisioned database should use.\",\n\"default\": 1234\n},\n\"dbName\": {\n\"type\": \"string\",\n\"prettyName\": \"Database Name\",\n\"description\": \"Name to use for newly provisioned database.\",\n\"default\": \"vdb\"\n}\n}\n}\n},\n\"snapshotSchema\": {\n\"type\": \"object\",\n\"properties\": {\n\"snapshotID\": {\n\"type\": \"string\",\n\"prettyName\": \"Snapshot ID\",\n\"description\": \"A unique ID for this snapshot\"\n}\n}\n}\n}\n</code></pre> <p>Here is a valid plugin config for a plugin that wants to be upgradable from the toolkit:</p> <pre><code>id: ea009cb4-f76b-46dc-bbb6-689e7acecce4\nname: DelphixDB\nluaName: delphixdb\nminimumLuaVersion: \"1.0\"\nlanguage: PYTHON27\nhostTypes:\n- UNIX\npluginType: STAGED\nentryPoint: plugin_runner:plugin\nsrcDir: src\nschemaFile: schema.json\nbuildNumber: 2.0.0\n</code></pre> <p><code>id</code> and <code>luaName</code> fields in plugins versus <code>name</code> field in toolkits</p> <ul> <li>The <code>luaName</code> will be used to determine if an already uploaded Lua toolkit is considered a lower version of the Pyhon plugin being uploaded.</li> <li>If the <code>luaName</code> is not set then no Lua toolkit will be upgraded.</li> <li>If the <code>id</code> of the plugin being uploaded happens to match the <code>name</code> in the Lua toolkit already installed on the Delphix Engine, the upload will fail regardless of what the <code>luaName</code> is.  </li> <li>When uploading a plugin with the <code>luaName</code> set, that <code>luaName</code> and <code>id</code> pair will be the only pair uploaded successfully. Uploading a new plugin with the same <code>luaName</code> but different <code>id</code> will fail.</li> </ul>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/","title":"Plugin Operations","text":""},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#summary","title":"Summary","text":"<p>Plugin operations related to Lua migrations are listed below. Information regarding other operations is here.</p> Plugin Operation Required Decorator Delphix Engine Operations Lua Repository Data Migration No <code>upgrade.repository(lua_version, MigrationType.LUA)</code> Upgrade Lua Source Config Data Migration No <code>upgrade.source_config(lua_version, MigrationType.LUA)</code> Upgrade Lua Linked Source Data Migration No <code>upgrade.linked_source(lua_version, MigrationType.LUA)</code> Upgrade Lua Virtual Source Data Migration No <code>upgrade.virtual_source(lua_version, MigrationType.LUA)</code> Upgrade Lua Snapshot Data Migration No <code>upgrade.snapshot(lua_version, MigrationType.LUA)</code> Upgrade"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#lua-repository-data-migration","title":"Lua Repository Data Migration","text":"<p>A Lua Repository Data Migration migrates repository data from an older schema format defined originally from a Lua toolkit to an updated schema format defined in the Python plugin.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#required-optional","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all repository data will match your updated repository schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more repository data migrations.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#delphix-engine-operations","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#signature","title":"Signature","text":"<p><code>def migrate_repository(old_repository)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator","title":"Decorator","text":"<p><code>upgrade.repository(lua_version, MigrationType.LUA)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator-arguments","title":"Decorator Arguments","text":"Argument Type Description lua_version String The Lua version of the toolkit that this migration would be applicable to. This is the ID of this migration. The version here is actually just the major and minor version of the Lua toolkit. Therefore the <code>lua_version</code> for each repository data migration must be unique. migration_type String This field indicates whether the operation is a Lua migration or just a regular data migration. Specify this as LUA to indicate a Lua migration. If not defined, this operation will default to a regular repository data migration."},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#function-arguments","title":"Function Arguments","text":"Argument Type Description old_repository Dictionary The plugin-specific data associated with a repository, that conforms to the previous schema defined in Lua. <p>Warning</p> <p>The function argument <code>old_repository</code> is a Python dictionary, where each property name appears exactly as described in the previous repository schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#returns","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_repository</code> input that must conform to the updated repository schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#example","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.repository(\"1.1\", MigrationType.LUA)\ndef add_new_flag_to_repository(old_repository):\nnew_repository = dict(old_repository)\nnew_repository[\"useNewFeature\"] = False\nreturn new_repository\n</code></pre>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#lua-source-config-data-migration","title":"Lua Source Config Data Migration","text":"<p>A Lua Source Config Data Migration migrates source config data from an older schema format defined originally from a Lua toolkit to an updated schema format defined in the Python plugin.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#required-optional_1","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all source config data will match your source config schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more source config data migrations.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#delphix-engine-operations_1","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#signature_1","title":"Signature","text":"<p><code>def migrate_source_config(old_source_config)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator_1","title":"Decorator","text":"<p><code>upgrade.source_config(lua_version, MigrationType.LUA)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator-arguments_1","title":"Decorator Arguments","text":"Argument Type Description lua_version String The Lua version of the toolkit that this migration would be applicable to. This is the ID of this migration. The version here is actually just the major and minor version of the Lua toolkit. Therefore the <code>lua_version</code> for each repository data migration must be unique. migration_type String This field indicates whether the operation is a Lua migration or just a regular data migration. Specify this as LUA to indicate a Lua migration. If not defined, this operation will default to a regular source config data migration."},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#function-arguments_1","title":"Function Arguments","text":"Argument Type Description old_source_config Dictionary The plugin-specific data associated with a source config, that conforms to the previous schema. <p>Warning</p> <p>The function argument <code>old_source_config</code> is a Python dictionary, where each property name appears exactly as described in the previous source config schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#returns_1","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_source_config</code> input that must conform to the updated source config schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#example_1","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.source_config(\"1.1\", MigrationType.LUA)\ndef add_new_flag_to_source_config(old_source_config):\nnew_source_config = dict(old_source_config)\nnew_source_config[\"useNewFeature\"] = False\nreturn new_source_config\n</code></pre>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#lua-linked-source-data-migration","title":"Lua Linked Source Data Migration","text":"<p>A Lua Linked Source Data Migration migrates linked source data from an older schema format defined originally from a Lua toolkit to an updated schema format defined in the Python plugin.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#required-optional_2","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all linked source data will match your linked source schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more linked source data migrations.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#delphix-engine-operations_2","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#signature_2","title":"Signature","text":"<p><code>def migrate_linked_source(old_linked_source)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator_2","title":"Decorator","text":"<p><code>upgrade.linked_source(lua_version, MigrationType.LUA)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator-arguments_2","title":"Decorator Arguments","text":"Argument Type Description lua_version String The Lua version of the toolkit that this migration would be applicable to. This is the ID of this migration. The version here is actually just the major and minor version of the Lua toolkit. Therefore the <code>lua_version</code> for each repository data migration must be unique. migration_type String This field indicates whether the operation is a Lua migration or just a regular data migration. Specify this as LUA to indicate a Lua migration. If not defined, this operation will default to a regular linked source data migration."},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#function-arguments_2","title":"Function Arguments","text":"Argument Type Description old_linked_source Dictionary The plugin-specific data associated with a linked source, that conforms to the previous schema. <p>Warning</p> <p>The function argument <code>old_linked_source</code> is a Python dictionary, where each property name appears exactly as described in the previous linked source schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#returns_2","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_linked_source</code> input that must conform to the updated linked source schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#example_2","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.linked_source(\"1.1\", MigrationType.LUA)\ndef add_new_flag_to_linked_source(old_linked_source):\nnew_linked_source = dict(old_linked_source)\nnew_linked_source[\"useNewFeature\"] = False\nreturn new_linked_source\n</code></pre>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#lua-virtual-source-data-migration","title":"Lua Virtual Source Data Migration","text":"<p>A Lua Virtual Source Data Migration migrates virtual source data from an older schema format defined originally from a Lua toolkit to an updated schema format defined in the Python plugin.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#required-optional_3","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all virtual source data will match your virtual source schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more virtual source data migrations.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#delphix-engine-operations_3","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#signature_3","title":"Signature","text":"<p><code>def migrate_virtual_source(old_virtual_source)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator_3","title":"Decorator","text":"<p><code>upgrade.virtual_source(lua_version, MigrationType.LUA)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator-arguments_3","title":"Decorator Arguments","text":"Argument Type Description lua_version String The Lua version of the toolkit that this migration would be applicable to. This is the ID of this migration. The version here is actually just the major and minor version of the Lua toolkit. Therefore the <code>lua_version</code> for each repository data migration must be unique. migration_type String This field indicates whether the operation is a Lua migration or just a regular data migration. Specify this as LUA to indicate a Lua migration. If not defined, this operation will default to a regular virtual source data migration."},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#function-arguments_3","title":"Function Arguments","text":"Argument Type Description old_virtual_source Dictionary The plugin-specific data associated with a virtual source, that conforms to the previous schema. <p>Warning</p> <p>The function argument <code>old_virtual_source</code> is a Python dictionary, where each property name appears exactly as described in the previous virtual source schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#returns_3","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_virtual_source</code> input that must conform to the updated virtual source schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#example_3","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.virtual_source(\"1.1\", MigrationType.LUA)\ndef add_new_flag_to_virtual_source(old_virtual_source):\nnew_virtual_source = dict(old_virtual_source)\nnew_virtual_source[\"useNewFeature\"] = False\nreturn new_virtual_source\n</code></pre>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#lua-snapshot-data-migration","title":"Lua Snapshot Data Migration","text":"<p>A Lua Snapshot Data Migration migrates snapshot data from an older schema format defined originally from a Lua toolkit to an updated schema format defined in the Python plugin.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#required-optional_4","title":"Required / Optional","text":"<p>Optional.</p> <p>Warning</p> <p>You must ensure that all snapshot data will match your snapshot schema after an upgrade operation. Depending on how your schema has changed, this might imply that you need to write one or more snapshot migrations.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#delphix-engine-operations_4","title":"Delphix Engine Operations","text":"<ul> <li>Upgrade</li> </ul>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#signature_4","title":"Signature","text":"<p><code>def migrate_snapshot(old_snapshot)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator_4","title":"Decorator","text":"<p><code>upgrade.snapshot(lua_version, MigrationType.LUA)</code></p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#decorator-arguments_4","title":"Decorator Arguments","text":"Argument Type Description lua_version String The Lua version of the toolkit that this migration would be applicable to. This is the ID of this migration. The version here is actually just the major and minor version of the Lua toolkit. Therefore the <code>lua_version</code> for each repository data migration must be unique. migration_type String This field indicates whether the operation is a Lua migration or just a regular data migration. Specify this as LUA to indicate a Lua migration. If not defined, this operation will default to a regular snapshot data migration."},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#function-arguments_4","title":"Function Arguments","text":"Argument Type Description old_snapshot Dictionary The plugin-specific data associated with a snapshot, that conforms to the previous schema. <p>Warning</p> <p>The function argument <code>old_snapshot</code> is a Python dictionary, where each property name appears exactly as described in the previous snapshot schema. This differs from non-upgrade-related operations, where the function arguments are autogenerated classes based on the schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#returns_4","title":"Returns","text":"<p>Dictionary A migrated version of the <code>old_snapshot</code> input that must conform to the updated snapshot schema.</p>"},{"location":"Versioning_And_Upgrade/Lua_Toolkit_To_SDK_Plugin_Migration/Plugin_Operations/#example_4","title":"Example","text":"<pre><code>from dlpx.virtualization.platform import Plugin\nplugin = Plugin()\n@plugin.upgrade.snapshot(\"1.1\", MigrationType.LUA)\ndef add_new_flag_to_snapshot(old_snapshot):\nnew_snapshot = dict(old_snapshot)\nnew_snapshot[\"useNewFeature\"] = False\nreturn new_snapshot\n</code></pre>"}]}